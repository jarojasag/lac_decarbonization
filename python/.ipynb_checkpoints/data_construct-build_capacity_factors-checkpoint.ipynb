{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87aada3-9452-4551-9e41-770c3763602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import batch_data_support_regions as bds_reg\n",
    "import geopy.distance\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model_attributes as ma\n",
    "from attribute_table import AttributeTable\n",
    "import model_afolu as mafl\n",
    "import model_ippu as mi\n",
    "import model_circular_economy as mc\n",
    "import model_energy as me\n",
    "import model_electricity as ml\n",
    "import model_socioeconomic as se\n",
    "import setup_analysis as sa\n",
    "import sisepuede as ssp\n",
    "import support_functions as sf\n",
    "import importlib\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sql_utilities as sq\n",
    "from typing import *\n",
    "import sqlalchemy\n",
    "import sql_utilities as sqlutil\n",
    "import re\n",
    "importlib.reload(ma)\n",
    "importlib.reload(sa)\n",
    "importlib.reload(sf)\n",
    "importlib.reload(mafl)\n",
    "importlib.reload(mc)\n",
    "importlib.reload(mi)\n",
    "importlib.reload(me)\n",
    "importlib.reload(se)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e40fd-5bfc-4e44-b3e5-64f39a81c8d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  For Seasonal Variationo in Hydropower Capacity Factors, derive from global model of hydropower generation developed by Wan et al. (2021)\n",
    "\n",
    "- Wan, W., Zhao, J., Popat, E., Herbert, C., & DÃ¶ll, P. (2021). Analyzing the impact of streamflow drought on hydroelectricity production: A global-scale study. Water Resources Research, 57, e2020WR028087. https://doi.org/10.1029/2020WR028087\n",
    "\n",
    "- Code (modified to read variable \"days\" from a CSV, see below) available from \n",
    "    - https://energy.duke.edu/content/global-hydropower-database, which leads to\n",
    "    - https://figshare.com/articles/dataset/Global_Hydropower_Database_GHD_/11283758/3?file=22767863\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c03f8b17-4e82-4c52-bc94-d96c67ee3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  IMPORT SOME ATTRIBUTES, MODELS, AND SHARED VARIABLES\n",
    "\n",
    "attr_region = sa.model_attributes.dict_attributes.get(f\"{sa.model_attributes.dim_region}\")\n",
    "attr_time_period = sa.model_attributes.dict_attributes.get(f\"dim_{sa.model_attributes.dim_time_period}\")\n",
    "attr_time_slice = sa.model_attributes.dict_attributes.get(f\"time_slice\")\n",
    "\n",
    "# call variables from the electric model\n",
    "model_elec = ml.ElectricEnergy(sa.model_attributes, sa.dir_jl, sa.dir_ref_nemo, initialize_julia = False)\n",
    "\n",
    "# map each country to ISO code 3 and each code to \n",
    "dict_country_to_iso = dict((k, v.upper()) for k, v in attr_region.field_maps.get(f\"{attr_region.key}_to_iso_alpha_3\").items())\n",
    "dict_iso_to_country = sf.reverse_dict(dict_country_to_iso)\n",
    "\n",
    "\n",
    "# used in a number of places\n",
    "dict_n_days_per_month = {\n",
    "    1: 31,\n",
    "    2: 28,\n",
    "    3: 31,\n",
    "    4: 30,\n",
    "    5: 31,\n",
    "    6: 30,\n",
    "    7: 31,\n",
    "    8: 31,\n",
    "    9: 30,\n",
    "    10: 31,\n",
    "    11: 30,\n",
    "    12: 31\n",
    "}\n",
    "# weights days/month on average when only monthly data are avaiable\n",
    "dict_num_days_per_month_weights = dict((k, (v if (k != 2) else 28.25)) for k, v in dict_n_days_per_month.items())\n",
    "\n",
    "# setup some fields\n",
    "field_capacity = \"capacity_mw\"\n",
    "field_capacity_factor = \"capacity_factor\"\n",
    "field_country = \"Country\"\n",
    "field_date_string = \"date_string\"\n",
    "field_generation = \"generation_gwh\"\n",
    "field_gwp = \"max_generation_gwp\"\n",
    "field_iso = \"iso_code3\"\n",
    "field_lat_region = \"latitude_population_centroid_2020\"\n",
    "field_lon_region = \"longitude_population_centroid_2020\"\n",
    "field_key = \"GHD_ID\"\n",
    "field_month = \"month\"\n",
    "field_ndays = \"n_days\"\n",
    "field_weight_month = \"weight_month\"\n",
    "field_weight_tg1 = \"weight_tg1\"\n",
    "field_year = \"year\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  TIME GROUP MANIPULATIONS\n",
    "\n",
    "attr_tg1 = sa.model_attributes.dict_attributes.get(\"ts_group_1\")\n",
    "\n",
    "# format month/time group 1 dictionaries\n",
    "dict_tg1_to_months = dict(\n",
    "    (k, [int(x) for x in v.split(\"|\")]) for k, v in attr_tg1.field_maps.get(f\"{attr_tg1.key}_to_months\").items()\n",
    ")\n",
    "\n",
    "# map each month to the TG1\n",
    "dict_month_to_tg1 = {}\n",
    "for k in dict_tg1_to_months.keys():\n",
    "    mos = dict_tg1_to_months.get(k)\n",
    "    for m in mos:\n",
    "        dict_month_to_tg1.update({m: k})\n",
    "        \n",
    "# build within year weights for ts groups\n",
    "dict_tg1_num_days_weights = {}\n",
    "for k in attr_tg1.key_values:\n",
    "    mos = dict_tg1_to_months.get(k)\n",
    "    total = sum([dict_num_days_per_month_weights.get(x) for x in mos])\n",
    "    dict_tg1_num_days_weights.update({k: total})\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#\n",
    "#    READ DATA FROM Wan et al. Package and monthly results file, \"Plant_monthly_V1.csv\"\n",
    "# \n",
    "\n",
    "dir_data = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/wan_et_al_hydro_model/11283758\"\n",
    "dfs_power_plants = pd.read_excel(os.path.join(dir_data, \"Plant_Database.xlsx\"), sheet_name = \"2 GHD with estimations\")\n",
    "df_generated_simulated = pd.read_csv(os.path.join(dir_data, \"Plant_monthly_V1.csv\"), low_memory = False)\n",
    "\n",
    "\n",
    "##  Note: Had to overwrite \"days\" variable since dayseries() function called in `HP_model.R` does not seem to exist. \n",
    "## The following code shows the creation of that series (also called in this notebook)\n",
    "df_days_per_month = []\n",
    "n_y = 41\n",
    "y_0 = 1975\n",
    "\n",
    "for y in range(y_0, y_0 + n_y + 1):\n",
    "    for m in range(1, 13):\n",
    "        n_day = 29 if ((y%4 == 0) and (m == 2)) else dict_n_days_per_month.get(m)\n",
    "        df_days_per_month.append([y, m, n_day])\n",
    "\n",
    "df_days_per_month = pd.DataFrame(df_days_per_month, columns = [\"year\", \"month\", \"n_days\"])\n",
    "df_days_per_month.to_csv(os.path.join(dir_data, \"n_days.csv\"), index = None, encoding = \"UTF-8\")\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "#    SOME USED FUNCTIONS    #\n",
    "#############################\n",
    "\n",
    "def get_closest_region(\n",
    "    region: str,\n",
    "    attr_region: AttributeTable, \n",
    "    field_iso: str = \"iso_alpha_3\",\n",
    "    field_lat: str = \"latitude_population_centroid_2020\",\n",
    "    field_lon: str = \"longitude_population_centroid_2020\",\n",
    "    missing_flag: float = -999,\n",
    "    regions_valid: Union[List[str], None] = None,\n",
    "    type_input: str = \"region\",\n",
    "    type_return: str = \"region\",\n",
    ") -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Based on latitude/longitude of population centers, find the \n",
    "        closest neighboring region.\n",
    "    \n",
    "    \n",
    "    Function Arguments\n",
    "    ------------------\n",
    "    - region: region to search for closest neighbor\n",
    "    - attr_region: attribute table for regions\n",
    "    \n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    - field_iso: iso field in attr_regin\n",
    "    - field_lat: field storing latitude\n",
    "    - field_lon: field storing longitude\n",
    "    - missing_flag: flag indicating a missing value\n",
    "    - regions_valid: optional list of regions to restrict search to. If None,\n",
    "        searches through all regions specified in attr_region\n",
    "    - type_input: input region type. Either \"region\" or \"iso\"\n",
    "    - type_return: return type. Either \"region\" or \"iso\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ##  INITIALIZATION\n",
    "    \n",
    "    type_return = \"region\" if (type_return not in [\"region\", \"iso\"]) else type_return\n",
    "    type_input = \"region\" if (type_input not in [\"region\", \"iso\"]) else type_input\n",
    "    \n",
    "    # get some dictionaries\n",
    "    dict_region_to_lat = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_lat}\")\n",
    "    dict_region_to_lon = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_lon}\")\n",
    "    dict_iso_to_region = attr_region.field_maps.get(f\"{field_iso}_to_{attr_region.key}\")\n",
    "    dict_region_to_iso = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_iso}\")\n",
    "    \n",
    "    # check region/lat/lon\n",
    "    region = dict_iso_to_region.get(region) if (type_input == \"iso\") else region\n",
    "    region = region if (region in attr_region.key_values) else None\n",
    "    lat, lon = dict_region_to_lat.get(region), dict_region_to_lon.get(region)\n",
    "    \n",
    "    # return None if one of the dimensions is missing\n",
    "    if (lat is None) or (lon is None) or (region is None):\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ##  FILTER TABLE AND APPLY DISTANCES\n",
    "    \n",
    "    if (regions_valid is None):\n",
    "        regions_valid = attr_region.key_values \n",
    "    else:\n",
    "        regions_valid = (\n",
    "            [x for x in attr_region.key_values if x in (regions_valid)]\n",
    "            if type_input == \"region\"\n",
    "            else [x for x in attr_region.key_values if dict_region_to_iso.get(x) in (regions_valid)]\n",
    "        )\n",
    "        \n",
    "    df_regions = attr_region.table[\n",
    "        attr_region.table[attr_region.key].isin(regions_valid)\n",
    "    ].copy().reset_index(drop = True)\n",
    "    \n",
    "    # function to apply\n",
    "    def f(tup: Tuple[float, float]) -> float:\n",
    "        y, x = tuple(tup)\n",
    "        \n",
    "        out = (\n",
    "            -1.0\n",
    "            if (min(y, lat) < -90) or (max(y, lat) > 90) or (min(x, lon) < -180) or (max(x, lon) > 180)\n",
    "            else geopy.distance.geodesic((lat, lon), (y, x)).km\n",
    "        )\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "    vec_dists = np.array(df_regions[[field_lat, field_lon]].apply(f, raw = True, axis = 1))\n",
    "    valid_dists = vec_dists[vec_dists > 0.0]\n",
    "    out = None\n",
    "    \n",
    "    if len(valid_dists) > 0:\n",
    "\n",
    "        m = min(vec_dists)\n",
    "        w = np.where(vec_dists == m)[0]\n",
    "\n",
    "        out = (\n",
    "            list(df_regions[attr_region.key])[w[0]]\n",
    "            if len(w) > 0\n",
    "            else None\n",
    "        )\n",
    "        out = dict_region_to_iso.get(out) if (type_return == \"iso\") else out\n",
    "\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ccbd2-68e4-4649-8813-3e19213b8458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "42f6902a-25c4-4ca0-9ac5-7bf872432afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  CONVERT SIMULATIONS TO LONG FILE\n",
    "\n",
    "\n",
    "regex_match_dates = re.compile(\"(\\d*)-(\\d*)\")\n",
    "cat_name_hydro = \"pp_hydropower\"\n",
    "cat_name_solar = \"pp_solar\"\n",
    "\n",
    "\n",
    "def format_cf(cf:str, field_prepend: str = field_capacity_factor) -> str:\n",
    "    return f\"{field_prepend}_{cf}\"\n",
    "\n",
    "\n",
    "fields_date = [x for x in df_generated_simulated.columns if regex_match_dates.match(x) is not None]\n",
    "\n",
    "# total generation (GWh--see script) per plant\n",
    "df_generated = pd.melt(\n",
    "    df_generated_simulated[[field_key, field_country, \"Install_Act\"] + fields_date],\n",
    "    [field_key, field_country, \"Install_Act\"],\n",
    "    fields_date,\n",
    "    var_name = \"date_string\",\n",
    "    value_name = field_generation\n",
    ").rename(columns = {\"Install_Act\": field_capacity})\n",
    "\n",
    "\n",
    "##  CLEAN DATES TO PREPARE AGGREGATION\n",
    "\n",
    "# function to convert date columns to paired year/month\n",
    "def ds_to_date(\n",
    "    ds: str,\n",
    "    regex_check: re.Pattern = regex_match_dates\n",
    ") -> Tuple[int, int]:\n",
    "    \n",
    "    out = (\n",
    "        tuple([int(x) for x in ds.split(\"-\")])\n",
    "        if regex_check.match(str(ds)) is not None\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    return out\n",
    "\n",
    "df_year_month = pd.DataFrame(list(df_generated[field_date_string].apply(ds_to_date)), columns = [field_year, field_month])\n",
    "df_generated = pd.concat([df_generated, df_year_month], axis = 1).drop([field_date_string], axis = 1)\n",
    "df_generated = pd.merge(df_generated, df_days_per_month)\n",
    "\n",
    "# add potential\n",
    "df_generated[field_gwp] = np.array(df_generated[field_capacity])*np.array(df_generated[field_ndays])*24/1000\n",
    "\n",
    "\n",
    "\n",
    "##  FIRST AGGREGATION -- TOTAL GENERATION/GENERATION POTENTIAL BY COUNTRY, YEAR, AND MONTH\n",
    "\n",
    "fields_group = [field_country, field_year, field_month]\n",
    "fields_agg = [field_generation, field_gwp]\n",
    "dict_agg = dict((x, \"first\") for x in fields_group)\n",
    "dict_agg.update(dict((x, \"sum\") for x in fields_agg))\n",
    "\n",
    "# aggregate, then add an estimated capacity factor\n",
    "df_generated_by_country = df_generated[list(dict_agg.keys())].groupby(fields_group).agg(dict_agg).reset_index(drop = True)\n",
    "df_generated_by_country[format_cf(cat_name_hydro)] = np.array(df_generated_by_country[field_generation])/np.array(df_generated_by_country[field_gwp])\n",
    "\n",
    "\n",
    "##  SECOND AGGREGATION -- MEAN CAPACITYFACTOR BY COUNTRY AND MONTH\n",
    "\n",
    "# number of most recent years to keep \n",
    "n_years_keep = 20\n",
    "\n",
    "fields_group = [field_country, field_month]\n",
    "fields_agg = [format_cf(cat_name_hydro)]\n",
    "dict_agg = dict((x, \"first\") for x in fields_group)\n",
    "dict_agg.update(dict((x, \"mean\") for x in fields_agg))\n",
    "\n",
    "df_gen_for_averages_init = df_generated_by_country.groupby(fields_group)\n",
    "df_gen_for_averages = []\n",
    "\n",
    "for df in df_gen_for_averages_init:\n",
    "    i, df = df\n",
    "    yr_max = max(df[field_year])\n",
    "    yr_min = min(df[field_year])\n",
    "    \n",
    "    year_range = list(range(max(yr_max - n_years_keep + 1, yr_min), yr_max))\n",
    "    \n",
    "    df_gen_for_averages.append(df[df[field_year].isin(year_range)])\n",
    "\n",
    "    \n",
    "##  GET HYDROPOWER CAPACITY FACTOR ESTIMATES\n",
    "\n",
    "df_capacity_factor_hydro = pd.concat(df_gen_for_averages, axis = 0).groupby(fields_group).agg(dict_agg).reset_index(drop = True)\n",
    "df_capacity_factor_hydro[field_country] = [x.lower().replace(\" \", \"_\") for x in df_capacity_factor_hydro[field_country]]\n",
    "df_capacity_factor_hydro[field_country].replace(dict_country_to_iso, inplace = True)\n",
    "df_capacity_factor_hydro.rename(columns = {field_country: field_iso}, inplace = True)\n",
    "\n",
    "# filter out countries \n",
    "df_capacity_factor_hydro = df_capacity_factor_hydro[\n",
    "    df_capacity_factor_hydro[field_iso].isin(dict_country_to_iso.values())\n",
    "].reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "#    FORMAT FOR TIME SLICING    #\n",
    "#################################\n",
    "\n",
    "\n",
    "# adjust fields\n",
    "df_capacity_factor_hydro_by_tg1 = df_capacity_factor_hydro.copy()\n",
    "df_capacity_factor_hydro_by_tg1[model_elec.field_nemomod_tg1] = df_capacity_factor_hydro_by_tg1[field_month].replace(dict_month_to_tg1)\n",
    "\n",
    "# add weights for aggregation\n",
    "df_capacity_factor_hydro_by_tg1[field_weight_month] = df_capacity_factor_hydro_by_tg1[field_month].replace(dict_num_days_per_month_weights)\n",
    "df_capacity_factor_hydro_by_tg1[field_weight_tg1] = df_capacity_factor_hydro_by_tg1[model_elec.field_nemomod_tg1].replace(dict_tg1_num_days_weights)\n",
    "df_capacity_factor_hydro_by_tg1[format_cf(cat_name_hydro)] = np.array(\n",
    "    df_capacity_factor_hydro_by_tg1[format_cf(cat_name_hydro)]\n",
    ")*np.array(\n",
    "    df_capacity_factor_hydro_by_tg1[field_weight_month]\n",
    ")/np.array(df_capacity_factor_hydro_by_tg1[field_weight_tg1])\n",
    "\n",
    "\n",
    "df_cf_avg_hydro_by_tg = sf.simple_df_agg(\n",
    "    df_capacity_factor_hydro_by_tg1,\n",
    "    [field_iso, model_elec.field_nemomod_tg1],\n",
    "    {format_cf(cat_name_hydro): \"sum\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  NEXT, COMBINE SEASONAL VARIATION WITH ANNUAL CAPACITY FACTORS TO ESTIMATE CAPACITY FACTORS BY TIME SLICE\n",
    "\n",
    "# get hydro CF by region/tg1\n",
    "df_cf_hydro_by_ts = pd.merge(\n",
    "    attr_time_slice.table.copy().drop([\"description\"], axis = 1),\n",
    "    df_cf_avg_hydro_by_tg,\n",
    "    how = \"outer\"\n",
    ")[[field_iso, attr_time_slice.key, format_cf(cat_name_hydro)]].sort_values(by = [field_iso, attr_time_slice.key])\n",
    "\n",
    "\n",
    "# fill in missing regions\n",
    "missing_regions = sorted(list(set(dict_iso_to_country.keys()) - set(df_cf_hydro_by_ts[field_iso])))\n",
    "\n",
    "# use closest neighbor (by population) if unavailable\n",
    "if len(missing_regions) > 0:\n",
    "    \n",
    "    df_append = [df_cf_hydro_by_ts]\n",
    "    \n",
    "    for region in missing_regions:\n",
    "        \n",
    "        iso_closest = get_closest_region(\n",
    "            region,\n",
    "            attr_region,\n",
    "            regions_valid = list(set(df_cf_hydro_by_ts[field_iso])),\n",
    "            type_input = \"iso\",\n",
    "            type_return = \"iso\"\n",
    "        )\n",
    "        \n",
    "        if iso_closest is not None:\n",
    "\n",
    "            # fill in missing\n",
    "            df_cur = df_cf_hydro_by_ts[\n",
    "                df_cf_hydro_by_ts[field_iso] == iso_closest\n",
    "            ].copy().reset_index(drop = True)\n",
    "            df_cur[field_iso] = region\n",
    "\n",
    "            df_append.append(df_cur)\n",
    "        \n",
    "    df_cf_hydro_by_ts = pd.concat(df_append).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "# finally, format for input table\n",
    "df_cf_hydro_by_ts[field_iso].replace(dict_iso_to_country, inplace = True)\n",
    "df_cf_hydro_by_ts.rename(columns = {\n",
    "        field_iso: model_elec.field_nemomod_region,\n",
    "        format_cf(cat_name_hydro): cat_name_hydro,\n",
    "        attr_time_slice.key: model_elec.field_nemomod_time_slice\n",
    "    },\n",
    "    inplace = True\n",
    ")\n",
    "df_cf_hydro_by_ts.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3fb68b-1c01-4309-bd7d-d1a56b3250b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6a606c6-cb92-4eea-a4f1-f9b3db0df188",
   "metadata": {},
   "source": [
    "##  Next, generate Solar Capacity Factors from World Bank/Solar Atlas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "da6cf8ff-ea9c-4e7f-852e-1f542ba7a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_data = pd.read_excel(\n",
    "    \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/solargis_pvpotential_countryranking_2020_data.xlsx\", \n",
    "    sheet_name = \"Monthly data\", \n",
    "    skiprows = [0]\n",
    ")\n",
    "\n",
    "dict_month_nm_to_num = {\n",
    "    \"January\": 1,\n",
    "    \"February\": 2,\n",
    "    \"March\": 3,\n",
    "    \"April\": 4,\n",
    "    \"May\": 5,\n",
    "    \"June\": 6,\n",
    "    \"July\": 7,\n",
    "    \"August\": 8,\n",
    "    \"September\": 9,\n",
    "    \"October\": 10,\n",
    "    \"November\": 11,\n",
    "    \"December\": 12\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  CLEAN AND REFORMAT\n",
    "\n",
    "dict_rnm = {\"ISO_A3\": field_iso}\n",
    "    \n",
    "df_capacity_factor_solar = df_solar_data[[\"ISO_A3\"] + list(dict_month_nm_to_num.keys())].rename(columns = dict_rnm)\n",
    "df_capacity_factor_solar = df_capacity_factor_solar.melt(\n",
    "    [field_iso],\n",
    "    list(dict_month_nm_to_num.keys()),\n",
    "    var_name = field_month,\n",
    "    value_name = format_cf(cat_name_solar)\n",
    ")\n",
    "\n",
    "# adjust fields\n",
    "df_capacity_factor_solar[field_month].replace(dict_month_nm_to_num, inplace = True)\n",
    "df_capacity_factor_solar[format_cf(cat_name_solar)] /= 24\n",
    "df_capacity_factor_solar[model_elec.field_nemomod_tg1] = df_capacity_factor_solar[field_month].replace(dict_month_to_tg1)\n",
    "\n",
    "# add weights for aggregation\n",
    "df_capacity_factor_solar[field_weight_month] = df_capacity_factor_solar[field_month].replace(dict_num_days_per_month_weights)\n",
    "df_capacity_factor_solar[field_weight_tg1] = df_capacity_factor_solar[model_elec.field_nemomod_tg1].replace(dict_tg1_num_days_weights)\n",
    "df_capacity_factor_solar[format_cf(cat_name_solar)] = np.array(\n",
    "    df_capacity_factor_solar[format_cf(cat_name_solar)]\n",
    ")*np.array(\n",
    "    df_capacity_factor_solar[field_weight_month]\n",
    ")/np.array(df_capacity_factor_solar[field_weight_tg1])\n",
    "\n",
    "\n",
    "df_cf_avg_solar_by_tg = sf.simple_df_agg(\n",
    "    df_capacity_factor_solar,\n",
    "    [field_iso, model_elec.field_nemomod_tg1],\n",
    "    {format_cf(cat_name_solar): \"sum\"}\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#################################################################################################\n",
    "#   READ IN SOLAR HOUR GROUP FACTOR SCALARS BY CAPACTITY FACTOR REGION (THESE ARE TEMPORARY)    #\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "dict_cf_region_to_sheet = dict(\n",
    "    (x, f\"cfs_solar_hour_group_{x.lower()}\")\n",
    "    for x in list(set(dict_iso_to_cf_region.values()))\n",
    ")\n",
    "df_solar_factor_by_season = pd.read_excel(\n",
    "    \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/capacity_factor_esitmation_tables.xlsx\", \n",
    "    sheet_name = None\n",
    ")\n",
    "\n",
    "dict_cf_region_to_solar_factor_by_tg1 = dict((cfr, df_solar_factor_by_season.get(dict_cf_region_to_sheet.get(cfr))) for cfr in dict_cf_region_to_sheet.keys())\n",
    "\n",
    "# set some shared fields\n",
    "field_cfs = \"cf_scalar\"\n",
    "field_hour = \"hour\"\n",
    "field_hour_group = \"hour_group\"\n",
    "field_time_of_day = \"time_of_day\"\n",
    "field_weight = \"weight\"\n",
    "\n",
    "\n",
    "# set up the regular expression to match hour groups on\n",
    "def regex_by_hour_group(\n",
    "    hour_group: int\n",
    ") -> Union[str, None]:\n",
    "    return re.compile(f\"(\\D*)w(\\D*){hour_group}$\")\n",
    "\n",
    "# map time slices to hour group\n",
    "all_hour_groups = sorted(list(\n",
    "    set(\n",
    "        dict_cf_region_to_solar_factor_by_tg1.get(list(dict_cf_region_to_solar_factor_by_tg1.keys())[0])[field_hour_group]\n",
    "    )\n",
    "))\n",
    "dict_time_slice_to_hour_group = {}\n",
    "for hg in all_hour_groups:\n",
    "    regex = regex_by_hour_group(hg)\n",
    "    for time_slice in attr_time_slice.key_values:\n",
    "        if regex.match(time_slice) is not None:\n",
    "            dict_time_slice_to_hour_group.update({time_slice: hg})\n",
    "\n",
    "\n",
    "# initialize the output in terms of hour group\n",
    "df_cf_avg_solar_by_hour_group_base = attr_time_slice.table.copy().drop([\"description\"], axis = 1)\n",
    "df_cf_avg_solar_by_hour_group_base[field_hour_group] = df_cf_avg_solar_by_hour_group_base[attr_time_slice.key].replace(dict_time_slice_to_hour_group)\n",
    "\n",
    "    \n",
    "##  GET BASELINE DAILY CAPACITY FACTOR SCALARS BY CAPACITY FACTOR REGION\n",
    "\n",
    "\n",
    "dict_cf_region_to_solar_factor_by_tg1_agg = {}\n",
    "for cfr in dict_cf_region_to_solar_factor_by_tg1.keys():\n",
    "    \n",
    "    # get map of region to CF Scalar\n",
    "    df_solar_factor_by_season = dict_cf_region_to_solar_factor_by_tg1.get(cfr)\n",
    "    \n",
    "    df_solar_factor_by_season_agg = df_solar_factor_by_season.drop([field_hour, field_time_of_day], axis = 1).melt(\n",
    "        [field_hour_group],\n",
    "        attr_tg1.key_values,\n",
    "        var_name = model_elec.field_nemomod_tg1\n",
    "    )\n",
    "    \n",
    "    df_solar_factor_by_season_agg = sf.simple_df_agg(\n",
    "        df_solar_factor_by_season_agg,\n",
    "        [field_hour_group, model_elec.field_nemomod_tg1],\n",
    "        \"mean\",\n",
    "        fields_agg = [\"value\"]\n",
    "    )\n",
    "    \n",
    "    # merge into \n",
    "    df_solar_factor_by_season_agg = pd.merge(\n",
    "        df_cf_avg_solar_by_hour_group_base,\n",
    "        df_solar_factor_by_season_agg.rename(columns = {\"value\": field_cfs}),\n",
    "        how = \"left\"\n",
    "    )\n",
    "   \n",
    "    dict_cf_region_to_solar_factor_by_tg1_agg.update({cfr: df_solar_factor_by_season_agg})\n",
    "\"\"\";\n",
    "    \n",
    "    \n",
    "##  NEXT, COMBINE SEASONAL VARIATION WITH ANNUAL CAPACITY FACTORS TO ESTIMATE CAPACITY FACTORS BY TIME SLICE\n",
    "\n",
    "df_cf_solar_by_ts = []\n",
    "df_cf_solar_by_ts_wide = None\n",
    "\n",
    "# initialize the output in terms of hour group\n",
    "df_cf_avg_solar_by_hour_group_base = attr_time_slice.table.copy().drop([\"description\"], axis = 1)\n",
    "df_cf_avg_solar_by_hour_group_base[field_hour_group] = df_cf_avg_solar_by_hour_group_base[attr_time_slice.key].replace(dict_time_slice_to_hour_group)\n",
    "\n",
    "\n",
    "# \n",
    "for region in dict_iso_to_country.keys():   \n",
    "    \n",
    "    df_cf_avg_solar_by_tg_cur = df_cf_avg_solar_by_tg[df_cf_avg_solar_by_tg[field_iso] == region]\n",
    "    country = dict_iso_to_country.get(region)\n",
    "    \n",
    "    \n",
    "    ##  GET SOLAR SCALARS REPRESENTING MAXIMUM SOLAR IRRADIANCE BY TIME \n",
    "    \n",
    "    # build the solar region object\n",
    "    cur = list(\n",
    "        attr_region.table[\n",
    "            attr_region.table[attr_region.key] == country\n",
    "        ][[field_iso, field_lat_region, field_lon_region]].iloc[0]\n",
    "    )\n",
    "    region_solar_obj = bds_reg.region_solar(*cur)\n",
    "    \n",
    "    # get the dataframe and do a little bit of reshaping\n",
    "    df_solar_factor_by_season = region_solar_obj.build_solar_cf_seasonal_component_by_hour(sa.model_attributes)\n",
    "    df_solar_factor_by_season_agg = df_solar_factor_by_season.drop([field_hour], axis = 1).melt(\n",
    "        [field_hour_group],\n",
    "        attr_tg1.key_values,\n",
    "        var_name = model_elec.field_nemomod_tg1\n",
    "    )\n",
    "    \n",
    "    df_solar_factor_by_season_agg = sf.simple_df_agg(\n",
    "        df_solar_factor_by_season_agg,\n",
    "        [field_hour_group, model_elec.field_nemomod_tg1],\n",
    "        \"mean\",\n",
    "        fields_agg = [\"value\"]\n",
    "    )\n",
    "    \n",
    "    # merge into \n",
    "    df_solar_factor_by_season_agg = pd.merge(HEREHERE\n",
    "        df_cf_avg_solar_by_hour_group_base,\n",
    "        df_solar_factor_by_season_agg.rename(columns = {\"value\": field_cfs}),\n",
    "        how = \"left\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cf_region is not None:\n",
    "        \n",
    "        df_cf_with_cf_scalar = pd.merge(\n",
    "            dict_cf_region_to_solar_factor_by_tg1_agg.get(cf_region),\n",
    "            df_cf_avg_solar_by_tg_cur,\n",
    "            how = \"left\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "        ##  CALCULATE SCALAR TO APPLY TO \n",
    "        dfs_group = df_cf_with_cf_scalar.groupby([model_elec.field_nemomod_tg1])\n",
    "        \n",
    "\n",
    "        df_cf_solar_by_ts_by_region = []\n",
    "        for df in dfs_group:\n",
    "            i, df = df\n",
    "\n",
    "            vec_weight = np.array(df[field_weight])\n",
    "            vec_scalar = np.array(df[field_cfs])\n",
    "            vec_cf = np.array(df[format_cf(cat_name_solar)])\n",
    "\n",
    "            # target average capacity factor for this tg1\n",
    "            target = vec_cf[0]\n",
    "\n",
    "            vec_total = vec_weight*(vec_scalar * vec_cf)/vec_weight.sum()\n",
    "            scalar = target/vec_total.sum()\n",
    "\n",
    "            # up capacity factor\n",
    "            vec_cf_new = sf.vec_bounds(vec_scalar * vec_cf * scalar, (0, 1.0))\n",
    "\n",
    "            df_add = df[[attr_time_slice.key]].copy()\n",
    "            df_add[format_cf(cat_name_solar)] = vec_cf_new\n",
    "            \n",
    "            df_cf_solar_by_ts_by_region.append(df_add)\n",
    "            \n",
    "        df_cf_solar_by_ts_by_region = pd.concat(df_cf_solar_by_ts_by_region, axis = 0).reset_index(drop = True)\n",
    "        df_cf_solar_by_ts_by_region[attr_region.key] = region\n",
    "        \n",
    "    # append to long data frame and add to wide data frame, used to generate regional average\n",
    "    df_cf_solar_by_ts.append(df_cf_solar_by_ts_by_region)\n",
    "\n",
    "# get solar cf by time slice (tg1) for all available regions--if unavailable, default to \"cf region\" average\n",
    "df_cf_solar_by_ts = pd.concat(df_cf_solar_by_ts, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "##  GET CF_REGION AVERAGES \n",
    "\n",
    "df_cf_solar_by_ts_cfr_avg = df_cf_solar_by_ts.copy()\n",
    "df_cf_solar_by_ts_cfr_avg[\"cfr\"] = df_cf_solar_by_ts_cfr_avg[attr_region.key].replace(dict_iso_to_cf_region)\n",
    "\n",
    "df_cf_solar_by_ts_cfr_avg = sf.simple_df_agg(\n",
    "    df_cf_solar_by_ts_cfr_avg,\n",
    "    [attr_time_slice.key, \"cfr\"],\n",
    "    \"mean\",\n",
    "    fields_agg = [format_cf(cat_name_solar)]\n",
    ")\n",
    "\n",
    "\n",
    "missing_regions = sorted(list(set(dict_iso_to_country.keys()) - set(df_cf_solar_by_ts[attr_region.key])))\n",
    "if len(missing_regions) > 0:\n",
    "    \n",
    "    df_append = [df_cf_solar_by_ts]\n",
    "    \n",
    "    for cfr in missing_regions:\n",
    "        \n",
    "        # fill in missing\n",
    "        country = dict_iso_to_country.get(cfr)\n",
    "        cf_region = dict_country_to_cf_region.get(country)\n",
    "\n",
    "        df_cur = df_cf_solar_by_ts_cfr_avg[\n",
    "            df_cf_solar_by_ts_cfr_avg[\"cfr\"] == cf_region\n",
    "        ].reset_index(drop = True)\n",
    "\n",
    "        df_cur[attr_region.key] = cfr\n",
    "\n",
    "        df_append.append(df_cur.drop(\"cfr\", axis = 1))\n",
    "        \n",
    "    df_cf_solar_by_ts = pd.concat(df_cf_solar_by_ts).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "# finally, format for input table\n",
    "df_cf_solar_by_ts[attr_region.key].replace(dict_iso_to_country, inplace = True)\n",
    "df_cf_solar_by_ts.rename(columns = { \n",
    "        attr_region.key: model_elec.field_nemomod_region,\n",
    "        format_cf(cat_name_solar): cat_name_solar,\n",
    "        attr_time_slice.key: model_elec.field_nemomod_time_slice\n",
    "    },\n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9805a4e-ee85-49fe-9521-8472a305fdb8",
   "metadata": {},
   "source": [
    "##  Get other, constant Capacity Factors\n",
    "- 2008-2012 regional averages by technology:\n",
    "    - https://www.eia.gov/todayinenergy/detail.php?id=22832\n",
    "- additional information on Ocean from https://www.nrel.gov/analysis/tech-cap-factor.html\n",
    "- use https://www.pnas.org/doi/10.1073/pnas.2205429119 for other generation sources (biomass, wind, geothermal, fossil, nuclear)\n",
    "- Assume 0.5 in absence of other information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1ca6ea83-c2c6-4051-91d3-094b1f349fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>region</th>\n",
       "      <th>iso_alpha_3</th>\n",
       "      <th>fao_area_code</th>\n",
       "      <th>latitude_population_centroid_2020</th>\n",
       "      <th>longitude_population_centroid_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2</td>\n",
       "      <td>34.612592</td>\n",
       "      <td>67.507387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>3</td>\n",
       "      <td>41.206902</td>\n",
       "      <td>19.858921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>4</td>\n",
       "      <td>35.524570</td>\n",
       "      <td>3.494062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>american_samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>5</td>\n",
       "      <td>-14.309417</td>\n",
       "      <td>-170.690438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>6</td>\n",
       "      <td>42.524074</td>\n",
       "      <td>1.562281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>VEN</td>\n",
       "      <td>236</td>\n",
       "      <td>9.748997</td>\n",
       "      <td>-67.934095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>viet_nam</td>\n",
       "      <td>VNM</td>\n",
       "      <td>237</td>\n",
       "      <td>15.441861</td>\n",
       "      <td>106.418389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>yemen</td>\n",
       "      <td>YEM</td>\n",
       "      <td>249</td>\n",
       "      <td>14.735593</td>\n",
       "      <td>44.434270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>251</td>\n",
       "      <td>-13.593902</td>\n",
       "      <td>28.635402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>181</td>\n",
       "      <td>-18.652425</td>\n",
       "      <td>30.618165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category_name          region iso_alpha_3  fao_area_code  \\\n",
       "0       Afghanistan     afghanistan         AFG              2   \n",
       "1           Albania         albania         ALB              3   \n",
       "2           Algeria         algeria         DZA              4   \n",
       "3    American Samoa  american_samoa         ASM              5   \n",
       "4           Andorra         andorra         AND              6   \n",
       "..              ...             ...         ...            ...   \n",
       "211       Venezuela       venezuela         VEN            236   \n",
       "212        Viet Nam        viet_nam         VNM            237   \n",
       "213           Yemen           yemen         YEM            249   \n",
       "214          Zambia          zambia         ZMB            251   \n",
       "215        Zimbabwe        zimbabwe         ZWE            181   \n",
       "\n",
       "     latitude_population_centroid_2020  longitude_population_centroid_2020  \n",
       "0                            34.612592                           67.507387  \n",
       "1                            41.206902                           19.858921  \n",
       "2                            35.524570                            3.494062  \n",
       "3                           -14.309417                         -170.690438  \n",
       "4                            42.524074                            1.562281  \n",
       "..                                 ...                                 ...  \n",
       "211                           9.748997                          -67.934095  \n",
       "212                          15.441861                          106.418389  \n",
       "213                          14.735593                           44.434270  \n",
       "214                         -13.593902                           28.635402  \n",
       "215                         -18.652425                           30.618165  \n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_region.table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "02b9cc87-d808-4a5f-8325-e6099c0d528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_tech = sa.model_attributes.dict_attributes.get(\"cat_technology\")\n",
    "dict_techs_to_capacity_factors = {\n",
    "    \"pp_biogas\": 0.5,\n",
    "    \"pp_biomass\": 0.37,\n",
    "    \"pp_coal\": 0.36,\n",
    "    #\"pp_coal_ccs\": 0.36,\n",
    "    \"pp_gas\": 0.36,\n",
    "    #\"pp_gas_ccs\": 0.36,\n",
    "    \"pp_geothermal\": 0.67,\n",
    "    \"pp_nuclear\": 0.8,\n",
    "    \"pp_ocean\": 0.25,\n",
    "    \"pp_oil\": 0.36,\n",
    "    \"pp_waste_incineration\": 0.5,\n",
    "    \"pp_wind\": 0.26\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ce3b2-1221-40c6-9649-7a8c2fe2a308",
   "metadata": {},
   "source": [
    "##  Build full dataframe of capacity factor inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "ce05c1ba-12c2-4d45-a1bf-37516b5aab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build full\n",
    "df_capacity_factor = pd.merge(\n",
    "    df_cf_hydro_by_ts,\n",
    "    df_cf_solar_by_ts\n",
    ")\n",
    "\n",
    "for k in dict_techs_to_capacity_factors.keys():\n",
    "    df_capacity_factor[k] = dict_techs_to_capacity_factors.get(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "0604851b-f614-431d-b0bd-983d15e9a6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_capacity_factor.to_csv(\n",
    "    sa.dict_fp_csv_nemomod.get(\"CapacityFactor\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5cf84-aea9-4ad8-9cfb-5114067976e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ad6cd-71e7-4c34-b4a9-d63f512a9d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8405d-a0c3-4318-b677-ecfb20c5b57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c90e56c0-2897-43c0-947c-f353a793fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build capacity factors by country\n",
    "\n",
    "df_capacity_factor_base = pd.read_csv(sa.dict_fp_csv_nemomod.get(\"CapacityFactor\"));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92149e42-028e-4c80-9998-452cf23d52fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcea657-0b61-42e2-8766-3da45966eb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207511b6-2942-4cc6-bf79-4eca9ddd0227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede002ea-9f50-41f2-9784-4e3dafd747a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
