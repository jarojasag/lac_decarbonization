{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6aa3ef-b372-4798-812e-676283b0a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (DEBUG)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from model_attributes import *\n",
    "import model_attributes as ma\n",
    "from attribute_table import AttributeTable\n",
    "import model_afolu as mafl\n",
    "import model_ippu as mi\n",
    "import model_circular_economy as mc\n",
    "import model_energy as me\n",
    "import model_socioeconomic as se\n",
    "from model_socioeconomic import Socioeconomic\n",
    "import setup_analysis as sa\n",
    "import support_functions as sf\n",
    "import importlib\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union\n",
    "import inspect\n",
    "import ingestion as ing\n",
    "import logging\n",
    "from sisepuede_file_structure import *\n",
    "\n",
    "\n",
    "importlib.reload(ma)\n",
    "importlib.reload(sa)\n",
    "importlib.reload(sf)\n",
    "importlib.reload(mafl)\n",
    "importlib.reload(mc)\n",
    "importlib.reload(mi)\n",
    "importlib.reload(me)\n",
    "importlib.reload(se)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sisepuede as ssp\n",
    "def _setup_logger(namespace: str, fn_out: Union[str, None] = None) -> None:\n",
    "    global logger\n",
    "    \n",
    "    format_str = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    # configure\n",
    "    if fn_out is not None:\n",
    "        logging.basicConfig(\n",
    "            filename = fn_out,\n",
    "            filemode = \"w\",\n",
    "            format = format_str,\n",
    "            level = logging.DEBUG\n",
    "        )\n",
    "    else:\n",
    "        logging.basicConfig(\n",
    "            format = format_str,\n",
    "            level = logging.DEBUG\n",
    "        )\n",
    "        \n",
    "    logger = logging.getLogger(namespace)\n",
    "    # create console handler and set level to debug\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    # create formatter\n",
    "    formatter = logging.Formatter(format_str)\n",
    "    # add formatter to ch\n",
    "    ch.setFormatter(formatter)\n",
    "    # add ch to logger\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    return logger\n",
    "\n",
    "_setup_logger(__name__, os.path.join(os.getcwd(), \"log_temp.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "750d804b-0738-4ecc-9c19-be9bc1349744",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#   LOAD INPUT TABLES    #\n",
    "##########################\n",
    "\n",
    "##  setup location of calibrated files by sector\n",
    "\n",
    "df_fake_data = pd.read_csv(os.path.join(sa.dir_ref, \"fake_data\", \"fake_data_complete.csv\"))\n",
    "dir_calibs = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/calibrated_input_files_from_edmundo\"\n",
    "dict_calibration_file_paths = {\n",
    "    \"af\": os.path.join(dir_calibs, \"af\", \"data_complete_future_2022_09_30_test_updated.csv\"),\n",
    "    \"ce\": os.path.join(dir_calibs, \"ce\", \"data_complete_future_2022_12_13_test.csv\"),\n",
    "    \"en\": os.path.join(dir_calibs, \"en\", \"data_complete_future_2023_02_24_with_transformations.csv\"),#\"data_complete_future_2022_12_09_test.csv\"),\n",
    "    \"ip\": os.path.join(dir_calibs, \"ip\", \"data_ippu_2023_02_07_fixed.csv\"),\n",
    "    # use most recent for socioeconomic\n",
    "    \"se\": os.path.join(dir_calibs, \"en\", \"data_complete_future_2022_12_09_test.csv\")\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "###\n",
    "###    TEMPORARY APPROACH! 20230220\n",
    "###\n",
    "dict_calibration_file_paths = {\n",
    "    \"af\": os.path.join(dir_calibs, \"all\", \"datos_calibrados_20230221_with_transformations.csv\"),\n",
    "    \"ce\": os.path.join(dir_calibs, \"all\", \"datos_calibrados_20230221_with_transformations.csv\"),\n",
    "    \"en\": os.path.join(dir_calibs, \"all\", \"datos_calibrados_20230221_with_transformations.csv\"),#\"data_complete_future_2022_12_09_test.csv\"),\n",
    "    \"ip\": os.path.join(dir_calibs, \"all\", \"datos_calibrados_20230221_with_transformations.csv\"),\n",
    "    # use most recent for socioeconomic\n",
    "    \"se\": os.path.join(dir_calibs, \"all\", \"datos_calibrados_20230221_with_transformations.csv\")\n",
    "}\n",
    "\"\"\";\n",
    "\n",
    "# initialize \n",
    "all_regions = None\n",
    "dict_isos = {}\n",
    "dict_calibration_tables = {}\n",
    "dict_replace_iso = sa.model_attributes.dict_attributes.get(\"region\").field_maps.get(\"region_abbreviation_to_region\")\n",
    "field_iso = \"iso_code3\"\n",
    "field_region = \"nation\"\n",
    "fields_drop = [\"iso_code3\", \"year\", \"nation\"] # only apply later\n",
    "field_time_period = sa.model_attributes.dim_time_period\n",
    "\n",
    "\n",
    "# load in tables and make some quick modifications\n",
    "dict_sets = {}\n",
    "for k in dict_calibration_file_paths.keys():\n",
    "    # read and clean columns\n",
    "    df_read = pd.read_csv(dict_calibration_file_paths.get(k))\n",
    "    dict_rnm = dict((x, x.lower()) for x in df_read.columns if x != x.lower())\n",
    "    df_read.rename(columns = dict_rnm, inplace = True)\n",
    "\n",
    "    \n",
    "    # filter time periods and do some field cleaning\n",
    "    df_read = df_read[df_read[field_time_period] >= 0].reset_index(drop = True)\n",
    "    df_read[field_region] = [dict_replace_iso.get(x.lower()) for x in list(df_read[field_iso])]\n",
    "    dict_isos.update({k: set(df_read[field_iso])})\n",
    "    \n",
    "    # fields missing from input file: take from fake data\n",
    "    fields_missing = list(set(df_fake_data.columns) - set(df_read.columns))\n",
    "    fields_eliminate = list((set(df_read.columns) - set(df_fake_data.columns)) - set(fields_drop) - set([\"strategy_id\"]))\n",
    "    \n",
    "    df_read = pd.merge(\n",
    "        df_read, \n",
    "        df_fake_data[[field_time_period] + fields_missing],\n",
    "        on = [field_time_period],\n",
    "        how = \"left\"\n",
    "    ).drop(fields_eliminate, axis = 1)\n",
    "    \n",
    "    dict_calibration_tables.update({k: df_read})\n",
    "    set_merge = set(df_read[field_region])\n",
    "    dict_sets.update({k: set_merge})\n",
    "    all_regions = set_merge if (all_regions is None) else (all_regions & set_merge)\n",
    "\n",
    "    \n",
    "attr_region = sa.model_attributes.dict_attributes.get(\"region\")\n",
    "attr_sector = sa.model_attributes.dict_attributes.get(\"abbreviation_sector\")\n",
    "attr_strat = sa.model_attributes.dict_attributes.get(f\"dim_{sa.model_attributes.dim_strategy_id}\")\n",
    "all_regions = sorted(list(set(attr_region.key_values) & all_regions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc643650-d38d-467d-886c-ecea59b4cb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bcc3232-a644-49fb-8dcf-09632e854181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Can't pickle <class 'model_attributes.ModelAttributes'>: it's not the same object as model_attributes.ModelAttributes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#####################################################################\n",
    "#    INITIALIZE AN EMPTY INPUT TEMPLATE OBJECT, USE FOR BUILDING    #\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "\n",
    "file_struct = SISEPUEDEFileStructure();\n",
    "dir_templates = file_struct.dict_data_mode_to_template_directory.get(\"calibrated\")\n",
    "dir_templates_demo = file_struct.dict_data_mode_to_template_directory.get(\"demo\")\n",
    "bid = ing.BaseInputDatabase(dir_templates, sa.model_attributes, None, demo_q = False);\n",
    "bid_demo = ing.BaseInputDatabase(dir_templates_demo, sa.model_attributes, list(all_regions)[0], demo_q = True);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db96426f-7d3d-4a41-b8f4-8c6aceac8fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sector AFOLU...\n",
      "\tCompleted region brazil.\n",
      "\tCompleted region chile.\n",
      "\tCompleted region ecuador.\n",
      "\tCompleted region mexico.\n",
      "\n",
      "Sector AFOLU complete in 1.92 seconds.\n",
      "\n",
      "\n",
      "Starting sector Circular Economy...\n",
      "\tCompleted region brazil.\n",
      "\tCompleted region chile.\n",
      "\tCompleted region ecuador.\n",
      "\tCompleted region mexico.\n",
      "\n",
      "Sector Circular Economy complete in 0.84 seconds.\n",
      "\n",
      "\n",
      "Starting sector Energy...\n",
      "\tCompleted region brazil.\n",
      "\tCompleted region chile.\n",
      "\tCompleted region ecuador.\n",
      "\tCompleted region mexico.\n",
      "\n",
      "Sector Energy complete in 138.4 seconds.\n",
      "\n",
      "\n",
      "Starting sector IPPU...\n",
      "\tCompleted region brazil.\n",
      "\tCompleted region chile.\n",
      "\tCompleted region ecuador.\n",
      "\tCompleted region mexico.\n",
      "\n",
      "Sector IPPU complete in 0.62 seconds.\n",
      "\n",
      "\n",
      "Starting sector Socioeconomic...\n",
      "\tCompleted region brazil.\n",
      "\tCompleted region chile.\n",
      "\tCompleted region ecuador.\n",
      "\tCompleted region mexico.\n",
      "\n",
      "Sector Socioeconomic complete in 0.3 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "########################################################\n",
    "#   LOOP OVER SECTOR/REGION TO CONVERT TO TEMPLATES    #\n",
    "########################################################\n",
    "\n",
    "importlib.reload(sf)\n",
    "importlib.reload(ing)\n",
    "input_template = ing.InputTemplate(\n",
    "    None,\n",
    "    sa.model_attributes\n",
    ")\n",
    "dict_sector_abv_to_sector = attr_sector.field_maps.get(f\"{attr_sector.key}_to_sector\")\n",
    "\n",
    "for sector_abv in dict_calibration_file_paths.keys():\n",
    "    \n",
    "    t_0 = time.time()\n",
    "    \n",
    "    # get input data\n",
    "    df_inputs = dict_calibration_tables.get(sector_abv)\n",
    "    fields_drop_cur = [x for x in fields_drop if x in df_inputs.columns]\n",
    "    sector = dict_sector_abv_to_sector.get(sector_abv)\n",
    "    print(f\"Starting sector {sector}...\")\n",
    "    \n",
    "    # get baseline \"demo\" template, use for ranges\n",
    "    fp_read = bid_demo.get_template_path(list(all_regions)[0], sector)\n",
    "    df_template = pd.read_excel(\n",
    "        fp_read, \n",
    "        sheet_name = input_template.name_sheet_from_index(input_template.baseline_strategy)\n",
    "    )\n",
    "    \n",
    "    # fields to extract\n",
    "    fields_ext = [x for x in input_template.list_fields_required_base]\n",
    "    fields_ext += [x for x in df_template.columns if input_template.regex_template_max.match(str(x)) is not None]\n",
    "    fields_ext += [x for x in df_template.columns if input_template.regex_template_min.match(str(x)) is not None]\n",
    "    df_template = df_template[fields_ext].drop_duplicates()\n",
    "    \n",
    "    # loop over regions to build template\n",
    "    for region in [\"brazil\", \"chile\", \"ecuador\", \"mexico\"]:#all_regions:\n",
    "        \n",
    "        # get input component and add baseline strategy marker\n",
    "        fields_sort = [attr_strat.key, field_time_period] if (attr_strat.key in df_inputs.columns) else [field_time_period]\n",
    "        df_input = df_inputs[\n",
    "            (df_inputs[field_region] == region)\n",
    "        ].drop(\n",
    "            fields_drop_cur, \n",
    "            axis = 1\n",
    "        ).sort_values(\n",
    "            by = fields_sort\n",
    "        ).reset_index(\n",
    "            drop = True\n",
    "        )\n",
    "        \n",
    "        if attr_strat.key not in df_input.columns:\n",
    "            df_input[attr_strat.key] = input_template.baseline_strategy\n",
    "        \n",
    "        # dictionary to export to excel\n",
    "        dict_write = input_template.template_from_inputs(\n",
    "            df_input,\n",
    "            df_template,\n",
    "            sector_abv\n",
    "        )\n",
    "        \n",
    "        # export \n",
    "        fp_write = bid.get_template_path(\n",
    "            region, \n",
    "            sector,\n",
    "            create_export_dir = True\n",
    "        )\n",
    "        \n",
    "        sf.dict_to_excel(\n",
    "            fp_write,\n",
    "            dict_write   \n",
    "        ) if True else None\n",
    "        print(f\"\\tCompleted region {region}.\")\n",
    "    \n",
    "    t_elapse = sf.get_time_elapsed(t_0)\n",
    "    print(f\"\\nSector {sector} complete in {t_elapse} seconds.\\n\\n\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93bf6d-bde6-4231-9e38-91419ed3332e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "022581e7-e98c-4a16-ad94-f4dbf1c3f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting calibration db to: /Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/calibrated_input_files_from_edmundo/sisepuede_aggregate_calibration_db_20220220.csv\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#    AGGREGATED DATABASE FOR HERMILLO/CALIBRATION    #\n",
    "######################################################\n",
    "\n",
    "def exp_aggregate_db(\n",
    "    dict_calibration_tables: dict,\n",
    "    dir_calibs: str,\n",
    "    tag: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Export aggregate database\n",
    "    \"\"\"\n",
    "    attr_sec = sa.model_attributes.dict_attributes.get(\"abbreviation_sector\")\n",
    "    attr_subsec = sa.model_attributes.dict_attributes.get(\"abbreviation_subsector\")\n",
    "    tab_subsec = attr_subsec.table.copy()\n",
    "\n",
    "\n",
    "    # setup some dicts\n",
    "    dict_subsec_to_abv_subsec = attr_subsec.field_maps.get(f\"subsector_to_{attr_subsec.key}\")\n",
    "    dict_abv_subsec_to_sec = attr_subsec.field_maps.get(f\"{attr_subsec.key}_to_sector\")\n",
    "    dict_subsec_to_sec = dict((x, dict_abv_subsec_to_sec.get(dict_subsec_to_abv_subsec.get(x))) for x in dict_subsec_to_abv_subsec.keys())\n",
    "    dict_abv_sec_to_sec = attr_sec.field_maps.get(f\"{attr_sec.key}_to_sector\")\n",
    "\n",
    "\n",
    "    # \n",
    "    df_vars = sa.model_attributes.build_variable_dataframe_by_sector(None)\n",
    "    all_vars = set(df_vars[\"variable\"])\n",
    "    df_vars = df_vars[\n",
    "        df_vars[\"time_period\"].isin([0])\n",
    "    ].drop([\"time_period\"], axis = 1).reset_index(drop = True)\n",
    "\n",
    "    df_vars[\"sector\"] = df_vars[\"subsector\"].replace(dict_subsec_to_sec)\n",
    "\n",
    "    fields_index = [\"time_period\", \"iso_code3\"]\n",
    "    fields_data = []\n",
    "    dict_subset = {\"strategy_id\": [0]}\n",
    "\n",
    "    df_out = None\n",
    "\n",
    "    for abv in dict_abv_sec_to_sec.keys():\n",
    "\n",
    "        sector = dict_abv_sec_to_sec.get(abv)\n",
    "        df_ext = dict_calibration_tables.get(abv)\n",
    "        vars_ext = list(df_vars[df_vars[\"sector\"] == sector][\"variable\"])\n",
    "        fields_data += vars_ext\n",
    "\n",
    "        fields_ext = fields_index + vars_ext\n",
    "\n",
    "        df = dict_calibration_tables.get(abv)\n",
    "        df = sf.subset_df(df, dict_subset)[fields_ext]\n",
    "        df.drop([\"strategy_id\"], axis = 1, inplace = True) if (\"strategy_id\" in df.columns) else None\n",
    "\n",
    "        df_out = df if (df_out is None) else pd.merge(df_out, df, on = fields_index, how = \"inner\")\n",
    "\n",
    "    fields_data.sort()\n",
    "    df_out = df_out[fields_index + fields_data]\n",
    "    \n",
    "    # export\n",
    "    fp_out = os.path.join(dir_calibs, f\"sisepuede_aggregate_calibration_db_{tag}.csv\")\n",
    "    print(f\"exporting calibration db to: {fp_out}\")\n",
    "    df_out.to_csv(\n",
    "        fp_out, \n",
    "        index = None, \n",
    "        encoding = \"UTF-8\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return df_out\n",
    "\n",
    "df_calib = exp_aggregate_db(dict_calibration_tables, dir_calibs, \"20220220\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e317efe5-e1af-4371-8abb-a12cec8f19e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "efficfactor_ccsq_heat_energy_direct_air_capture_geothermal                0.9500\n",
       "efficfactor_ccsq_heat_energy_direct_air_capture_hydrogen                  0.8000\n",
       "efficfactor_ccsq_heat_energy_direct_air_capture_natural_gas               0.8000\n",
       "efficfactor_enfu_industrial_energy_fuel_biomass                           0.6000\n",
       "efficfactor_enfu_industrial_energy_fuel_coal                              0.6000\n",
       "efficfactor_enfu_industrial_energy_fuel_coke                              0.6000\n",
       "efficfactor_enfu_industrial_energy_fuel_diesel                            0.7500\n",
       "efficfactor_enfu_industrial_energy_fuel_electricity                       0.9900\n",
       "efficfactor_enfu_industrial_energy_fuel_gas_furnace                       0.8000\n",
       "efficfactor_enfu_industrial_energy_fuel_gas_petroleum_liquid              0.7500\n",
       "efficfactor_enfu_industrial_energy_fuel_gasoline                          0.7500\n",
       "efficfactor_enfu_industrial_energy_fuel_hydrogen                          0.8000\n",
       "efficfactor_enfu_industrial_energy_fuel_kerosene                          0.7500\n",
       "efficfactor_enfu_industrial_energy_fuel_natural_gas                       0.8000\n",
       "efficfactor_enfu_industrial_energy_fuel_oil                               0.7500\n",
       "efficfactor_enfu_industrial_energy_fuel_solar                             0.9500\n",
       "efficfactor_entc_technology_fuel_use_pp_biogas                            0.3350\n",
       "efficfactor_entc_technology_fuel_use_pp_biomass                           0.4000\n",
       "efficfactor_entc_technology_fuel_use_pp_coal                              0.4500\n",
       "efficfactor_entc_technology_fuel_use_pp_gas                               0.4000\n",
       "efficfactor_entc_technology_fuel_use_pp_geothermal                        1.0000\n",
       "efficfactor_entc_technology_fuel_use_pp_hydropower                        1.0000\n",
       "efficfactor_entc_technology_fuel_use_pp_nuclear                           0.0027\n",
       "efficfactor_entc_technology_fuel_use_pp_ocean                             1.0000\n",
       "efficfactor_entc_technology_fuel_use_pp_oil                               0.4000\n",
       "efficfactor_entc_technology_fuel_use_pp_solar                             1.0000\n",
       "efficfactor_entc_technology_fuel_use_pp_waste_incineration                0.4000\n",
       "efficfactor_entc_technology_fuel_use_pp_wind                              1.0000\n",
       "efficfactor_entc_technology_fuel_use_st_batteries                         0.8000\n",
       "efficfactor_entc_technology_fuel_use_st_compressed_air                    0.7500\n",
       "efficfactor_entc_technology_fuel_use_st_flywheels                         0.8500\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_coal                    0.6000\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_diesel                  0.7500\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_electricity             0.9900\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_gas_petroleum_liquid    0.7500\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_gasoline                0.7500\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_hydrogen                0.8000\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_kerosene                0.7500\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_natural_gas             0.8000\n",
       "efficfactor_scoe_heat_energy_commercial_municipal_solid_biomass           0.6000\n",
       "efficfactor_scoe_heat_energy_other_se_coal                                0.6000\n",
       "efficfactor_scoe_heat_energy_other_se_diesel                              0.7500\n",
       "efficfactor_scoe_heat_energy_other_se_electricity                         0.9900\n",
       "efficfactor_scoe_heat_energy_other_se_gas_petroleum_liquid                0.7500\n",
       "efficfactor_scoe_heat_energy_other_se_gasoline                            0.7500\n",
       "efficfactor_scoe_heat_energy_other_se_hydrogen                            0.8000\n",
       "efficfactor_scoe_heat_energy_other_se_kerosene                            0.7500\n",
       "efficfactor_scoe_heat_energy_other_se_natural_gas                         0.8000\n",
       "efficfactor_scoe_heat_energy_other_se_solid_biomass                       0.6000\n",
       "efficfactor_scoe_heat_energy_residential_coal                             0.6000\n",
       "efficfactor_scoe_heat_energy_residential_diesel                           0.7500\n",
       "efficfactor_scoe_heat_energy_residential_electricity                      0.9900\n",
       "efficfactor_scoe_heat_energy_residential_gas_petroleum_liquid             0.7500\n",
       "efficfactor_scoe_heat_energy_residential_gasoline                         0.7500\n",
       "efficfactor_scoe_heat_energy_residential_hydrogen                         0.8000\n",
       "efficfactor_scoe_heat_energy_residential_kerosene                         0.7500\n",
       "efficfactor_scoe_heat_energy_residential_natural_gas                      0.8000\n",
       "efficfactor_scoe_heat_energy_residential_solid_biomass                    0.6000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calib[[x for x in df_calib.columns if (x.startswith(\"efficfactor\"))]].iloc[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e16bc668-5561-4f69-a297-fe79904b4e1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ingestion' has no attribute 'df_cur_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8m/3ll2cn6d1hdcs6gjqxr2jx5d2hffc9/T/ipykernel_23060/780582726.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_cur_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_is\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sf.filter_df_on_reference_df_rows(\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ingestion' has no attribute 'df_cur_out'"
     ]
    }
   ],
   "source": [
    "importlib.reload(sf)\n",
    "df_cur = ing.df_cur_out\n",
    "df_base = ing.dict_is.get(0)\n",
    "\n",
    "sf.filter_df_on_reference_df_rows(\n",
    "    df_cur,\n",
    "    df_base,\n",
    "    [\"subsector\", \"variable\", \"time_period\"],#'subsector', 'variable', 'time_period'],\n",
    "    [\"value\"],\n",
    "    [\"variable\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "407f7d22-7c83-49f1-b157-aed6ae412763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsector</th>\n",
       "      <th>variable</th>\n",
       "      <th>time_period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subsector, variable, time_period, value]\n",
       "Index: []"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.iloc[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ed7521b-a320-41e9-96e6-41f9c55fb28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting strat 0\n",
      "starting strat 3001\n",
      "starting strat 3002\n",
      "starting strat 3003\n",
      "starting strat 3004\n",
      "starting strat 3005\n",
      "starting strat 3006\n",
      "starting strat 3007\n",
      "starting strat 3008\n",
      "starting strat 3009\n",
      "starting strat 3010\n",
      "starting strat 3011\n",
      "starting strat 3012\n",
      "starting strat 3013\n",
      "starting strat 3014\n",
      "starting strat 3015\n",
      "starting strat 3016\n",
      "starting strat 3017\n",
      "starting strat 3018\n",
      "starting strat 3019\n",
      "starting strat 3020\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m input_template \u001b[38;5;241m=\u001b[39m ing\u001b[38;5;241m.\u001b[39mInputTemplate(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     sa\u001b[38;5;241m.\u001b[39mmodel_attributes\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43minput_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_from_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msector_abv\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/git_jbus/lac_decarbonization/python/ingestion.py:360\u001b[0m, in \u001b[0;36mInputTemplate.template_from_inputs\u001b[0;34m(self, df_input, df_variable_information, sectors, field_key_strategy, field_req_normalize_group, field_req_subsector, field_req_trajgroup_no_vary_q, field_req_uniform_scaling_q, field_req_variable, field_req_variable_trajectory_group, field_req_variable_trajectory_group_trajectory_type, regex_max, regex_min, regex_tp)\u001b[0m\n\u001b[1;32m    357\u001b[0m df_var_info_out \u001b[38;5;241m=\u001b[39m df_var_info\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# add in variable info and pivot to wide by time period\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m df_cur \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_var_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m df_cur \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mpivot_df_clean(\n\u001b[1;32m    362\u001b[0m \tdf_cur,\n\u001b[1;32m    363\u001b[0m \t[field_time_period],\n\u001b[1;32m    364\u001b[0m \t[field_melted_value]\n\u001b[1;32m    365\u001b[0m )\n\u001b[1;32m    367\u001b[0m dict_inputs_by_strat\u001b[38;5;241m.\u001b[39mupdate({sheet_name: df_cur})\n",
      "File \u001b[0;32m~/anaconda3/envs/amber_is_your_energy/lib/python3.11/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/envs/amber_is_your_energy/lib/python3.11/site-packages/pandas/core/reshape/merge.py:644\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    630\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     _left \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_operand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     _right \u001b[38;5;241m=\u001b[39m _validate_operand(right)\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_left \u001b[38;5;241m=\u001b[39m _left\n",
      "File \u001b[0;32m~/anaconda3/envs/amber_is_your_energy/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2426\u001b[0m, in \u001b[0;36m_validate_operand\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   2425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only merge Series or DataFrame objects, a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2428\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed"
     ]
    }
   ],
   "source": [
    "#df_template[df_template[\"subsector\"] == sa.model_attributes.subsec_name_scoe]\n",
    "importlib.reload(ing)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "input_template = ing.InputTemplate(\n",
    "    None,\n",
    "    sa.model_attributes\n",
    ")\n",
    "input_template.template_from_inputs(\n",
    "    df_input, \n",
    "    df_template, \n",
    "    sector_abv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5fd0350-46d4-4b8c-b2a3-9cf439de084b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Industrial Energy', 'Stationary Combustion and Other Energy'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = sa.model_attributes.build_variable_dataframe_by_sector(\n",
    "    [\"Energy\"],\n",
    "    field_subsector = input_template.field_req_subsector,\n",
    "    field_variable = input_template.field_req_variable,\n",
    "    include_time_periods = True\n",
    ")\n",
    "set(df_base[\n",
    "    \n",
    "    [x.startswith(\"scalar\") for x in list(df_base[\"variable\"])]\n",
    "][\"subsector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb0da8de-c811-46bf-ab67-8606397c94a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x13bc5f6d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing.dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd072849-ba78-4931-a7c9-85d6bb4be4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f912c44-081d-499b-a9d0-a49df96c54b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f794a-76ab-40c7-b377-cd21900ef178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6d41774-1c75-4aa5-9cdd-ec1b60bad062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field_req_normalize_group = self.field_req_normalize_group if (field_req_normalize_group is None) else field_req_normalize_group\n",
      "field_req_subsector = self.field_req_subsector if (field_req_subsector is None) else field_req_subsector\n",
      "field_req_trajgroup_no_vary_q = self.field_req_trajgroup_no_vary_q if (field_req_trajgroup_no_vary_q is None) else field_req_trajgroup_no_vary_q\n",
      "field_req_uniform_scaling_q = self.field_req_uniform_scaling_q if (field_req_uniform_scaling_q is None) else field_req_uniform_scaling_q\n",
      "field_req_variable = self.field_req_variable if (field_req_variable is None) else field_req_variable\n",
      "field_req_variable_trajectory_group = self.field_req_variable_trajectory_group if (field_req_variable_trajectory_group is None) else field_req_variable_trajectory_group\n",
      "field_req_variable_trajectory_group_trajectory_type = self.field_req_variable_trajectory_group_trajectory_type if (field_req_variable_trajectory_group_trajectory_type is None) else field_req_variable_trajectory_group_trajectory_type\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/jsyme/Desktop/untitled_5.txt\", \"r+\") as fl:\n",
    "    lines = fl.readlines()\n",
    "    lines = [x for x in lines if not (\"#\" in x)]\n",
    "    lines = [x.strip().split(\":\")[0] for x in lines]\n",
    "    lines = [f\"{x} = self.{x} if ({x} is None) else {x}\" for x in lines]\n",
    "    #lines = [x.strip().split(\":\")[0] + \": Union[str, none] = None,\" for x in lines]\n",
    "    \n",
    "for x in sorted(lines):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82f2745e-e57b-40af-b42d-0242a17566a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bac42-5232-4ab1-aa02-2e9adb1e0110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5260d72-7b04-436d-bf9b-42dd64875690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cc273-7d20-4f31-9311-c581b4164c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
