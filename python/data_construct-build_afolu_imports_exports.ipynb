{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_structures as ds\n",
    "import setup_analysis as sa\n",
    "import support_functions as sf\n",
    "import importlib\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import model_afolu as ma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build composite data frame for estimation\n",
    "def build_df_est(\n",
    "    df_exports: pd.DataFrame,\n",
    "    df_imports: pd.DataFrame,  \n",
    "    df_production: pd.DataFrame,\n",
    "    df_stocks: pd.DataFrame,\n",
    "    dict_items_repl: dict,\n",
    "    fields_dat: list,\n",
    "    fields_grp: list, \n",
    "    agg_func: str = \"sum\"\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # collect and fill na\n",
    "    df_est = pd.merge(df_imports, df_exports, how = \"outer\")\n",
    "    df_est = pd.merge(df_est, df_production, how = \"outer\")\n",
    "    df_est = pd.merge(df_est, df_stocks, how = \"outer\")\n",
    "    df_est.fillna(0.0, inplace = True)\n",
    "    \n",
    "    # drop rows where exports exceed production (here, we have 1:1 connection for items)\n",
    "    df_est = df_est[\n",
    "        (df_est[\"exports\"] <= df_est[\"production\"])\n",
    "        #(df_est[\"imports\"] <= df_est[\"production\"])\n",
    "    ].reset_index(drop = True)\n",
    "    \n",
    "    # calculate demand\n",
    "    E = np.array(df_est[\"exports\"])\n",
    "    I = np.array(df_est[\"imports\"])\n",
    "    P = np.array(df_est[\"production\"])\n",
    "    M = P + I - E\n",
    "    df_est[\"demand\"] = M\n",
    "    fields_dat.append(\"demand\")\n",
    "    \n",
    "    df_est_out = df_est.copy()\n",
    "    df_est[\"Item\"] = df_est[\"Item\"].replace(dict_items_repl)\n",
    "    dict_agg = dict([(x, \"first\") for x in fields_grp])\n",
    "    dict_agg.update(dict([(x, agg_func) for x in fields_dat]))\n",
    "    fields_drop = [x for x in df_est.columns if (x not in fields_dat + fields_grp)]\n",
    "    \n",
    "    df_agg = df_est.drop(fields_drop, axis = 1).groupby(fields_grp).agg(dict_agg).reset_index(drop = True)\n",
    "    \n",
    "    return df_agg, df_est_out\n",
    "\n",
    "\n",
    "\n",
    "# function to clean country names\n",
    "def clean_region_name(x: str, clean_type = \"for_data\") -> str:\n",
    "    nm = x.split(\"(\")[0].strip()\n",
    "    \n",
    "    if clean_type == \"for_data\":\n",
    "        nm = nm.lower().replace(\" \", \"_\")\n",
    "    elif clean_type == \"for_key\":\n",
    "        None\n",
    "    \n",
    "    return nm\n",
    "\n",
    "\n",
    "\n",
    "# filter and order data frames\n",
    "def filter_dfs(\n",
    "    df: pd.DataFrame, \n",
    "    dict_subset: dict,\n",
    "    fields_keep: list\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    df_out = sf.subset_df(df, dict_subset)\n",
    "    fields_drop = [x for x in df_out.columns if x not in fields_keep]\n",
    "    df_out.drop(fields_drop, axis = 1, inplace = True)\n",
    "    df_out.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "# read in FAO data\n",
    "def get_faostat_data(\n",
    "    dir_faostat: str, \n",
    "    nm: str,\n",
    "    encode: str = \"ISO-8859-1\"\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    fp_read = os.path.join(dir_faostat, nm, f\"{nm}.csv\")\n",
    "    sf.check_path(fp_read)\n",
    "    \n",
    "    df_ret = pd.read_csv(\n",
    "        fp_read, \n",
    "        encoding = encode\n",
    "    )\n",
    "    \n",
    "    return df_ret\n",
    "\n",
    "\n",
    "# load data\n",
    "dir_faostat = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/ingestion/FAOSTAT/\"\n",
    "df_ag_production = get_faostat_data(dir_faostat, \"Production_Crops_Livestock_E_All_Data_(Normalized)\")\n",
    "df_ag_trade = get_faostat_data(dir_faostat, \"Trade_Crops_Livestock_E_All_Data_(Normalized)\")\n",
    "df_cw_fao = pd.read_csv(sa.fp_csv_cw_fao_crops)\n",
    "attribute_cw_fao_cats = ds.AttributeTable(\n",
    "    sa.fp_csv_cw_fao_product_demand_categories_for_ie,\n",
    "    field_cat, \n",
    "    []\n",
    ")\n",
    "\n",
    "# set some attributes\n",
    "attr_region = sa.model_attributes.dict_attributes.get(\"region\")\n",
    "attr_time_period = sa.model_attributes.dict_attributes.get(\"dim_time_period\")\n",
    "model_afolu = ma.AFOLU(sa.model_attributes)\n",
    "\n",
    "# get region codes\n",
    "region_codes_all = attr_region.key_values\n",
    "dict_area_codes = attr_region.field_maps.get(\"region_to_fao_area_code\")\n",
    "region_codes_all = [dict_area_codes.get(x, None) for x in region_codes_all]\n",
    "\n",
    "# set some fields for working with crosswalk\n",
    "flag_none = \"NONE\"\n",
    "field_cat = \"fao_category\"\n",
    "field_subsec = \"sisepuede_demand_subsector\"\n",
    "field_demand_cat = \"sisepuede_demand_category\"\n",
    "\n",
    "# FAO Items to drop and keep\n",
    "df_cw_product_cats = attribute_cw_fao_cats.table\n",
    "items_drop = list(\n",
    "    df_cw_product_cats[\n",
    "        df_cw_product_cats[field_demand_cat].isin([flag_none])\n",
    "    ][field_cat]\n",
    ")\n",
    "items_keep = list(\n",
    "    df_cw_product_cats[\n",
    "        ~df_cw_product_cats[field_demand_cat].isin([flag_none])\n",
    "    ][field_cat]\n",
    ")\n",
    "\n",
    "# get years to keep\n",
    "years_keep = list(range(2011, 2021))\n",
    "\n",
    "# filtering dictionaries\n",
    "dict_filt = {\n",
    "    \"Element\": [\"Production\"],\n",
    "    \"Year\": years_keep,\n",
    "    \"Area Code\": region_codes_all,\n",
    "    \"Item\": list(df_cw_fao[\"fao_crop\"])\n",
    "}\n",
    "fields_keep = [\"Area\", \"Item\", \"Item Code\", \"Year\", \"Unit\", \"Value\"]\n",
    "\n",
    "\n",
    "##  reduce\n",
    "\n",
    "dict_repl_stocks_0 = {\n",
    "    \"Asses\": \"mules\", \n",
    "    \"Cattle\": \"Cattle_nondairy\",\n",
    "    \"Chickens\": \"chickens\",\n",
    "    \"Ducks\": \"chickens\",\n",
    "    \"Goats\": \"goats\",\n",
    "    \"Horses\": \"horses\",\n",
    "    \"Mules\": \"mules\",\n",
    "    \"Pigs\": \"pigs\",\n",
    "    \"Sheep\": \"sheep\",\n",
    "    \"Turkeys\": \"chickens\",\n",
    "    \"Camelids, other\": \"horses\",\n",
    "    \"Buffaloes\": \"buffalo\"\n",
    "}\n",
    "# stocks/yield - two parts\n",
    "df_yields = filter_dfs(\n",
    "    df_ag_production,\n",
    "    dict_filt,\n",
    "    fields_keep\n",
    ").rename(columns =  {\"Value\": \"stocks\"})\n",
    "dict_filt.update({\"Item\": items_keep, \"Element\": [\"Stocks\"]})\n",
    "df_stocks_0 = filter_dfs(\n",
    "    df_ag_production,\n",
    "    dict_filt,\n",
    "    fields_keep\n",
    ").rename(columns =  {\"Value\": \"stocks\"})\n",
    "df_stocks = pd.concat([\n",
    "    df_yields,\n",
    "    df_stocks_0\n",
    "], axis = 0).reset_index(drop = True)\n",
    "\n",
    "# production\n",
    "dict_filt.update({\"Element\": [\"Production\"]})\n",
    "df_prod = filter_dfs(\n",
    "    df_ag_production,\n",
    "    dict_filt,\n",
    "    fields_keep\n",
    ").rename(columns =  {\"Value\": \"production\"})\n",
    "\n",
    "# append stocks that are unaccounted for\n",
    "df_prod_app = df_stocks[\n",
    "    df_stocks[\"Item\"].isin(set(df_stocks[\"Item\"]) - set(df_prod[\"Item\"]))\n",
    "].copy().rename(columns = {\"stocks\": \"production\"})\n",
    "df_prod = pd.concat([\n",
    "    df_prod,\n",
    "    df_prod_app\n",
    "], axis = 0).reset_index(drop = True)\n",
    "\n",
    "# imports\n",
    "dict_filt.update({\"Element\": [\"Import Quantity\"]})\n",
    "df_imports = filter_dfs(\n",
    "    df_ag_trade,\n",
    "    dict_filt,\n",
    "    fields_keep\n",
    ").rename(columns =  {\"Value\": \"imports\"})\n",
    "\n",
    "# exports\n",
    "dict_filt.update({\"Element\": [\"Export Quantity\"]})\n",
    "df_exports = filter_dfs(\n",
    "    df_ag_trade,\n",
    "    dict_filt,\n",
    "    fields_keep\n",
    ").rename(columns =  {\"Value\": \"exports\"})\n",
    "\n",
    "\n",
    "# convert Heads units to 1000 Heads where present and clean items\n",
    "dict_dfs = {\n",
    "    \"exports\": df_exports,\n",
    "    \"imports\": df_imports,\n",
    "    \"production\": df_prod,\n",
    "    \"stocks\": df_stocks\n",
    "}\n",
    "for key in dict_dfs.keys():\n",
    "    # \n",
    "    df = dict_dfs[key]\n",
    "    vec_adj = np.ones(len(df))\n",
    "    vec_unit = np.array(df[\"Unit\"])\n",
    "    vec_vals = np.array(df[key])\n",
    "    \n",
    "    w = np.where(vec_unit == \"Head\")[0]\n",
    "    if len(w) > 0:\n",
    "        np.put(vec_adj, w, 0.001)\n",
    "        np.put(vec_unit, w, \"1000 Head\")\n",
    "    df[\"Unit\"] = vec_unit\n",
    "    df[key] = vec_vals*vec_adj\n",
    "    \n",
    "    # clean items\n",
    "    df[\"Item\"] = [x.strip() for x in list(df[\"Item\"])]\n",
    "    \n",
    "    dict_dfs.update({key: df})\n",
    "\n",
    "    \n",
    "    \n",
    "# split out between items associated with stock and derivative goods \n",
    "items_stock = list(df_stocks[\"Item Code\"])\n",
    "dict_dfs_split = {\"stocks\": {}, \"derivatives\": {}}\n",
    "\n",
    "for key in dict_dfs.keys():\n",
    "    df = dict_dfs[key]\n",
    "    df_st = df[df[\"Item Code\"].isin(items_stock)].copy().reset_index(drop = True)\n",
    "    df_dr = df[~df[\"Item Code\"].isin(items_stock)].copy().reset_index(drop = True)\n",
    "    \n",
    "    dict_dfs_split[\"stocks\"].update({key: df_st})\n",
    "    dict_dfs_split[\"derivatives\"].update({key: df_dr})\n",
    "    \n",
    "\n",
    "# get composite\n",
    "dict_repl = attribute_cw_fao_cats.field_maps[f\"{field_cat}_to_{field_demand_cat}\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get dfs - stock goods\n",
    "df_agg_stock, df_est_stock = build_df_est(\n",
    "    dict_dfs_split[\"stocks\"][\"exports\"],\n",
    "    dict_dfs_split[\"stocks\"][\"imports\"], \n",
    "    dict_dfs_split[\"stocks\"][\"production\"], \n",
    "    dict_dfs_split[\"stocks\"][\"stocks\"],\n",
    "    dict_repl,\n",
    "    [\"exports\", \"imports\", \"production\", \"stocks\"],\n",
    "    [\"Area\", \"Item\", \"Year\", \"Unit\"]\n",
    ")\n",
    "\n",
    "# get data for derivative products\n",
    "df_agg_deriv, df_est_deriv_0 = build_df_est(\n",
    "    dict_dfs_split[\"derivatives\"][\"exports\"],\n",
    "    dict_dfs_split[\"derivatives\"][\"imports\"], \n",
    "    dict_dfs_split[\"derivatives\"][\"production\"], \n",
    "    dict_dfs_split[\"derivatives\"][\"stocks\"],\n",
    "    dict_repl,\n",
    "    [\"exports\", \"imports\", \"production\", \"stocks\"],\n",
    "    [\"Area\", \"Item\", \"Year\", \"Unit\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-756-d7420e9fdf75>:45: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  df_est_ie[field_ratio] = np.nan_to_num(np.array(df_est_ie[\"production\"])/np.array(df_est_ie[\"stocks\"]), 0.0, posinf = 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:48: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  df_est_ie[field_new] = np.nan_to_num(np.array(df_est_ie[key])/np.array(df_est_ie[field_ratio]), 0.0, posinf = 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:48: RuntimeWarning: invalid value encountered in true_divide\n",
      "  df_est_ie[field_new] = np.nan_to_num(np.array(df_est_ie[key])/np.array(df_est_ie[field_ratio]), 0.0, posinf = 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  df_out[\"import_frac_of_demand\"] = np.nan_to_num(np.array(df_out[\"imports_fin_est\"])/np.array(df_out[\"domestic_demand_fin_est\"]), 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:101: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  df_out[\"export_frac_of_prod\"] = np.nan_to_num(np.array(df_out[\"exports_fin_est\"])/np.array(df_out[\"stocks\"]), 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:101: RuntimeWarning: invalid value encountered in true_divide\n",
      "  df_out[\"export_frac_of_prod\"] = np.nan_to_num(np.array(df_out[\"exports_fin_est\"])/np.array(df_out[\"stocks\"]), 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_new = np.nan_to_num(np.array(df_out[\"exports\"])/np.array(df_out[\"stocks\"]), 0, posinf = 0.0)\n",
      "<ipython-input-756-d7420e9fdf75>:120: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_new = np.nan_to_num(np.array(df_out[\"imports\"])/(np.array(df_out[\"stocks\"]) + np.array(df_out[\"imports\"]) - np.array(df_out[\"exports\"])), 0, posinf = 0.0)\n"
     ]
    }
   ],
   "source": [
    "# 1. calculate demands for stocks (done, available in df_agg_stock, df_est_stock)\n",
    "# 2. caclculate production ratios for derivative products in dict_dfs_split[\"derivatives\"]\n",
    "#    - merge derivative production to df_agg_stock *after* replacing item names\n",
    "#    - calculate demadns for each derivative good\n",
    "#    - using this ratio, calculate demands in terms of \n",
    "# get data for derivative products\n",
    "\n",
    "df_est_deriv_0[\"Item_merge\"] = df_est_deriv_0[\"Item\"].replace(dict_repl)\n",
    "df_est_deriv_0.drop([\"stocks\"], axis = 1, inplace = True) if (\"stocks\" in df_est_deriv_0.columns) else None\n",
    "\n",
    "# initialize the data frame for estimating imports/exports\n",
    "df_est_ie = pd.merge(\n",
    "    df_est_deriv_0, \n",
    "    df_agg_stock[[\"Area\", \"Year\", \"Item\", \"demand\"]].rename(columns = {\"demand\": \"stocks\", \"Item\": \"Item_merge\"}), \n",
    "    how = \"left\"\n",
    ")\n",
    "# drop no production\n",
    "df_est_ie = df_est_ie[df_est_ie[\"production\"] > 0.0].reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "##  MAKE SURE ALL PRODUCTION/EXPORT/IMPORT/DEMANDS ARE IN SAME UNIT (tonnes)\n",
    "\n",
    "# use \"small\" value as average, 43g/egg: https://www.dineachook.com.au/blog/how-to-get-bigger-eggs-from-your-chickens-egg-weight-and-size/\n",
    "# 43g/egg = 0.043 tonne/1000 egg\n",
    "factor_eggs = 0.043\n",
    "vec_adj = np.ones(len(df_est_ie))\n",
    "vec_unit = np.array(df_est_ie[\"Unit\"])\n",
    "\n",
    "for key in [\"exports\", \"imports\", \"production\", \"demand\"]:\n",
    "    \n",
    "    vec_vals = np.array(df_est_ie[key])\n",
    "    w = np.where(vec_unit == \"1000 No\")[0]\n",
    "    if len(w) > 0:\n",
    "        np.put(vec_adj, w, factor_eggs)\n",
    "        np.put(vec_unit, w, \"tonnes\")\n",
    "    df_est_ie[\"Unit\"] = vec_unit\n",
    "    df_est_ie[key] = vec_vals*vec_adj\n",
    "\n",
    "\n",
    "##  THEN, ADD THE PRODUCTION RATIO, GENERATE IMP/EXP ESTIMATES IN TERMS OF STOCKS, AND TAKE TONNE-WEIGHTED AVERAGE\n",
    "\n",
    "# production ratio and import/exports as stock equiv\n",
    "field_ratio = \"domestic_production_ratio\" # prod/stocks\n",
    "df_est_ie[field_ratio] = np.nan_to_num(np.array(df_est_ie[\"production\"])/np.array(df_est_ie[\"stocks\"]), 0.0, posinf = 0.0)\n",
    "for key in [\"imports\", \"exports\"]:\n",
    "    field_new = f\"{key}_stock_equivalent\"\n",
    "    df_est_ie[field_new] = np.nan_to_num(np.array(df_est_ie[key])/np.array(df_est_ie[field_ratio]), 0.0, posinf = 0.0)\n",
    "\n",
    "# get production weights - start with total derivative production\n",
    "fields_grp = [\"Area\", \"Year\", \"Item_merge\"]\n",
    "fields_sum = [\"production\"]\n",
    "dict_agg = dict(zip(fields_grp, [\"first\" for x in fields_grp]))\n",
    "dict_agg.update(dict(zip(fields_sum, [\"sum\" for x in fields_sum])))\n",
    "df_est_ie_total_deriv_prod = df_est_ie[\n",
    "    ~df_est_ie[\"Item\"].isin(list(df_stocks[\"Item\"]))\n",
    "][fields_grp + fields_sum].groupby(fields_grp).agg(dict_agg).reset_index(drop = True).rename(columns = {\"production\": \"total_derivative_production\"})\n",
    "\n",
    "\n",
    "##  \n",
    "\n",
    "# merge in to get production weights\n",
    "df_est_ie = pd.merge(df_est_ie, df_est_ie_total_deriv_prod, how = \"left\")\n",
    "df_est_ie[\"production_weight\"] = np.array(df_est_ie[\"production\"])/np.array(df_est_ie[\"total_derivative_production\"])\n",
    "\n",
    "# now, estimate weighted imports/exports\n",
    "for key in [\"imports\", \"exports\"]:\n",
    "    field_new = f\"weighted_est_{key}_equiv\"\n",
    "    field_stock_equiv = f\"{key}_stock_equivalent\"\n",
    "    df_est_ie[field_new] = np.array(df_est_ie[field_stock_equiv])*np.array(df_est_ie[\"production_weight\"])\n",
    "\n",
    "# aggregate \n",
    "fields_grp = [\"Area\", \"Year\", \"Item_merge\"]\n",
    "fields_sum = [\"weighted_est_imports_equiv\", \"weighted_est_exports_equiv\"]\n",
    "dict_agg = dict(zip(fields_grp, [\"first\" for x in fields_grp]))\n",
    "dict_agg.update(dict(zip(fields_sum, [\"sum\" for x in fields_sum])))\n",
    "df_est_ie_est_ie_equiv = df_est_ie[fields_grp + fields_sum].groupby(fields_grp).agg(dict_agg).reset_index(drop = True)\n",
    "df_est_ie_est_ie_equiv.rename(\n",
    "    columns = {\n",
    "        \"weighted_est_imports_equiv\": \"est_imports_equiv\",\n",
    "        \"weighted_est_exports_equiv\": \"est_exports_equiv\"\n",
    "    }\n",
    ")\n",
    "\n",
    "df_out = pd.merge(\n",
    "    df_est_ie_est_ie_equiv.rename(columns = {\"Item_merge\": \"Item\"}),\n",
    "    df_agg_stock[[\"Area\", \"Item\", \"Year\", \"exports\", \"imports\", \"stocks\"]], \n",
    "    how = \"outer\"\n",
    ")\n",
    "\n",
    "df_out.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "##  CHECK FRACTIONS, OVERWRITE WHERE ESTIMATES ARE UNREASONABLE\n",
    "\n",
    "# get some fractions\n",
    "df_out[\"exports_fin_est\"] = np.array(df_out[\"exports\"]) + np.array(df_out[\"weighted_est_exports_equiv\"])\n",
    "df_out[\"imports_fin_est\"] = np.array(df_out[\"imports\"]) + np.array(df_out[\"weighted_est_imports_equiv\"])\n",
    "df_out[\"domestic_demand_fin_est\"] = np.array(df_out[\"imports_fin_est\"]) + np.array(df_out[\"stocks\"]) - np.array(df_out[\"exports_fin_est\"])\n",
    "df_out[\"import_frac_of_demand\"] = np.nan_to_num(np.array(df_out[\"imports_fin_est\"])/np.array(df_out[\"domestic_demand_fin_est\"]), 0.0)\n",
    "df_out[\"export_frac_of_prod\"] = np.nan_to_num(np.array(df_out[\"exports_fin_est\"])/np.array(df_out[\"stocks\"]), 0.0)\n",
    "\n",
    "# set a threshold for acceptable exports; if exceeding the threshold, revert to stock exports\n",
    "thresh = 0.75\n",
    "vec_old = np.array(df_out[\"export_frac_of_prod\"])\n",
    "w = np.where(vec_old > thresh)[0]\n",
    "if len(w) > 0:\n",
    "    vec_new = np.nan_to_num(np.array(df_out[\"exports\"])/np.array(df_out[\"stocks\"]), 0, posinf = 0.0)\n",
    "    vec_repl = vec_new[w]\n",
    "    np.put(vec_old, w, vec_new[w])\n",
    "    df_out[\"export_frac_of_prod\"] = vec_old\n",
    "    \n",
    "df_out[\"exports_est\"] = np.array(df_out[\"export_frac_of_prod\"])*np.array(df_out[\"stocks\"])\n",
    "\n",
    "# set a threshold for acceptable imports;\n",
    "thresh = 0.75\n",
    "vec_old = np.array(df_out[\"import_frac_of_demand\"])\n",
    "w = np.where(vec_old > thresh)[0]\n",
    "if len(w) > 0:\n",
    "    vec_new = np.nan_to_num(np.array(df_out[\"imports\"])/(np.array(df_out[\"stocks\"]) + np.array(df_out[\"imports\"]) - np.array(df_out[\"exports\"])), 0, posinf = 0.0)\n",
    "    vec_repl = vec_new[w]\n",
    "    np.put(vec_old, w, vec_new[w])\n",
    "    df_out[\"import_frac_of_demand\"] = vec_old\n",
    "\n",
    "\n",
    "    \n",
    "# components used to build input fields\n",
    "attr_agrc = sa.model_attributes.get_attribute_table(sa.model_attributes.subsec_name_agrc)\n",
    "attr_lvst = sa.model_attributes.get_attribute_table(sa.model_attributes.subsec_name_lvst)\n",
    "dict_subsec_to_subsec_abv = sa.model_attributes.dict_attributes.get(\"abbreviation_subsector\").field_maps.get(\"subsector_to_abbreviation_subsector\")\n",
    "dict_subsec_abv_to_subsec = sa.model_attributes.dict_attributes.get(\"abbreviation_subsector\").field_maps.get(\"abbreviation_subsector_to_subsector\")\n",
    "\n",
    "dict_repl_subsecs = dict([(x, dict_subsec_to_subsec_abv.get(sa.model_attributes.subsec_name_agrc)) for x in attr_agrc.key_values])\n",
    "dict_repl_subsecs.update(dict([(x, dict_subsec_to_subsec_abv.get(sa.model_attributes.subsec_name_lvst)) for x in attr_lvst.key_values]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format items as fields\n",
    "def build_field(item: str, field_type: str) -> str:\n",
    "    \n",
    "    subsec_abv = dict_repl_subsecs.get(item)\n",
    "    subsec = dict_subsec_abv_to_subsec.get(subsec_abv)\n",
    "    \n",
    "    if subsec_abv == \"agrc\":\n",
    "        modvar = model_afolu.modvar_agrc_frac_demand_imported if (field_type == \"imports\") else model_afolu.modvar_agrc_equivalent_exports\n",
    "    elif subsec_abv == \"lvst\":\n",
    "        modvar = model_afolu.modvar_lvst_frac_demand_imported if (field_type == \"imports\") else model_afolu.modvar_lvst_equivalent_exports\n",
    "    \n",
    "    out = sa.model_attributes.build_varlist(subsec, modvar, restrict_to_category_values = [item])\n",
    "    \n",
    "    return out[0]\n",
    "\n",
    "df_out[\"field_imports\"] = df_out[\"Item\"].apply(build_field, field_type = \"imports\")\n",
    "df_out[\"field_exports\"] = df_out[\"Item\"].apply(build_field, field_type = \"exports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_wide = pd.concat([\n",
    "    df_out[[\"Area\", \"Year\", \"import_frac_of_demand\", \"field_imports\"]].rename(columns = {\"import_frac_of_demand\": \"value\", \"field_imports\": \"field\"}),\n",
    "    df_out[[\"Area\", \"Year\", \"export_frac_of_prod\", \"field_exports\"]].rename(columns = {\"export_frac_of_prod\": \"value\", \"field_exports\": \"field\"})\n",
    "], axis = 0).reset_index(drop = True)\n",
    "\n",
    "df_out_wide = pd.pivot(\n",
    "    df_out_wide,\n",
    "    [\"Area\", \"Year\"],\n",
    "    [\"field\"],\n",
    "    [\"value\"]\n",
    ").reset_index()\n",
    "df_out_wide.columns = df_out_wide.columns.to_flat_index()\n",
    "\n",
    "# rename\n",
    "cols_old = list(df_out_wide.columns)\n",
    "cols = []\n",
    "\n",
    "for c in cols_old:\n",
    "    if c[0] == \"value\":\n",
    "        cols.append(c[1])\n",
    "    else:\n",
    "        cols.append(c[0])\n",
    "dict_rnm = dict(zip(cols_old, cols))\n",
    "df_out_wide.rename(columns = dict_rnm, inplace = True)\n",
    "df_out_wide.rename(columns = {\"Year\": \"year\", \"Area\": \"Nation\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read path to formatted input data\n",
    "df_input_data = pd.read_csv(\"/Users/jsyme/Downloads/data_complete_future_2022_08_24_test1-4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_wide.to_csv(sa.fp_csv_afolu_import_exports, index = None, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
