{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87aada3-9452-4551-9e41-770c3763602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import batch_data_support_regions as bds_reg\n",
    "import geopy.distance\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model_attributes as ma\n",
    "from attribute_table import AttributeTable\n",
    "import model_afolu as mafl\n",
    "import model_ippu as mi\n",
    "import model_circular_economy as mc\n",
    "import model_energy as me\n",
    "import model_electricity as ml\n",
    "import model_socioeconomic as se\n",
    "import setup_analysis as sa\n",
    "import sisepuede as ssp\n",
    "import support_functions as sf\n",
    "import importlib\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sql_utilities as sq\n",
    "from typing import *\n",
    "import sqlalchemy\n",
    "import sql_utilities as sqlutil\n",
    "import re\n",
    "importlib.reload(ma)\n",
    "importlib.reload(sa)\n",
    "importlib.reload(sf)\n",
    "importlib.reload(mafl)\n",
    "importlib.reload(mc)\n",
    "importlib.reload(mi)\n",
    "importlib.reload(me)\n",
    "importlib.reload(se)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e40fd-5bfc-4e44-b3e5-64f39a81c8d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  For Seasonal Variationo in Hydropower Capacity Factors, derive from global model of hydropower generation developed by Wan et al. (2021)\n",
    "\n",
    "- Wan, W., Zhao, J., Popat, E., Herbert, C., & DÃ¶ll, P. (2021). Analyzing the impact of streamflow drought on hydroelectricity production: A global-scale study. Water Resources Research, 57, e2020WR028087. https://doi.org/10.1029/2020WR028087\n",
    "\n",
    "- Code (modified to read variable \"days\" from a CSV, see below) available from \n",
    "    - https://energy.duke.edu/content/global-hydropower-database, which leads to\n",
    "    - https://figshare.com/articles/dataset/Global_Hydropower_Database_GHD_/11283758/3?file=22767863\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c03f8b17-4e82-4c52-bc94-d96c67ee3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  IMPORT SOME ATTRIBUTES, MODELS, AND SHARED VARIABLES\n",
    "\n",
    "attr_region = sa.model_attributes.dict_attributes.get(f\"{sa.model_attributes.dim_region}\")\n",
    "attr_time_period = sa.model_attributes.dict_attributes.get(f\"dim_{sa.model_attributes.dim_time_period}\")\n",
    "attr_time_slice = sa.model_attributes.dict_attributes.get(f\"time_slice\")\n",
    "\n",
    "# call variables from the electric model\n",
    "model_elec = ml.ElectricEnergy(sa.model_attributes, sa.dir_jl, sa.dir_ref_nemo, initialize_julia = False)\n",
    "\n",
    "# map each country to ISO code 3 and each code to \n",
    "dict_country_to_iso = dict((k, v.upper()) for k, v in attr_region.field_maps.get(f\"{attr_region.key}_to_iso_alpha_3\").items())\n",
    "dict_iso_to_country = sf.reverse_dict(dict_country_to_iso)\n",
    "\n",
    "\n",
    "# used in a number of places\n",
    "dict_n_days_per_month = {\n",
    "    1: 31,\n",
    "    2: 28,\n",
    "    3: 31,\n",
    "    4: 30,\n",
    "    5: 31,\n",
    "    6: 30,\n",
    "    7: 31,\n",
    "    8: 31,\n",
    "    9: 30,\n",
    "    10: 31,\n",
    "    11: 30,\n",
    "    12: 31\n",
    "}\n",
    "# weights days/month on average when only monthly data are avaiable\n",
    "dict_num_days_per_month_weights = dict((k, (v if (k != 2) else 28.25)) for k, v in dict_n_days_per_month.items())\n",
    "\n",
    "# setup some fields\n",
    "field_capacity = \"capacity_mw\"\n",
    "field_capacity_factor = \"capacity_factor\"\n",
    "field_cfs = \"cf_scalar\"\n",
    "field_country = \"Country\"\n",
    "field_date_string = \"date_string\"\n",
    "field_generation = \"generation_gwh\"\n",
    "field_gwp = \"max_generation_gwp\"\n",
    "field_iso = \"iso_code3\"\n",
    "field_iso_region_attr = \"iso_alpha_3\"\n",
    "field_lat_region = \"latitude_population_centroid_2020\"\n",
    "field_lon_region = \"longitude_population_centroid_2020\"\n",
    "field_key = \"GHD_ID\"\n",
    "field_month = \"month\"\n",
    "field_ndays = \"n_days\"\n",
    "field_weight_month = \"weight_month\"\n",
    "field_weight_tg1 = \"weight_tg1\"\n",
    "field_year = \"year\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  TIME GROUP MANIPULATIONS\n",
    "\n",
    "attr_tg1 = sa.model_attributes.dict_attributes.get(\"ts_group_1\")\n",
    "\n",
    "# format month/time group 1 dictionaries\n",
    "dict_tg1_to_months = dict(\n",
    "    (k, [int(x) for x in v.split(\"|\")]) for k, v in attr_tg1.field_maps.get(f\"{attr_tg1.key}_to_months\").items()\n",
    ")\n",
    "\n",
    "# map each month to the TG1\n",
    "dict_month_to_tg1 = {}\n",
    "for k in dict_tg1_to_months.keys():\n",
    "    mos = dict_tg1_to_months.get(k)\n",
    "    for m in mos:\n",
    "        dict_month_to_tg1.update({m: k})\n",
    "        \n",
    "# build within year weights for ts groups\n",
    "dict_tg1_num_days_weights = {}\n",
    "for k in attr_tg1.key_values:\n",
    "    mos = dict_tg1_to_months.get(k)\n",
    "    total = sum([dict_num_days_per_month_weights.get(x) for x in mos])\n",
    "    dict_tg1_num_days_weights.update({k: total})\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#\n",
    "#    READ DATA FROM Wan et al. Package and monthly results file, \"Plant_monthly_V1.csv\"\n",
    "# \n",
    "\n",
    "dir_data = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/wan_et_al_hydro_model/11283758\"\n",
    "dfs_power_plants = pd.read_excel(os.path.join(dir_data, \"Plant_Database.xlsx\"), sheet_name = \"2 GHD with estimations\")\n",
    "df_generated_simulated = pd.read_csv(os.path.join(dir_data, \"Plant_monthly_V1.csv\"), low_memory = False)\n",
    "\n",
    "\n",
    "##  Note: Had to overwrite \"days\" variable since dayseries() function called in `HP_model.R` does not seem to exist. \n",
    "## The following code shows the creation of that series (also called in this notebook)\n",
    "df_days_per_month = []\n",
    "n_y = 41\n",
    "y_0 = 1975\n",
    "\n",
    "for y in range(y_0, y_0 + n_y + 1):\n",
    "    for m in range(1, 13):\n",
    "        n_day = 29 if ((y%4 == 0) and (m == 2)) else dict_n_days_per_month.get(m)\n",
    "        df_days_per_month.append([y, m, n_day])\n",
    "\n",
    "df_days_per_month = pd.DataFrame(df_days_per_month, columns = [\"year\", \"month\", \"n_days\"])\n",
    "df_days_per_month.to_csv(os.path.join(dir_data, \"n_days.csv\"), index = None, encoding = \"UTF-8\")\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "#    SOME USED FUNCTIONS    #\n",
    "#############################\n",
    "\n",
    "def get_closest_region(\n",
    "    region: str,\n",
    "    attr_region: AttributeTable, \n",
    "    field_iso: str = \"iso_alpha_3\",\n",
    "    field_lat: str = \"latitude_population_centroid_2020\",\n",
    "    field_lon: str = \"longitude_population_centroid_2020\",\n",
    "    missing_flag: float = -999,\n",
    "    regions_valid: Union[List[str], None] = None,\n",
    "    type_input: str = \"region\",\n",
    "    type_return: str = \"region\",\n",
    ") -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Based on latitude/longitude of population centers, find the \n",
    "        closest neighboring region.\n",
    "    \n",
    "    \n",
    "    Function Arguments\n",
    "    ------------------\n",
    "    - region: region to search for closest neighbor\n",
    "    - attr_region: attribute table for regions\n",
    "    \n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    - field_iso: iso field in attr_regin\n",
    "    - field_lat: field storing latitude\n",
    "    - field_lon: field storing longitude\n",
    "    - missing_flag: flag indicating a missing value\n",
    "    - regions_valid: optional list of regions to restrict search to. If None,\n",
    "        searches through all regions specified in attr_region\n",
    "    - type_input: input region type. Either \"region\" or \"iso\"\n",
    "    - type_return: return type. Either \"region\" or \"iso\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ##  INITIALIZATION\n",
    "    \n",
    "    type_return = \"region\" if (type_return not in [\"region\", \"iso\"]) else type_return\n",
    "    type_input = \"region\" if (type_input not in [\"region\", \"iso\"]) else type_input\n",
    "    \n",
    "    # get some dictionaries\n",
    "    dict_region_to_lat = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_lat}\")\n",
    "    dict_region_to_lon = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_lon}\")\n",
    "    dict_iso_to_region = attr_region.field_maps.get(f\"{field_iso}_to_{attr_region.key}\")\n",
    "    dict_region_to_iso = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_iso}\")\n",
    "    \n",
    "    # check region/lat/lon\n",
    "    region = dict_iso_to_region.get(region) if (type_input == \"iso\") else region\n",
    "    region = region if (region in attr_region.key_values) else None\n",
    "    lat, lon = dict_region_to_lat.get(region), dict_region_to_lon.get(region)\n",
    "    \n",
    "    # return None if one of the dimensions is missing\n",
    "    if (lat is None) or (lon is None) or (region is None):\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ##  FILTER TABLE AND APPLY DISTANCES\n",
    "    \n",
    "    if (regions_valid is None):\n",
    "        regions_valid = attr_region.key_values \n",
    "    else:\n",
    "        regions_valid = (\n",
    "            [x for x in attr_region.key_values if x in (regions_valid)]\n",
    "            if type_input == \"region\"\n",
    "            else [x for x in attr_region.key_values if dict_region_to_iso.get(x) in (regions_valid)]\n",
    "        )\n",
    "        \n",
    "    df_regions = attr_region.table[\n",
    "        attr_region.table[attr_region.key].isin(regions_valid)\n",
    "    ].copy().reset_index(drop = True)\n",
    "    \n",
    "    # function to apply\n",
    "    def f(tup: Tuple[float, float]) -> float:\n",
    "        y, x = tuple(tup)\n",
    "        \n",
    "        out = (\n",
    "            -1.0\n",
    "            if (min(y, lat) < -90) or (max(y, lat) > 90) or (min(x, lon) < -180) or (max(x, lon) > 180)\n",
    "            else geopy.distance.geodesic((lat, lon), (y, x)).km\n",
    "        )\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "    vec_dists = np.array(df_regions[[field_lat, field_lon]].apply(f, raw = True, axis = 1))\n",
    "    valid_dists = vec_dists[vec_dists > 0.0]\n",
    "    out = None\n",
    "    \n",
    "    if len(valid_dists) > 0:\n",
    "\n",
    "        m = min(vec_dists)\n",
    "        w = np.where(vec_dists == m)[0]\n",
    "\n",
    "        out = (\n",
    "            list(df_regions[attr_region.key])[w[0]]\n",
    "            if len(w) > 0\n",
    "            else None\n",
    "        )\n",
    "        out = dict_region_to_iso.get(out) if (type_return == \"iso\") else out\n",
    "\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4edf41-1705-4632-9494-78e3cf5f608f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "42f6902a-25c4-4ca0-9ac5-7bf872432afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  CONVERT SIMULATIONS TO LONG FILE\n",
    "\n",
    "\n",
    "regex_match_dates = re.compile(\"(\\d*)-(\\d*)\")\n",
    "cat_name_hydro = \"pp_hydropower\"\n",
    "cat_name_solar = \"pp_solar\"\n",
    "\n",
    "\n",
    "def format_cf(cf:str, field_prepend: str = field_capacity_factor) -> str:\n",
    "    return f\"{field_prepend}_{cf}\"\n",
    "\n",
    "\n",
    "fields_date = [x for x in df_generated_simulated.columns if regex_match_dates.match(x) is not None]\n",
    "\n",
    "# total generation (GWh--see script) per plant\n",
    "df_generated = pd.melt(\n",
    "    df_generated_simulated[[field_key, field_country, \"Install_Act\"] + fields_date],\n",
    "    [field_key, field_country, \"Install_Act\"],\n",
    "    fields_date,\n",
    "    var_name = \"date_string\",\n",
    "    value_name = field_generation\n",
    ").rename(columns = {\"Install_Act\": field_capacity})\n",
    "\n",
    "\n",
    "##  CLEAN DATES TO PREPARE AGGREGATION\n",
    "\n",
    "# function to convert date columns to paired year/month\n",
    "def ds_to_date(\n",
    "    ds: str,\n",
    "    regex_check: re.Pattern = regex_match_dates\n",
    ") -> Tuple[int, int]:\n",
    "    \n",
    "    out = (\n",
    "        tuple([int(x) for x in ds.split(\"-\")])\n",
    "        if regex_check.match(str(ds)) is not None\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    return out\n",
    "\n",
    "df_year_month = pd.DataFrame(list(df_generated[field_date_string].apply(ds_to_date)), columns = [field_year, field_month])\n",
    "df_generated = pd.concat([df_generated, df_year_month], axis = 1).drop([field_date_string], axis = 1)\n",
    "df_generated = pd.merge(df_generated, df_days_per_month)\n",
    "\n",
    "# add potential\n",
    "df_generated[field_gwp] = np.array(df_generated[field_capacity])*np.array(df_generated[field_ndays])*24/1000\n",
    "\n",
    "\n",
    "\n",
    "##  FIRST AGGREGATION -- TOTAL GENERATION/GENERATION POTENTIAL BY COUNTRY, YEAR, AND MONTH\n",
    "\n",
    "fields_group = [field_country, field_year, field_month]\n",
    "fields_agg = [field_generation, field_gwp]\n",
    "dict_agg = dict((x, \"first\") for x in fields_group)\n",
    "dict_agg.update(dict((x, \"sum\") for x in fields_agg))\n",
    "\n",
    "# aggregate, then add an estimated capacity factor\n",
    "df_generated_by_country = df_generated[list(dict_agg.keys())].groupby(fields_group).agg(dict_agg).reset_index(drop = True)\n",
    "df_generated_by_country[format_cf(cat_name_hydro)] = np.array(df_generated_by_country[field_generation])/np.array(df_generated_by_country[field_gwp])\n",
    "\n",
    "\n",
    "##  SECOND AGGREGATION -- MEAN CAPACITYFACTOR BY COUNTRY AND MONTH\n",
    "\n",
    "# number of most recent years to keep \n",
    "n_years_keep = 20\n",
    "\n",
    "fields_group = [field_country, field_month]\n",
    "fields_agg = [format_cf(cat_name_hydro)]\n",
    "dict_agg = dict((x, \"first\") for x in fields_group)\n",
    "dict_agg.update(dict((x, \"mean\") for x in fields_agg))\n",
    "\n",
    "df_gen_for_averages_init = df_generated_by_country.groupby(fields_group)\n",
    "df_gen_for_averages = []\n",
    "\n",
    "for df in df_gen_for_averages_init:\n",
    "    i, df = df\n",
    "    yr_max = max(df[field_year])\n",
    "    yr_min = min(df[field_year])\n",
    "    \n",
    "    year_range = list(range(max(yr_max - n_years_keep + 1, yr_min), yr_max))\n",
    "    \n",
    "    df_gen_for_averages.append(df[df[field_year].isin(year_range)])\n",
    "\n",
    "    \n",
    "##  GET HYDROPOWER CAPACITY FACTOR ESTIMATES\n",
    "\n",
    "df_capacity_factor_hydro = pd.concat(df_gen_for_averages, axis = 0).groupby(fields_group).agg(dict_agg).reset_index(drop = True)\n",
    "df_capacity_factor_hydro[field_country] = [x.lower().replace(\" \", \"_\") for x in df_capacity_factor_hydro[field_country]]\n",
    "df_capacity_factor_hydro[field_country].replace(dict_country_to_iso, inplace = True)\n",
    "df_capacity_factor_hydro.rename(columns = {field_country: field_iso}, inplace = True)\n",
    "\n",
    "# filter out countries \n",
    "df_capacity_factor_hydro = df_capacity_factor_hydro[\n",
    "    df_capacity_factor_hydro[field_iso].isin(dict_country_to_iso.values())\n",
    "].reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "#    FORMAT FOR TIME SLICING    #\n",
    "#################################\n",
    "\n",
    "\n",
    "# adjust fields\n",
    "df_capacity_factor_hydro_by_tg1 = df_capacity_factor_hydro.copy()\n",
    "df_capacity_factor_hydro_by_tg1[model_elec.field_nemomod_tg1] = df_capacity_factor_hydro_by_tg1[field_month].replace(dict_month_to_tg1)\n",
    "\n",
    "# add weights for aggregation\n",
    "df_capacity_factor_hydro_by_tg1[field_weight_month] = df_capacity_factor_hydro_by_tg1[field_month].replace(dict_num_days_per_month_weights)\n",
    "df_capacity_factor_hydro_by_tg1[field_weight_tg1] = df_capacity_factor_hydro_by_tg1[model_elec.field_nemomod_tg1].replace(dict_tg1_num_days_weights)\n",
    "df_capacity_factor_hydro_by_tg1[format_cf(cat_name_hydro)] = np.array(\n",
    "    df_capacity_factor_hydro_by_tg1[format_cf(cat_name_hydro)]\n",
    ")*np.array(\n",
    "    df_capacity_factor_hydro_by_tg1[field_weight_month]\n",
    ")/np.array(df_capacity_factor_hydro_by_tg1[field_weight_tg1])\n",
    "\n",
    "\n",
    "df_cf_avg_hydro_by_tg = sf.simple_df_agg(\n",
    "    df_capacity_factor_hydro_by_tg1,\n",
    "    [field_iso, model_elec.field_nemomod_tg1],\n",
    "    {format_cf(cat_name_hydro): \"sum\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  NEXT, COMBINE SEASONAL VARIATION WITH ANNUAL CAPACITY FACTORS TO ESTIMATE CAPACITY FACTORS BY TIME SLICE\n",
    "\n",
    "# get hydro CF by region/tg1\n",
    "df_cf_hydro_by_ts = pd.merge(\n",
    "    attr_time_slice.table.copy().drop([\"description\"], axis = 1),\n",
    "    df_cf_avg_hydro_by_tg,\n",
    "    how = \"outer\"\n",
    ")[[field_iso, attr_time_slice.key, format_cf(cat_name_hydro)]].sort_values(by = [field_iso, attr_time_slice.key])\n",
    "\n",
    "\n",
    "# fill in missing regions\n",
    "missing_regions = sorted(list(set(dict_iso_to_country.keys()) - set(df_cf_hydro_by_ts[field_iso])))\n",
    "\n",
    "# use closest neighbor (by population) if unavailable\n",
    "if len(missing_regions) > 0:\n",
    "    \n",
    "    df_append = [df_cf_hydro_by_ts]\n",
    "    \n",
    "    for region in missing_regions:\n",
    "        \n",
    "        iso_closest = get_closest_region(\n",
    "            region,\n",
    "            attr_region,\n",
    "            regions_valid = list(set(df_cf_hydro_by_ts[field_iso])),\n",
    "            type_input = \"iso\",\n",
    "            type_return = \"iso\"\n",
    "        )\n",
    "        \n",
    "        if iso_closest is not None:\n",
    "\n",
    "            # fill in missing\n",
    "            df_cur = df_cf_hydro_by_ts[\n",
    "                df_cf_hydro_by_ts[field_iso] == iso_closest\n",
    "            ].copy().reset_index(drop = True)\n",
    "            df_cur[field_iso] = region\n",
    "\n",
    "            df_append.append(df_cur)\n",
    "        \n",
    "    df_cf_hydro_by_ts = pd.concat(df_append).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "# finally, format for input table\n",
    "df_cf_hydro_by_ts[field_iso].replace(dict_iso_to_country, inplace = True)\n",
    "df_cf_hydro_by_ts.rename(columns = {\n",
    "        field_iso: model_elec.field_nemomod_region,\n",
    "        format_cf(cat_name_hydro): cat_name_hydro,\n",
    "        attr_time_slice.key: model_elec.field_nemomod_time_slice\n",
    "    },\n",
    "    inplace = True\n",
    ")\n",
    "df_cf_hydro_by_ts.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d885ae-61c5-44d0-8b81-dafad06184c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6a606c6-cb92-4eea-a4f1-f9b3db0df188",
   "metadata": {},
   "source": [
    "#  Next, generate Solar Capacity Factors from World Bank/Solar Atlas data\n",
    "- Country-wide annual averages are available from WB/Solar Atlas\n",
    "- Use Sunrise/Sunset model coupled with assumptions about time to solar peak (And time after surise/before sunset before generation) at each region's population centroid to generate diurnal irradiance curve (0 at night, e.g.)\n",
    "- Then, combine diurnal irradiance with country-wide average to generate time_slice capacity factors for solar generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "da6cf8ff-ea9c-4e7f-852e-1f542ba7a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_data = pd.read_excel(\n",
    "    \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/solargis_pvpotential_countryranking_2020_data.xlsx\", \n",
    "    sheet_name = \"Monthly data\", \n",
    "    skiprows = [0]\n",
    ")\n",
    "\n",
    "# some fields\n",
    "field_hour = \"hour\"\n",
    "field_hour_group = \"hour_group\"\n",
    "field_time_of_day = \"time_of_day\"\n",
    "field_weight = \"weight\"\n",
    "\n",
    "dict_month_nm_to_num = {\n",
    "    \"January\": 1,\n",
    "    \"February\": 2,\n",
    "    \"March\": 3,\n",
    "    \"April\": 4,\n",
    "    \"May\": 5,\n",
    "    \"June\": 6,\n",
    "    \"July\": 7,\n",
    "    \"August\": 8,\n",
    "    \"September\": 9,\n",
    "    \"October\": 10,\n",
    "    \"November\": 11,\n",
    "    \"December\": 12\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  CLEAN AND REFORMAT\n",
    "\n",
    "dict_rnm = {\"ISO_A3\": field_iso}\n",
    "    \n",
    "df_capacity_factor_solar = df_solar_data[[\"ISO_A3\"] + list(dict_month_nm_to_num.keys())].rename(columns = dict_rnm)\n",
    "df_capacity_factor_solar = df_capacity_factor_solar.melt(\n",
    "    [field_iso],\n",
    "    list(dict_month_nm_to_num.keys()),\n",
    "    var_name = field_month,\n",
    "    value_name = format_cf(cat_name_solar)\n",
    ")\n",
    "\n",
    "# adjust fields\n",
    "df_capacity_factor_solar[field_month].replace(dict_month_nm_to_num, inplace = True)\n",
    "df_capacity_factor_solar[format_cf(cat_name_solar)] /= 24\n",
    "df_capacity_factor_solar[model_elec.field_nemomod_tg1] = df_capacity_factor_solar[field_month].replace(dict_month_to_tg1)\n",
    "\n",
    "# add weights for aggregation\n",
    "df_capacity_factor_solar[field_weight_month] = df_capacity_factor_solar[field_month].replace(dict_num_days_per_month_weights)\n",
    "df_capacity_factor_solar[field_weight_tg1] = df_capacity_factor_solar[model_elec.field_nemomod_tg1].replace(dict_tg1_num_days_weights)\n",
    "df_capacity_factor_solar[format_cf(cat_name_solar)] = np.array(\n",
    "    df_capacity_factor_solar[format_cf(cat_name_solar)]\n",
    ")*np.array(\n",
    "    df_capacity_factor_solar[field_weight_month]\n",
    ")/np.array(df_capacity_factor_solar[field_weight_tg1])\n",
    "\n",
    "\n",
    "df_cf_avg_solar_by_tg = sf.simple_df_agg(\n",
    "    df_capacity_factor_solar,\n",
    "    [field_iso, model_elec.field_nemomod_tg1],\n",
    "    {format_cf(cat_name_solar): \"sum\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#   READ IN SOLAR HOUR GROUP FACTOR SCALARS BY CAPACTITY FACTOR REGION (THESE ARE TEMPORARY)    #\n",
    "#################################################################################################\n",
    "\n",
    "# set up the regular expression to match hour groups on\n",
    "def regex_by_hour_group(\n",
    "    hour_group: int\n",
    ") -> Union[str, None]:\n",
    "    return re.compile(f\"(\\D*)w(\\D*){hour_group}$\")\n",
    "\n",
    "# map time slices to hour group\n",
    "attr_hour = sa.model_attributes.dict_attributes.get(\"hour\")\n",
    "all_hour_groups = sorted(list(set(attr_hour.table[field_hour_group])))\n",
    "\n",
    "dict_time_slice_to_hour_group = {}\n",
    "for hg in all_hour_groups:\n",
    "    regex = regex_by_hour_group(hg)\n",
    "    for time_slice in attr_time_slice.key_values:\n",
    "        if regex.match(time_slice) is not None:\n",
    "            dict_time_slice_to_hour_group.update({time_slice: hg})\n",
    "\n",
    "# initialize the output in terms of hour group\n",
    "df_cf_avg_solar_by_hour_group_base = attr_time_slice.table.copy().drop([\"description\"], axis = 1)\n",
    "df_cf_avg_solar_by_hour_group_base[field_hour_group] = df_cf_avg_solar_by_hour_group_base[\n",
    "    attr_time_slice.key\n",
    "].replace(dict_time_slice_to_hour_group)\n",
    "\n",
    "\n",
    "    \n",
    "##  NEXT, COMBINE SEASONAL VARIATION WITH ANNUAL CAPACITY FACTORS TO ESTIMATE CAPACITY FACTORS BY TIME SLICE\n",
    "\n",
    "df_cf_solar_by_ts = []\n",
    "df_cf_solar_by_ts_wide = None\n",
    "\n",
    "def combine_avg_cf_with_variability_solar(\n",
    "    iso_region: str,\n",
    "    df_cf_avg_solar_by_tg: pd.DataFrame,\n",
    "    df_cf_avg_solar_by_hour_group_base: pd.DataFrame,\n",
    "    field_cf_avg: str = format_cf(cat_name_solar),\n",
    "    field_cfs: str = field_cfs,\n",
    "    field_iso_avg: str = field_iso,\n",
    "    field_iso_attr_region: str = field_iso_region_attr,\n",
    "    field_hour_group: str = field_hour_group,\n",
    "    field_lat: str = field_lat_region,\n",
    "    field_lon: str = field_lon_region,\n",
    "    field_nemomod_tg1: str = model_elec.field_nemomod_tg1,\n",
    "    field_weight: str = field_weight, \n",
    "    model_attributes: ma.ModelAttributes = sa.model_attributes,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For region `iso_region` (3-digit iso), build solar capacity factor\n",
    "        by time slice by scaling average capacity factors to coincide\n",
    "        seasonal and hourly variability.\n",
    "        \n",
    "    NOTE: If any regions are not present in the DataFrame specifying\n",
    "        regional average annual capacity factors, thne the closes region, \n",
    "        by population centroid, is chosen.\n",
    "\n",
    "    \n",
    "    Function Arguments\n",
    "    ------------------\n",
    "    - iso_region: 3-digit ISO Alpha for the region to build curve for\n",
    "    - df_cf_avg_solar_by_tg: DataFrame containing the average solar \n",
    "        capacity factor by NemoMod TimeSlice Group 1 (tg1), which \n",
    "        represents seasonal variation in solar availability\n",
    "    - df_cf_avg_solar_by_hour_group_base: DataFrame containing a map\n",
    "        of time slice to hour group (maps across time slice group names \n",
    "        to hour groups)\n",
    "    \n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    - field_cf_avg: field in df_cf_avg_solar_by_tg that stores the \n",
    "        average region-wide solar capacity factor\n",
    "    - field_cfs: field used to store capacity factor scalar\n",
    "    - field_hour_group: field in time slice attribute (from \n",
    "        model_attributes) that contains the hour group\n",
    "    - field_iso_attr_region: field in attribute_region\n",
    "    - field_iso_avg: iso field in df_cf_avg_solar_by_tg\n",
    "    - field_lat: field in attr_region.table that stores the latitude of\n",
    "        the population centroid (used to determine solar curve)\n",
    "    - field_lon: field in attr_region.table that stores the longitude of\n",
    "    the population centroid (used to determine solar curve)\n",
    "    - field_nemomod_tg1: field to use for time slice group 1 (NemoMod)\n",
    "    - field_weight: field in df_cf_avg_solar_by_hour_group_base that \n",
    "        stores the weight of each time_slice\n",
    "    - model_attributes: ModelAttributes object used to instantiate region\n",
    "        attribute and \n",
    "        region_solar.build_solar_cf_seasonal_component_by_hour()\n",
    "    \"\"\"\n",
    "    \n",
    "    attr_region = model_attributes.dict_attributes.get(\"region\")\n",
    "    attr_tg1 = model_attributes.dict_attributes.get(\"ts_group_1\")\n",
    "    attr_time_slice = model_attributes.dict_attributes.get(\"time_slice\")\n",
    "    \n",
    "    # get average cf for solar\n",
    "    \n",
    "    regions_valid = list(set(df_cf_avg_solar_by_tg[field_iso_avg]))\n",
    "    \n",
    "    # get the region that is used to pull WB data--a few sou\n",
    "    iso_region_filt = (\n",
    "        get_closest_region(\n",
    "            iso_region,\n",
    "            attr_region, \n",
    "            regions_valid = regions_valid,\n",
    "            type_input = \"iso\",\n",
    "            type_return = \"iso\",\n",
    "        )\n",
    "        if iso_region not in regions_valid\n",
    "        else iso_region\n",
    "    )\n",
    "    \n",
    "    df_cf_avg_solar_by_tg_cur = df_cf_avg_solar_by_tg[\n",
    "        df_cf_avg_solar_by_tg[field_iso_avg] == iso_region_filt\n",
    "    ].drop([field_iso_avg], axis = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ##  GET SOLAR IRRADIANCE SCALARS BY HOUR AND AGGREGATE, FOR EACH TS GROUP 1, TO HOUR GROUP\n",
    "    \n",
    "    # build the solar region object using the region_solar object\n",
    "    region_info_cur = list(\n",
    "        attr_region.table[\n",
    "            attr_region.table[field_iso_attr_region] == iso_region\n",
    "        ][[field_iso_attr_region, field_lat, field_lon]].iloc[0]\n",
    "    )\n",
    "    region_solar_obj = bds_reg.region_solar(*region_info_cur)\n",
    "    df_solar_factor_by_season = region_solar_obj.build_solar_cf_seasonal_component_by_hour(sa.model_attributes)\n",
    "    \n",
    "    # any issue with lat/lon, return None\n",
    "    if df_solar_factor_by_season is None:\n",
    "        return None\n",
    "    \n",
    "    #\n",
    "    df_solar_factor_by_season_agg = df_solar_factor_by_season.drop([field_hour], axis = 1).melt(\n",
    "        [field_hour_group],\n",
    "        attr_tg1.key_values,\n",
    "        var_name = field_nemomod_tg1\n",
    "    )\n",
    "\n",
    "    df_solar_factor_by_season_agg = sf.simple_df_agg(\n",
    "        df_solar_factor_by_season_agg,\n",
    "        [field_hour_group, field_nemomod_tg1],\n",
    "        {\"value\": \"mean\"}\n",
    "    )\n",
    "\n",
    "    # merge into aggregate\n",
    "    df_solar_factor_by_season_agg = pd.merge(\n",
    "        df_cf_avg_solar_by_hour_group_base,\n",
    "        df_solar_factor_by_season_agg.rename(columns = {\"value\": field_cfs}),\n",
    "        how = \"left\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    # add in aggregate average \n",
    "    df_solar_factor_by_season_agg = pd.merge(\n",
    "        df_solar_factor_by_season_agg,\n",
    "        df_cf_avg_solar_by_tg_cur,\n",
    "        how = \"left\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ##  NEXT, ITERATE OVER TIME SLICE GROUP 1 TO RESCALE VARIATION TIME SERIES TO MATCH REGION-WIDE AVERAGES\n",
    "    \n",
    "    # group by NemoMod time slice group 1 (seasons)\n",
    "    dfs_group = df_solar_factor_by_season_agg.groupby([field_nemomod_tg1])\n",
    "        \n",
    "    df_cf_solar_by_ts_by_region = []\n",
    "    \n",
    "    for df in dfs_group:\n",
    "        i, df = df\n",
    "\n",
    "        vec_weight = np.array(df[field_weight])\n",
    "        vec_scalar = np.array(df[field_cfs])\n",
    "        vec_cf = np.array(df[field_cf_avg])\n",
    "\n",
    "        # target average capacity factor for this tg1\n",
    "        target = vec_cf[0]\n",
    "\n",
    "        vec_total = vec_weight*(vec_scalar * vec_cf)/vec_weight.sum()\n",
    "        scalar = target/vec_total.sum()\n",
    "\n",
    "        # up capacity factor\n",
    "        vec_cf_new = sf.vec_bounds(vec_scalar * vec_cf * scalar, (0, 1.0))\n",
    "\n",
    "        df_add = df[[attr_time_slice.key]].copy()\n",
    "        df_add[field_cf_avg] = vec_cf_new\n",
    "\n",
    "        df_cf_solar_by_ts_by_region.append(df_add)\n",
    "\n",
    "    df_cf_solar_by_ts_by_region = pd.concat(df_cf_solar_by_ts_by_region, axis = 0).reset_index(drop = True)\n",
    "    df_cf_solar_by_ts_by_region[attr_region.key] = iso_region\n",
    "\n",
    "    return df_cf_solar_by_ts_by_region\n",
    "\n",
    "\n",
    "\n",
    "# loop over regions to build solar capacity factor by time slice\n",
    "for iso_region, region in dict_iso_to_country.items():   \n",
    "    \n",
    "    if region in attr_region.key_values:\n",
    "        df_cf_solar_by_ts_by_region = combine_avg_cf_with_variability_solar(\n",
    "            iso_region, \n",
    "            df_cf_avg_solar_by_tg,\n",
    "            df_cf_avg_solar_by_hour_group_base\n",
    "        ) \n",
    "\n",
    "        # append to long data frame and add to wide data frame, used to generate regional average\n",
    "        df_cf_solar_by_ts.append(df_cf_solar_by_ts_by_region)\n",
    "\n",
    "# get solar cf by time slice (tg1) for all available regions--if unavailable, default to \"cf region\" average\n",
    "df_cf_solar_by_ts = pd.concat(df_cf_solar_by_ts, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# finally, format for input table\n",
    "df_cf_solar_by_ts[attr_region.key].replace(dict_iso_to_country, inplace = True)\n",
    "df_cf_solar_by_ts.rename(\n",
    "    columns = { \n",
    "        attr_region.key: model_elec.field_nemomod_region,\n",
    "        format_cf(cat_name_solar): cat_name_solar,\n",
    "        attr_time_slice.key: model_elec.field_nemomod_time_slice\n",
    "    },\n",
    "    inplace = True\n",
    ")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e46a5-9003-431c-8a18-b9cbc45a667a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9805a4e-ee85-49fe-9521-8472a305fdb8",
   "metadata": {},
   "source": [
    "##  Get other, constant Capacity Factors\n",
    "- 2008-2012 regional averages by technology:\n",
    "    - https://www.eia.gov/todayinenergy/detail.php?id=22832\n",
    "- additional information on Ocean from https://www.nrel.gov/analysis/tech-cap-factor.html\n",
    "- use https://www.pnas.org/doi/10.1073/pnas.2205429119 for other generation sources (biomass, wind, geothermal, fossil, nuclear)\n",
    "- Assume 0.5 in absence of other information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "02b9cc87-d808-4a5f-8325-e6099c0d528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_tech = sa.model_attributes.dict_attributes.get(\"cat_technology\")\n",
    "dict_techs_to_capacity_factors = {\n",
    "    \"pp_biogas\": 0.5,\n",
    "    \"pp_biomass\": 0.37,\n",
    "    \"pp_coal\": 0.36,\n",
    "    #\"pp_coal_ccs\": 0.36,\n",
    "    \"pp_gas\": 0.36,\n",
    "    #\"pp_gas_ccs\": 0.36,\n",
    "    \"pp_geothermal\": 0.67,\n",
    "    \"pp_nuclear\": 0.8,\n",
    "    \"pp_ocean\": 0.25,\n",
    "    \"pp_oil\": 0.36,\n",
    "    \"pp_waste_incineration\": 0.5,\n",
    "    \"pp_wind\": 0.26\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ce3b2-1221-40c6-9649-7a8c2fe2a308",
   "metadata": {},
   "source": [
    "##  Build full dataframe of capacity factor inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "ce05c1ba-12c2-4d45-a1bf-37516b5aab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build full\n",
    "df_capacity_factor = pd.merge(\n",
    "    df_cf_hydro_by_ts,\n",
    "    df_cf_solar_by_ts\n",
    ")\n",
    "\n",
    "for k in dict_techs_to_capacity_factors.keys():\n",
    "    df_capacity_factor[k] = dict_techs_to_capacity_factors.get(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0604851b-f614-431d-b0bd-983d15e9a6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_capacity_factor.to_csv(\n",
    "    sa.dict_fp_csv_nemomod.get(\"CapacityFactor\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5cf84-aea9-4ad8-9cfb-5114067976e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ad6cd-71e7-4c34-b4a9-d63f512a9d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8405d-a0c3-4318-b677-ecfb20c5b57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c90e56c0-2897-43c0-947c-f353a793fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build capacity factors by country\n",
    "\n",
    "df_capacity_factor_base = pd.read_csv(sa.dict_fp_csv_nemomod.get(\"CapacityFactor\"));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92149e42-028e-4c80-9998-452cf23d52fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcea657-0b61-42e2-8766-3da45966eb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207511b6-2942-4cc6-bf79-4eca9ddd0227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede002ea-9f50-41f2-9784-4e3dafd747a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
