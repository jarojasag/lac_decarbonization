{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/python/model_attributes.py:2244: UserWarning: Invalid subsector attribute 'key_varreqs_partial'. Valid return type values are:'pycategory_primary', 'abv_subsector', 'sector', 'abv_sector', 'key_varreqs_all'\n",
      "  warnings.warn(f\"Invalid subsector attribute '{return_type}'. Valid return type values are:{valid_rts}\")\n",
      "/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/python/model_attributes.py:2244: UserWarning: Invalid subsector attribute 'key_varreqs_partial'. Valid return type values are:'pycategory_primary', 'abv_subsector', 'sector', 'abv_sector', 'key_varreqs_all'\n",
      "  warnings.warn(f\"Invalid subsector attribute '{return_type}'. Valid return type values are:{valid_rts}\")\n"
     ]
    }
   ],
   "source": [
    "from attribute_table import AttributeTable\n",
    "import datetime\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import model_attributes as ma\n",
    "import model_afolu as mafl\n",
    "import model_ippu as mi\n",
    "import model_circular_economy as mc\n",
    "import model_energy as me\n",
    "import model_electricity as ml\n",
    "import model_socioeconomic as se\n",
    "from model_socioeconomic import Socioeconomic\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import re\n",
    "import setup_analysis as sa\n",
    "import support_classes as sc\n",
    "import support_functions as sf\n",
    "import time\n",
    "from typing import *\n",
    "import warnings\n",
    "\n",
    "importlib.reload(ma)\n",
    "importlib.reload(sa)\n",
    "importlib.reload(sf)\n",
    "importlib.reload(mafl)\n",
    "importlib.reload(mc)\n",
    "importlib.reload(mi)\n",
    "importlib.reload(me)\n",
    "importlib.reload(se)\n",
    "importlib.reload(ml)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  IMPORT SOME ATTRIBUTES, MODELS, AND SHARED VARIABLES\n",
    "\n",
    "attr_fuel = sa.model_attributes.get_attribute_table(f\"{sa.model_attributes.subsec_name_enfu}\")\n",
    "attr_region = sa.model_attributes.dict_attributes.get(f\"{sa.model_attributes.dim_region}\")\n",
    "attr_technology = sa.model_attributes.get_attribute_table(f\"{sa.model_attributes.subsec_name_entc}\")\n",
    "attr_time_period = sa.model_attributes.dict_attributes.get(f\"dim_{sa.model_attributes.dim_time_period}\")\n",
    "attr_time_slice = sa.model_attributes.dict_attributes.get(f\"time_slice\")\n",
    "\n",
    "# support classes\n",
    "time_periods = sc.TimePeriods(sa.model_attributes)\n",
    "regions = sc.Regions(sa.model_attributes)\n",
    "\n",
    "# set some fields\n",
    "field_country = \"Country\"\n",
    "field_date_string = \"date_string\"\n",
    "field_fraction_production = \"fraction_production\"\n",
    "field_generation = \"generation_gwh\"\n",
    "field_gwp = \"max_generation_gwp\"\n",
    "field_iso = \"iso_code3\"\n",
    "field_iso_region_attr = \"iso_alpha_3\"\n",
    "field_key = \"GHD_ID\"\n",
    "field_latitude = \"latitude_population_centroid_2020\"\n",
    "field_longitude = \"longitude_population_centroid_2020\"\n",
    "field_month = \"month\"\n",
    "field_ndays = \"n_days\"\n",
    "field_technology = \"technology\"\n",
    "field_wb_global_region = \"world_bank_global_region\"\n",
    "field_year = \"year\"\n",
    "\n",
    "# map each country to ISO code 3 and each code to \n",
    "dict_country_to_iso = dict((k, v.upper()) for k, v in attr_region.field_maps.get(f\"{attr_region.key}_to_{field_iso_region_attr}\").items())\n",
    "dict_iso_to_country = sf.reverse_dict(dict_country_to_iso)\n",
    "all_iso = list(dict_iso_to_country.keys())\n",
    "\n",
    "\n",
    "\n",
    "# call variables from the electric model\n",
    "model_elec = ml.ElectricEnergy(sa.model_attributes, sa.dir_jl, sa.dir_ref_nemo, initialize_julia = False)\n",
    "model_energy = me.NonElectricEnergy(sa.model_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Contents\n",
    "\n",
    "This notebook inlcudes several basic datasets:\n",
    "- Basic enery costs (not most current)\n",
    "- Residual Capacities and assumed technology lifetimes\n",
    "- Baseline Minimum Production Shares (MinShareProduction)\n",
    "- Electricity Transmission Loss\n",
    "- Fuel Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Energy Costs from EIA\n",
    "- source: https://www.eia.gov/outlooks/aeo/assumptions/pdf/table_8.2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_read = \"/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/ref/data_tables_and_derivations/ENERGY/eia_outlooks_table_8.2.xlsx\"\n",
    "df_eia = pd.read_excel(fp_read, skiprows = 1).rename(columns = {\n",
    "    \"Unnamed: 0\": \"tech\", \n",
    "    \"Unnamed: 1\": \"year_start\",\n",
    "    \"Total Overnight Cost (2021$/kW)\": \"capital_cost\",\n",
    "    \"Variable O&M (2021 $/MWh)\": \"variable_cost\",\n",
    "    \"Fixed O&M 2021$/kW-y)\": \"fixed_cost\"\n",
    "})\n",
    "\n",
    "fields_group = [\"cat_technology\"]\n",
    "fields_mean = [f\"{x}_cost\" for x in [\"capital\", \"variable\", \"fixed\"]]\n",
    "\n",
    "dict_agg = dict(zip(fields_group, [\"first\" for x in fields_group]))\n",
    "dict_agg.update(dict(zip(fields_mean, [\"mean\" for x in fields_mean])))\n",
    "\n",
    "df_eia = df_eia.groupby(fields_group).agg(dict_agg).reset_index(drop = True).sort_values(by = [\"cat_technology\"])\n",
    "df_eia.to_csv(\"/Users/jsyme/Desktop/tmp.csv\", index = None, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build Residual Capacity Data\n",
    "- See inline source commenting\n",
    "- WRI Global Power Plant database: https://datasets.wri.org/dataset/globalpowerplantdatabase\n",
    "    - Global Energy Observatory, Google, KTH Royal Institute of Technology in Stockholm, Enipedia, World Resources Institute. 2018. Global Power Plant Database. Published on Resource Watch and Google Earth Engine; http://resourcewatch.org/ https://earthengine.google.com/\n",
    "- powerplant level data may be incomplete, so scale to aggregate statistics from UN http://data.un.org/Data.aspx?d=EDATA&f=cmID%3AEC\n",
    "- Ocean (wave and tidal) rough lifetimes and efficiencies from \n",
    "    - Are Wave and Tidal Energy Plants New Green Technologies? MÃ©lanie Douziech, Stefanie Hellweg, and Francesca Verones. Environmental Science & Technology 2016 50 (14), 7870-7878, DOI: 10.1021/acs.est.6b00156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "###                                                  ###\n",
    "###    BUILD NEMOMOD ReserveCapacity INITIAL DATA    ###\n",
    "###                                                  ###\n",
    "########################################################\n",
    "\n",
    "# get data \n",
    "#fp_data = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/LAC_global_power_plant_database.csv\"\n",
    "fp_data = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/global_power_plant_database_v_1_3/global_power_plant_database.csv\"\n",
    "df_data = pd.read_csv(fp_data)\n",
    "# some cleaning of ISO codes\n",
    "df_data[\"country\"].replace(\n",
    "    {\n",
    "        \"KOS\": \"XKX\"\n",
    "    },\n",
    "    inplace = True\n",
    ")\n",
    "\n",
    "##  integrate aggreate production from UN data to scale up Residual Capacities \n",
    "df_un_pp_agg = pd.read_csv(\"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/UNdata_Export_20230307_234559434.csv\")\n",
    "\n",
    "\n",
    "if False:\n",
    "    df_data.dropna(\n",
    "        how = \"all\", \n",
    "        subset = [\"estimated_generation_gwh_2017\", \"estimated_generation_gwh_2016\", \"estimated_generation_gwh_2015\", \"estimated_generation_gwh_2014\", \"estimated_generation_gwh_2013\"],\n",
    "        inplace = True\n",
    "    )\n",
    "\n",
    "# assumed lifetimes (baseline) - add sources to attribute table\n",
    "dict_lifetimes = {\n",
    "    \"Biomass\": 25, # https://www.nrel.gov/analysis/tech-footprint.html\n",
    "    \"Other\": 50, \n",
    "    \"Gas\": 25, # 22, but set to 25 https://www.eia.gov/todayinenergy/detail.php?id=34172\n",
    "    \"Hydro\": 100, # https://www.nrel.gov/docs/fy04osti/34916.pdf\n",
    "    \"Oil\": 40, \n",
    "    \"Nuclear\": 30, # https://www.iaea.org/sites/default/files/29402043133.pdf\n",
    "    \"Coal\": 50, # https://www.nature.com/articles/s41467-019-12618-3\n",
    "    \"Solar\": 30, # https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiExIeGvL35AhVPKkQIHR1ABJMQFnoECBsQAw&url=https%3A%2F%2Fnews.energysage.com%2Fhow-long-do-solar-panels-last%2F&usg=AOvVaw0rJ8w3zaBIP4b83sJgsKcr\n",
    "    \"Wind\": 20, # https://nepis.epa.gov/Exe/ZyNET.exe/P100IL8K.TXT?ZyActionD=ZyDocument&Client=EPA&Index=2011+Thru+2015&Docs=&Query=&Time=&EndTime=&SearchMethod=1&TocRestrict=n&Toc=&TocEntry=&QField=&QFieldYear=&QFieldMonth=&QFieldDay=&IntQFieldOp=0&ExtQFieldOp=0&XmlQuery=&File=D%3A%5Czyfiles%5CIndex%20Data%5C11thru15%5CTxt%5C00000010%5CP100IL8K.txt&User=ANONYMOUS&Password=anonymous&SortMethod=h%7C-&MaximumDocuments=1&FuzzyDegree=0&ImageQuality=r75g8/r75g8/x150y150g16/i425&Display=hpfr&DefSeekPage=x&SearchBack=ZyActionL&Back=ZyActionS&BackDesc=Results%20page&MaximumPages=1&ZyEntry=1&SeekPage=x&ZyPURL\n",
    "    \"Waste\": 30, # https://www.pbs.org/newshour/science/is-burning-trash-a-good-way-to-dispose-of-it-waste-incineration-in-charts,\n",
    "    \"Geothermal\": 30, # https://geothermal-energy-journal.springeropen.com/articles/10.1186/s40517-021-00183-2\n",
    "    \"Ocean\": 34 # mean of 5 plants, from https://pubs.acs.org/doi/10.1021/acs.est.6b00156 ()\n",
    "}\n",
    "\n",
    "# real lifetimes are available here\n",
    "attr_entc = sa.model_attributes.get_attribute_table(sa.model_attributes.subsec_name_entc)\n",
    "dict_lifetimes = attr_entc.field_maps.get(\"cat_technology_to_operational_life\")\n",
    "\n",
    "\n",
    "# TEMPORARY (20230424): DROP `OTHER` POWER PLANTS (AFFECTS ONE IN ALBANIA GLOBALLY) AND COGENERATION (UK and USA ONLYâSISEPUEDE NEEDS WORK TO IMP)\n",
    "fuels_drop = [\"Storage\"]\n",
    "fuels_try_before_drop = [\"Cogeneration\", \"Other\"]\n",
    "# setup a dictionary to map some fuels in the database to SISEPUEDE fuels\n",
    "dict_fuel_repls = {\"Petcoke\": \"Coal\"}\n",
    "\n",
    "# FOR PURPOSES OF INITIAL STATES, SET PETCOKE TO COAL\n",
    "df_data[\"primary_fuel\"].replace(dict_fuel_repls, inplace = True)\n",
    "    \n",
    "    \n",
    "##  FOR OTHER POWER PLANTS, USE FIRST AVAILABLE NON-PRIMARY FUEL \n",
    "\n",
    "# setup regex for other fuel columnsassume less than 10 are specified\n",
    "regex_other_fuel = re.compile(\"other_fuel(\\d$)\")\n",
    "\n",
    "def get_other_fuel_from_other(\n",
    "    row: pd.Series,\n",
    "    dict_repl_fuel: Union[Dict[str, str], None] = None,\n",
    "    fuels_drop: Union[List[str], None] = None,\n",
    "    regex_fuel: re.Pattern = re.compile(\"other_fuel(\\d$)\")\n",
    ") -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Using a row from input data frame, return a fuel based on \"other_fuel\" if\n",
    "        primary_fuel is invalid\n",
    "        \n",
    "    \n",
    "    Function Arguments\n",
    "    ------------------\n",
    "    - row: Pandas series representing a row from a data frame\n",
    "    \n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    - dict_repl_fuel: dictionary of fuels to replace with other fuels\n",
    "    - fuels_drop: optional list of fuels to drop\n",
    "    - regex_fuel: regular expression used to define other_fuels in the row/df\n",
    "    \"\"\"\n",
    "    fields_other_fuel = [x for x in row.index if (regex_other_fuel.match(x) is not None)]\n",
    "    fields_other_fuel.sort()\n",
    "    \n",
    "    if len(fields_other_fuel) == 0:\n",
    "        return None\n",
    "    \n",
    "    fuels_drop = [] if not isinstance(fuels_drop, list) else fuels_drop\n",
    "    \n",
    "    # get locations of potentially valid fuels\n",
    "    vec = np.array(row[fields_other_fuel])\n",
    "    w = [i for i in range(len(vec)) if isinstance(vec[i], str)]\n",
    "    \n",
    "    out = None\n",
    "    \n",
    "    if len(w) > 0:\n",
    "        i = 0\n",
    "        ind_take = -1\n",
    "        while i <= len(w):\n",
    "            ind_take = (\n",
    "                i \n",
    "                if (vec[i] not in fuels_drop) or (vec[i] in dict_repl_fuel.keys())\n",
    "                else ind_take\n",
    "            )\n",
    "            \n",
    "            if (ind_take >= 0):\n",
    "                break \n",
    "            i += 1\n",
    "            \n",
    "        out = vec[w[i]] if (i < len(w)) else out\n",
    "        out = dict_repl_fuel.get(out, out)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "if len(df_data[\"primary_fuel\"][df_data[\"primary_fuel\"].isin(fuels_try_before_drop)]) > 0:\n",
    "    \n",
    "    vec_new_pf = np.array(df_data[\"primary_fuel\"])\n",
    "    \n",
    "    # try for any of the drop fuels\n",
    "    inds = df_data[df_data[\"primary_fuel\"].isin(fuels_try_before_drop)].index\n",
    "    \n",
    "    for i in inds:\n",
    "        \n",
    "        fuel_new = get_other_fuel_from_other(\n",
    "            df_data.iloc[i], \n",
    "            dict_repl_fuel = dict_fuel_repls,\n",
    "            fuels_drop = fuels_drop + fuels_try_before_drop\n",
    "        )\n",
    "        \n",
    "        vec_new_pf[i] = (\n",
    "            fuel_new \n",
    "            if (fuel_new is not None)\n",
    "            else (\n",
    "                \"Solar\"\n",
    "                if (df_data[\"name\"].iloc[i] == \"Sol\")\n",
    "                else vec_new_pf[i]\n",
    "            )\n",
    "        )\n",
    "     \n",
    "    df_data[\"primary_fuel\"] = vec_new_pf\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "# CONVERT TO FORMAT COMPATIBLE WITH SISEPUEDE\n",
    "\n",
    "df_data[\"primary_fuel\"] = df_data[\"primary_fuel\"].replace(\n",
    "    {\n",
    "        \"Hydro\": \"Hydropower\",\n",
    "        \"Waste\": \"Waste Incineration\",\n",
    "        \"Wave and Tidal\": \"Ocean\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# drop any remainining instances of invalid fuels\n",
    "df_data = df_data[\n",
    "    ~df_data[\"primary_fuel\"].isin(fuels_drop + fuels_try_before_drop)\n",
    "].reset_index(drop = True)\n",
    "\n",
    "all_fuel = list(set(df_data[\"primary_fuel\"]))\n",
    "dict_repl_fuel = {}\n",
    "for fuel in all_fuel:\n",
    "    fuel_new = fuel.lower().replace(\" \", \"_\")\n",
    "    fuel_new = f\"pp_{fuel_new}\"\n",
    "    dict_repl_fuel.update({fuel: fuel_new})\n",
    "df_data[\"primary_fuel\"] = df_data[\"primary_fuel\"].replace(dict_repl_fuel)\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "#    FILL IN MISSING COMMISSIONING YEARS    #\n",
    "#############################################\n",
    "\n",
    "#\n",
    "# TO FILL MISSING COMMISSION YEARS, GET MEAN COMMISSION YEAR FOR PLANTS BY TYPE IN LAC\n",
    "# - USE RANDOM NUMBERS WITH A SEED\n",
    "# - NEED TO ESTIMATE WHEN EXISTING PLANTS GO OFFLINE\n",
    "# - CAN IMPROVE WITH BETTER INFORMATION LATER\n",
    "#\n",
    "\n",
    "# add some really rough numbers for commissionoing years for some plants where there are NO commissioning year data\n",
    "dict_years_commission = {\n",
    "    # see \n",
    "    \"pp_ocean\": {\n",
    "        # https://en.wikipedia.org/wiki/European_Marine_Energy_Centre\n",
    "        #     \"ANDRITZ HYDRO Hammerfest installed their 1MW HS1000 tidal energy converter in 2011\"\n",
    "        \"Hammerfest (EMEC)\": 2011,\n",
    "        # https://en.wikipedia.org/wiki/European_Marine_Energy_Centre\n",
    "        #     \"The test site was officially opened by Scotland's First Minister in September 2007\"\n",
    "        \"Fall of Warness Tidal Demonstrator (EMEC)\": 2007,\n",
    "        # https://en.wikipedia.org/wiki/Wave_Hub\n",
    "        \"Hayle Wave Hub (Test Site)\": 2010,\n",
    "        # https://www.nsenergybusiness.com/projects/meygen-tidal-power-project/\n",
    "        #    Offshore installation works for the initial 6MW project was completed in October 2016, while the first electricity was exported to the grid in the month that followed\n",
    "        \"Inner Sound Phase 1A (MeyGen)\": 2016,\n",
    "    }\n",
    "}\n",
    "\n",
    "all_plants = list(set(df_data[\"primary_fuel\"]))\n",
    "dict_mean_commission_year_by_plant = {}\n",
    "dict_mean_commission_year_by_plant_by_country = {}\n",
    "dict_std_commission_year_by_plant = {}\n",
    "dict_std_commission_year_by_plant_by_country = {}\n",
    "\n",
    "# get global averages\n",
    "for plant in all_plants:\n",
    "\n",
    "    df_tmp = df_data[df_data[\"primary_fuel\"] == plant]   \n",
    "\n",
    "    if len(df_tmp) > 0:\n",
    "\n",
    "        yr_mean_commission = np.array(df_tmp[\"commissioning_year\"])\n",
    "        yr_mean_commission = yr_mean_commission[np.where(~np.isnan(yr_mean_commission))[0]]\n",
    "\n",
    "        if len(yr_mean_commission) == 0:\n",
    "            yr_mean_commission = dict_years_commission.get(plant)\n",
    "            yr_mean_commission = (\n",
    "                np.array(list(yr_mean_commission.values()))\n",
    "                if yr_mean_commission is not None\n",
    "                else np.array([])\n",
    "            )\n",
    "\n",
    "        yr_std_commission = np.std(yr_mean_commission)\n",
    "        yr_mean_commission = int(np.round(np.mean(yr_mean_commission)))\n",
    "\n",
    "        dict_mean_commission_year_by_plant.update({plant: yr_mean_commission})\n",
    "        dict_std_commission_year_by_plant.update({plant: yr_std_commission})\n",
    "            \n",
    "\n",
    "##  GET MEANS BY COUNTRY\n",
    "\n",
    "df_data_grouped = df_data.groupby([field_country.lower()])\n",
    "\n",
    "for iso, df in df_data_grouped:\n",
    "\n",
    "    dict_mean_commission_year_by_plant_by_country.update({iso: {}})\n",
    "    dict_std_commission_year_by_plant_by_country.update({iso: {}})\n",
    "    \n",
    "    for plant in all_plants:\n",
    "        \n",
    "        df_tmp = df[df[\"primary_fuel\"] == plant]   \n",
    "        \n",
    "        if len(df_tmp) > 0:\n",
    "            \n",
    "            yr_mean_commission = np.array(df_tmp[\"commissioning_year\"])\n",
    "            yr_mean_commission = yr_mean_commission[np.where(~np.isnan(yr_mean_commission))[0]]\n",
    "            \n",
    "            if len(yr_mean_commission) == 0:\n",
    "                yr_mean_commission = dict_mean_commission_year_by_plant.get(plant)\n",
    "                yr_std_commission = dict_std_commission_year_by_plant.get(plant)\n",
    "            \n",
    "            else: \n",
    "                yr_std_commission = np.std(yr_mean_commission)\n",
    "                yr_mean_commission = int(np.round(np.mean(yr_mean_commission)))\n",
    "            \n",
    "            dict_mean_commission_year_by_plant_by_country[iso].update({plant: yr_mean_commission})\n",
    "            dict_std_commission_year_by_plant_by_country[iso].update({plant: yr_std_commission})\n",
    "\n",
    "            \n",
    "            \n",
    "# initialize some components\n",
    "countries_iso = list(set(df_data[field_country.lower()]))\n",
    "countries_iso.sort()\n",
    "df_years = pd.DataFrame({\"year\": range(1920, 2056)})\n",
    "# \n",
    "max_year_commission = 2020\n",
    "\n",
    "# set a seed - I just chose 50 - and get some last-line numbers for sampling\n",
    "np.random.seed(50)\n",
    "commission_year_no_info = np.mean(df_data[\"commissioning_year\"].dropna()).astype(int)\n",
    "std_no_info = np.std(df_data[\"commissioning_year\"].dropna()).astype(int)\n",
    "\n",
    "df_out_total = []\n",
    "\n",
    "\n",
    "for ind_country, country_iso in enumerate(countries_iso):\n",
    "    \n",
    "    df_tmp = df_data[df_data[field_country.lower()] == country_iso].copy().reset_index(drop = True)\n",
    "    \n",
    "    # check commision years\n",
    "    df_na_comissions = df_tmp[df_tmp[\"commissioning_year\"].isna()]\n",
    "    inds_na_commissions = df_na_comissions.index\n",
    "    \n",
    "    for i, ind in enumerate(inds_na_commissions):\n",
    "        plant = str(df_na_comissions[\"primary_fuel\"].iloc[i])\n",
    "        \n",
    "        mu = dict_mean_commission_year_by_plant_by_country.get(country_iso)\n",
    "        mu = mu.get(plant) if (mu is not None) else commission_year_no_info\n",
    "        \n",
    "        sd = dict_std_commission_year_by_plant_by_country.get(country_iso)\n",
    "        sd = sd.get(plant) if (sd is not None) else std_no_info\n",
    "        \n",
    "        rand_yr = int(min(np.random.normal(mu, sd), max_year_commission))\n",
    "        df_tmp[\"commissioning_year\"].iloc[ind] = rand_yr\n",
    "        \n",
    "\n",
    "    df_years_tmp = []\n",
    "    df_years_out = df_years.copy()\n",
    "    \n",
    "    for i in range(len(df_tmp)):\n",
    "        field_plant = f\"plant_{i}\"\n",
    "        plant = str(df_tmp[\"primary_fuel\"].iloc[i])\n",
    "        commission_year = int(df_tmp[\"commissioning_year\"].iloc[i])\n",
    "        lifetime = dict_lifetimes.get(plant)\n",
    "        capacity = float(df_tmp[\"capacity_mw\"].iloc[i])\n",
    "        \n",
    "        df_years_merge = pd.DataFrame({\n",
    "            \"year\": range(commission_year, commission_year + lifetime), \n",
    "            \"capacity\": capacity,\n",
    "            \"plant\": plant\n",
    "        })\n",
    "        \n",
    "        if len(df_years_tmp) == 0:\n",
    "            df_years_tmp = [df_years_merge for x in range(len(df_tmp))]\n",
    "        else:\n",
    "            df_years_tmp[i] = df_years_merge[df_years_tmp[0].columns]\n",
    "            \n",
    "    df_years_tmp = pd.concat(df_years_tmp, axis = 0)\n",
    "    df_years_tmp = df_years_tmp.groupby([\"year\", \"plant\"]).agg({\"year\": \"first\", \"plant\": \"first\", \"capacity\": \"sum\"}).reset_index(drop = True)\n",
    "    #\n",
    "    df_years_out = pd.merge(df_years_out, df_years_tmp, how = \"left\")\n",
    "    df_years_out[\"capacity\"] = df_years_out[\"capacity\"].fillna(0)\n",
    "    df_years_out = df_years_out.dropna(how = \"any\", subset = [\"plant\"]).sort_values(by = [\"year\", \"plant\"]).reset_index(drop = True)\n",
    "    df_years_out[field_country.lower()] = dict_iso_to_country.get(country_iso);\n",
    "    \n",
    "    df_years_out = (\n",
    "        pd.pivot(\n",
    "            df_years_out,\n",
    "            [\"year\", field_country.lower()], \n",
    "            [\"plant\"], \n",
    "            \"capacity\"\n",
    "        )\n",
    "        .reset_index()\n",
    "        .dropna(subset = [field_country.lower()])\n",
    "    )\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    for k in df_years_out.columns:\n",
    "        df_out[k] = df_years_out[k].copy().fillna(0.0)\n",
    "        \n",
    "    \n",
    "    if len(df_out_total) == 0:\n",
    "        df_out_total = [df_out for x in countries]\n",
    "    else:\n",
    "        df_out_total[ind_country] = df_out\n",
    "    \n",
    "df_out_total = pd.concat(df_out_total, axis = 0).fillna(0)\n",
    "\n",
    "\n",
    "##  FORMAT VARIABLES FOR INGESTION\n",
    "\n",
    "model_elec = ml.ElectricEnergy(\n",
    "    sa.model_attributes, \n",
    "    sa.dir_jl,\n",
    "    sa.dir_ref_nemo,\n",
    "    initialize_julia = False\n",
    ")\n",
    "\n",
    "fields_rnm = [x for x in attr_entc.key_values if x in df_out_total.columns]\n",
    "fields_new = sa.model_attributes.build_varlist(\n",
    "    \"Energy Technology\", model_elec.modvar_entc_nemomod_residual_capacity,\n",
    "    restrict_to_category_values = fields_rnm\n",
    ")\n",
    "dict_rnm = dict(zip(fields_rnm, fields_new))\n",
    "\n",
    "#\n",
    "#  do units conversion\n",
    "#\n",
    "\n",
    "units_target = sa.model_attributes.get_variable_characteristic(\n",
    "    model_elec.modvar_entc_nemomod_residual_capacity, \n",
    "    sa.model_attributes.varchar_str_unit_power\n",
    ")\n",
    "scalar = sa.model_attributes.get_power_equivalent(\"mw\", units_target)\n",
    "\n",
    "for field in fields_rnm:\n",
    "    df_out_total[field] = np.array(df_out_total[field])*scalar\n",
    "\n",
    "\n",
    "df_out_total.rename(columns = dict_rnm, inplace = True)\n",
    "fields_ind = [x for x in [\"year\", \"country\"] if x in df_out_total.columns]\n",
    "fields_dat = sorted([x for x in df_out_total.columns if (x not in fields_ind)])\n",
    "\n",
    "df_out_total = df_out_total[fields_ind + fields_dat]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "###                                                         ###\n",
    "###    ADD UN AGGREGATE DATA TO SCALE UP WHERE NECESSARY    ###\n",
    "###                                                         ###\n",
    "###############################################################\n",
    "\n",
    "field_total_capacity = f\"total_capacity_{units_target}\"\n",
    "df_out_total[field_total_capacity] = df_out_total[fields_new].sum(axis = 1)\n",
    "\n",
    "\n",
    "#attr_region.table[attr_region.table[attr_region.key] == \"montenegro\"]\n",
    "\n",
    "dict_repl_un = {\n",
    "    \"Bolivia (Plur. State of)\": \"Bolivia\",\n",
    "    \"Central African Rep.\": \"Central African Republic\",\n",
    "    \"China, Hong Kong SAR\": \"Hong Kong SAR, China\",\n",
    "    \"China, Macao SAR\": \"Macao SAR, China\",\n",
    "    \"CÃ´te d'Ivoire\": \"Cote d'Ivoire\",\n",
    "    \"Congo\": \"Republic of the Congo\",\n",
    "    \"Congo, Rep.\": \"Republic of the Congo\",\n",
    "    \"Congo, Dem. Rep.\": \"Democratic Republic of the Congo\",\n",
    "    \"Dem. Rep. of the Congo\": \"Democratic Republic of the Congo\",\n",
    "    \"CuraÃ§ao\": \"Curacao\",\n",
    "    \"Ethiopia PDR\": \"Ethiopia\",\n",
    "    \"Faeroe Islands\": \"Faroe Islands\",\n",
    "    \"Gambia, The\": \"Gambia\",\n",
    "    \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "    \"Iran (Islamic Rep. of)\": \"Iran\",\n",
    "    \"United Kingdom of Great Britain and Northern Ireland\": \"United Kingdom\",\n",
    "    \"Korea, Dem. People's Rep.\": \"Democratic People's Republic of Korea\",\n",
    "    \"Korea, Dem.Ppl's.Rep.\": \"Democratic People's Republic of Korea\",\n",
    "    \"Korea\": \"Republic of Korea\",\n",
    "    \"Korea, Republic of\": \"Republic of Korea\",\n",
    "    \"Kyrgyz Republic\": \"Kyrgyzstan\",\n",
    "    \"Lao PDR\": \"Lao People's Democratic Republic\",\n",
    "    \"Lao People's Dem. Rep.\": \"Lao People's Democratic Republic\",\n",
    "    \"Micronesia, Fed. Sts.\": \"Micronesia (Federated States of)\",\n",
    "    \"Micronesia (Fed. States of)\": \"Micronesia (Federated States of)\",\n",
    "    \"Moldova\": \"Republic of Moldova\",\n",
    "    \"St. Kitts and Nevis\": \"Saint Kitts and Nevis\",\n",
    "    \"St. Kitts-Nevis\": \"Saint Kitts and Nevis\",\n",
    "    \"St. Martin (French part)\": \"Saint-Martin (French part)\",\n",
    "    \"St. Vincent and the Grenadines\": \"Saint Vincent and the Grenadines\",\n",
    "    \"St. Vincent-Grenadines\": \"Saint Vincent and the Grenadines\",\n",
    "    \"Slovak Republic\": \"Slovakia\",\n",
    "    \"St. Lucia\": \"Saint Lucia\",\n",
    "    \"Tanzania\": \"United Republic of Tanzania\",\n",
    "    \"TÃ¼rkiye\": \"Turkey\",\n",
    "    \"United Rep. of Tanzania\": \"United Republic of Tanzania\",\n",
    "    \"United States\": \"United States of America\",\n",
    "    \"Venezuela (Bolivarian Republic of)\": \"Venezuela\",\n",
    "    \"Venezuela (Bolivar. Rep.)\": \"Venezuela\",\n",
    "    \"Vietnam\": \"Viet Nam\",\n",
    "    \"Virgin Islands (U.S.)\": \"United States Virgin Islands\",\n",
    "    \"United States Virgin Is.\": \"United States Virgin Islands\",\n",
    "    \"Yemen, Rep.\": \"Yemen\",\n",
    "}\n",
    "\n",
    "# ok to drop\n",
    "# Anguilla - Britain\n",
    "# Bonaire, St Eustatius, Saba - Netherlands\n",
    "# Cook Islands - Free association with New Zealand\n",
    "# Ethiopia, incl. Eritrea - no longer exists\n",
    "# Falkland - na\n",
    "# French Guiana - France\n",
    "# Guernsey - dutch protectorate\n",
    "# Jersey - dutch protectorate\n",
    "# Martinique - France\n",
    "# Mayotte - France\n",
    "# Montserrat - Britain\n",
    "# Niue - \"free association with New Zealand\"\n",
    "# RÃ©union - France\n",
    "# Serbia and Montenegro - no longer exists\n",
    "# St. Helena and Depend. - UK dependency\n",
    "# St. Pierre-Miquelon - France\n",
    "# Wallis and Futuna - France\n",
    "\n",
    "\n",
    "# some basic fields\n",
    "field_capacity = \"capacity\"\n",
    "field_commodity = \"Commodity - Transaction\"\n",
    "field_plant_type = \"plant_type_un\"\n",
    "\n",
    "# map power plants to grouping in UN\n",
    "dict_plant_to_subgroup = {\n",
    "    \"pp_biogas\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_biomass\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_coal\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_coal_ccs\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_geothermal\": \"Electricity - total net installed capacity of electric power plants, geothermal\",\n",
    "    \"pp_hydropower\": \"Electricity - total net installed capacity of electric power plants, hydro\",\n",
    "    \"pp_gas\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_gas_ccs\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_nuclear\": \"Electricity - total net installed capacity of electric power plants, nuclear\",\n",
    "    \"pp_ocean\": \"Electricity - total net installed capacity of electric power plants, tide, wave, marine\",\n",
    "    \"pp_oil\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_solar\": \"Electricity - total net installed capacity of electric power plants, solar\",\n",
    "    \"pp_waste_incineration\": \"Electricity - total net installed capacity of electric power plants, combustible fuels\",\n",
    "    \"pp_wind\": \"Electricity - total net installed capacity of electric power plants, wind\"\n",
    "}\n",
    "\n",
    "# reduce to scale to aggregate installed capacity\n",
    "df_capacity_un_total = df_un_pp_agg[\n",
    "    df_un_pp_agg[\"Commodity - Transaction\"].isin(\n",
    "        [\n",
    "            \"Electricity - total net installed capacity of electric power plants, main activity & autoproducer\"\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "df_capacity_un_by_subgroup = df_un_pp_agg[\n",
    "    df_un_pp_agg[\"Commodity - Transaction\"].isin(\n",
    "        dict_plant_to_subgroup.values()\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "##  CLEAN THE DATA\n",
    "\n",
    "field_cat_nam = \"category_name\"\n",
    "# rename\n",
    "dict_rnm = {\n",
    "    \"Country or Area\": field_cat_nam, #attr_region.key,\n",
    "    \"Year\": field_year,\n",
    "    \"Quantity\": field_capacity,\n",
    "    field_commodity: field_plant_type\n",
    "}\n",
    "df_capacity_un_total = df_capacity_un_total[dict_rnm.keys()].rename(columns = dict_rnm).drop(field_plant_type, axis = 1)\n",
    "df_capacity_un_by_subgroup = df_capacity_un_by_subgroup[dict_rnm.keys()].rename(columns = dict_rnm)\n",
    "# replace country names\n",
    "df_capacity_un_total[field_cat_nam].replace(dict_repl_un, inplace = True)\n",
    "df_capacity_un_by_subgroup[field_cat_nam].replace(dict_repl_un, inplace = True)\n",
    "\n",
    "\n",
    "# UN data are in mw\n",
    "units_target = sa.model_attributes.get_variable_characteristic(\n",
    "    model_elec.modvar_entc_nemomod_residual_capacity, \n",
    "    sa.model_attributes.varchar_str_unit_power\n",
    ")\n",
    "scalar = sa.model_attributes.get_power_equivalent(\"mw\", units_target)\n",
    "\n",
    "\n",
    "# merge in region key\n",
    "df_capacity_un_by_subgroup = (\n",
    "    pd.merge(\n",
    "        df_capacity_un_by_subgroup,\n",
    "        attr_region.table[[field_cat_nam, attr_region.key]],\n",
    "        how = \"inner\"\n",
    "    )\n",
    "    .drop([field_cat_nam], axis = 1)\n",
    ")\n",
    "\n",
    "df_capacity_un_total = (\n",
    "    pd.merge(\n",
    "        df_capacity_un_total,\n",
    "        attr_region.table[[field_cat_nam, attr_region.key]],\n",
    "        how = \"inner\"\n",
    "    )\n",
    "    .drop([field_cat_nam], axis = 1)\n",
    ")\n",
    "\n",
    "# standardize index fields - subgroups\n",
    "df_capacity_un_by_subgroup[field_year] = np.array(df_capacity_un_by_subgroup[field_year]).astype(int)\n",
    "df_capacity_un_by_subgroup[attr_time_period.key] = df_capacity_un_by_subgroup[field_year].apply(time_periods.year_to_tp)\n",
    "df_capacity_un_by_subgroup[field_capacity] = np.array(df_capacity_un_by_subgroup[field_capacity])*scalar\n",
    "# standardize index fields - total\n",
    "df_capacity_un_total[field_year] = np.array(df_capacity_un_total[field_year]).astype(int)\n",
    "df_capacity_un_total[attr_time_period.key] = df_capacity_un_total[field_year].apply(time_periods.year_to_tp)\n",
    "df_capacity_un_total[field_capacity] = np.array(df_capacity_un_total[field_capacity])*scalar\n",
    "\n",
    "\n",
    "##  BUILD SCALARS\n",
    "\n",
    "field_scale_residual_capacity = \"scalar_residual_capacity\"\n",
    "df_get_scalars = pd.merge(\n",
    "    df_out_total[[field_year, field_country.lower(), field_total_capacity]],\n",
    "    df_capacity_un_total.rename(\n",
    "        columns = {\n",
    "            field_capacity: f\"{field_capacity}_un\",\n",
    "            attr_region.key: field_country.lower()\n",
    "        }\n",
    "    ),\n",
    "    how = \"left\"\n",
    ").dropna()\n",
    "\n",
    "df_get_scalars[field_scale_residual_capacity] = sf.vec_bounds(\n",
    "    np.nan_to_num(\n",
    "        np.array(df_get_scalars[f\"{field_capacity}_un\"])/np.array(df_get_scalars[field_total_capacity]),\n",
    "        0.0,\n",
    "        posinf = 0.0\n",
    "    ),\n",
    "    (1, np.inf)\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "# get scalars by region to convert power plants to aggregate metrics from UN\n",
    "df_scalars_by_region = df_get_scalars.groupby([field_country.lower()])\n",
    "df_scalars_by_region_cln = []\n",
    "df_left = pd.DataFrame({field_year: list(range(min(df_get_scalars[\"year\"]), max(df_out_total[field_year]) + 1))})\n",
    "for i, df in df_scalars_by_region:\n",
    "    # get last residual capacity scalar\n",
    "    df = df.sort_values(by = [field_year], ascending = False)\n",
    "    scalar_final = float(df[field_scale_residual_capacity].iloc[0])\n",
    "\n",
    "    df = pd.merge(\n",
    "        df_left, \n",
    "        df[[field_year, field_country.lower(), field_scale_residual_capacity]], \n",
    "        how = \"left\"\n",
    "    )\n",
    "\n",
    "    df[field_country.lower()] = i\n",
    "    df[field_scale_residual_capacity].interpolate(method = \"pad\", inplace = True)\n",
    "    df[field_scale_residual_capacity].interpolate(method = \"bfill\", inplace = True)\n",
    "\n",
    "    df_scalars_by_region_cln.append(df)\n",
    "\n",
    "df_scalars_by_region = pd.concat(df_scalars_by_region_cln, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "# MERGE INTO DF_OUT_TOTAL\n",
    "\n",
    "df_out_total_rescaled = pd.merge(\n",
    "    df_out_total,\n",
    "    df_scalars_by_region,\n",
    "    how = \"left\"\n",
    ")\n",
    "df_out_total_rescaled[field_scale_residual_capacity].interpolate(method = \"bfill\", inplace = True)\n",
    "\n",
    "# finally, provide rescale\n",
    "for fld in fields_new:\n",
    "    df_out_total_rescaled[fld] = np.array(df_out_total_rescaled[fld])*np.array(df_out_total_rescaled[field_scale_residual_capacity])\n",
    "\n",
    "\n",
    "df_out_total_rescaled.rename(\n",
    "    columns = {\n",
    "        field_country.lower(): attr_region.key\n",
    "    }, \n",
    "    inplace = True\n",
    ")\n",
    "\n",
    "df_out_total_rescaled = pd.merge(\n",
    "    df_out_total_rescaled,\n",
    "    attr_region.table[[attr_region.key, field_iso_region_attr]],\n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "df_out_total_rescaled = df_out_total_rescaled[[field_year, attr_region.key, field_iso_region_attr] + fields_new]\n",
    "\n",
    "\n",
    "if True:\n",
    "    df_out_total_rescaled.to_csv(\n",
    "        sa.fp_csv_nemomod_residual_capacity_inputs, \n",
    "        index = None,\n",
    "        encoding = \"UTF-8\"\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "regex_gen_capacity = re.compile(\"generation_gwh_(\\d*$)\")\n",
    "fields_gen_capac = [x for x in df_data.columns if regex_gen_capacity.match(x) is not None]\n",
    "\n",
    "df_data.dropna(subset = fields_gen_capac, how = \"all\")[\"country\"].unique()\n",
    "#df_data.columns\n",
    "\"\"\";\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'support_functions' from '/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/python/support_functions.py'>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_production_fractions_mean = sf.explode_merge(\n",
    "        pd.DataFrame({\n",
    "            field_year: sorted(list(df_production_fractions_annual[field_year].unique()))\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            field_iea_product: sorted(list(df_production_fractions_annual[field_iea_product].unique()))\n",
    "        })\n",
    "    )\n",
    "    df_production_fractions_mean = sf.explode_merge(\n",
    "        df_production_fractions_mean,\n",
    "        pd.DataFrame({\n",
    "            field_country: sorted(list(df_production_fractions_annual[field_country].unique()))\n",
    "        })\n",
    "    )\n",
    "    df_production_fractions_mean = (\n",
    "        pd.merge(\n",
    "            df_production_fractions_mean, \n",
    "            df_production_fractions_annual,\n",
    "            how = \"left\"\n",
    "        )\n",
    "        #.drop([field_year], axis = 1)\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Build MinShareProduction data \n",
    "- Currently read in aggregate, based on Monthly Data from IEA\n",
    "- Used to ensure historical production aligns\n",
    "\n",
    "**NOTE** will require integrating additional code to aggregate monthly data\n",
    "- Based on IEA monthly electricity generation data\n",
    "- See https://www.iea.org/data-and-statistics/data-product/monthly-electricity-statistics#monthly-electricity-statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No MSP found for region 'ABW' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'AFG' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'AGO' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'ALB' -- using value from closest neighbor (in WB Region) 'MKD' \n",
      "No MSP found for region 'AND' -- using value from closest neighbor (in WB Region) 'FRA' \n",
      "No MSP found for region 'ARE' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'ARM' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'ASM' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'ATG' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'AZE' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'BDI' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'BEN' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'BFA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'BGD' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'BHR' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'BHS' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'BIH' -- using value from closest neighbor (in WB Region) 'HRV' \n",
      "No MSP found for region 'BLR' -- using value from closest neighbor (in WB Region) 'LTU' \n",
      "No MSP found for region 'BLZ' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'BMU' -- using value from closest neighbor (in WB Region) 'CAN' \n",
      "No MSP found for region 'BOL' -- using value from closest neighbor (in WB Region) 'ARG' \n",
      "No MSP found for region 'BRB' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'BRN' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'BTN' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'BWA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'CAF' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'CIV' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'CMR' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'COD' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'COG' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'COM' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'CPV' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'CUB' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'CUW' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'CYM' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'DJI' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'DMA' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'DOM' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'DZA' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'ECU' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'EGY' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'ERI' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'ETH' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'FJI' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'FRO' -- using value from closest neighbor (in WB Region) 'ISL' \n",
      "No MSP found for region 'FSM' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'GAB' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'GEO' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'GHA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'GIB' -- using value from closest neighbor (in WB Region) 'ESP' \n",
      "No MSP found for region 'GIN' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'GMB' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'GNB' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'GNQ' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'GRD' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'GRL' -- using value from closest neighbor (in WB Region) 'ISL' \n",
      "No MSP found for region 'GTM' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'GUM' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'GUY' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'HKG' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'HND' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'HTI' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'IDN' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'IMN' -- using value from closest neighbor (in WB Region) 'IRL' \n",
      "No MSP found for region 'IRN' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'IRQ' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'ISR' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'JAM' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'JOR' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'KAZ' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'KEN' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'KGZ' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'KHM' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'KIR' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'KNA' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'KWT' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'LAO' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'LBN' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'LBR' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'LBY' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'LCA' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'LIE' -- using value from closest neighbor (in WB Region) 'CHE' \n",
      "No MSP found for region 'LKA' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'LSO' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MAC' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'MAF' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'MAR' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'MCO' -- using value from closest neighbor (in WB Region) 'CHE' \n",
      "No MSP found for region 'MDA' -- using value from closest neighbor (in WB Region) 'ROU' \n",
      "No MSP found for region 'MDG' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MDV' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'MHL' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'MLI' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MMR' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'MNE' -- using value from closest neighbor (in WB Region) 'MKD' \n",
      "No MSP found for region 'MNG' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'MNP' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'MOZ' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MRT' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MUS' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MWI' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'MYS' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'NAM' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'NCL' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'NER' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'NGA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'NIC' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'NPL' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'NRU' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'OMN' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'PAK' -- using value from closest neighbor (in WB Region) 'IND' \n",
      "No MSP found for region 'PAN' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'PER' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'PHL' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'PLW' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'PNG' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'PRI' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'PRK' -- using value from closest neighbor (in WB Region) 'KOR' \n",
      "No MSP found for region 'PRY' -- using value from closest neighbor (in WB Region) 'ARG' \n",
      "No MSP found for region 'PYF' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'QAT' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'RUS' -- using value from closest neighbor (in WB Region) 'EST' \n",
      "No MSP found for region 'RWA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SAU' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'SDN' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SEN' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SGP' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'SLB' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'SLE' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SLV' -- using value from closest neighbor (in WB Region) 'CRI' \n",
      "No MSP found for region 'SMR' -- using value from closest neighbor (in WB Region) 'ITA' \n",
      "No MSP found for region 'SOM' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SSD' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'STP' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SUR' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'SWZ' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SXM' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'SYC' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'SYR' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'TCA' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'TCD' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'TGO' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'THA' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'TJK' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'TKM' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'TLS' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'TON' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'TTO' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'TUN' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'TUV' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'TZA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'UGA' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'UKR' -- using value from closest neighbor (in WB Region) 'ROU' \n",
      "No MSP found for region 'URY' -- using value from closest neighbor (in WB Region) 'ARG' \n",
      "No MSP found for region 'UZB' -- using value from closest neighbor (in WB Region) 'TUR' \n",
      "No MSP found for region 'VCT' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'VEN' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'VGB' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'VIR' -- using value from closest neighbor (in WB Region) 'COL' \n",
      "No MSP found for region 'VNM' -- using value from closest neighbor (in WB Region) 'CHN' \n",
      "No MSP found for region 'VUT' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'WSM' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'XKX' -- using value from closest neighbor (in WB Region) 'MKD' \n",
      "No MSP found for region 'YEM' -- using value from closest neighbor (in WB Region) 'MLT' \n",
      "No MSP found for region 'ZAF' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'ZMB' -- using regional average from WB Region 'Latin America & Caribbean'\n",
      "No MSP found for region 'ZWE' -- using regional average from WB Region 'Latin America & Caribbean'\n"
     ]
    }
   ],
   "source": [
    "# NOTE: IEA puts these out monthly, easy to update regularly\n",
    "fp_prod_elec = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/MES_012023.csv\"\n",
    "\n",
    "\n",
    "##  FIELDS\n",
    "\n",
    "field_iea_balance = \"Balance\"\n",
    "field_iea_country = \"Country\"\n",
    "field_iea_product = \"Product\"\n",
    "field_iea_time = \"Time\"\n",
    "field_iea_unit = \"Unit\"\n",
    "field_iea_value = \"Value\"\n",
    "\n",
    "\n",
    "##  SOME DICTIONARIES\n",
    "\n",
    "# replace IEA products with SISEPUEDE powerplants\n",
    "dict_repl_iea_product = {\n",
    "    \"Coal, Peat and Manufactured Gases\": \"pp_coal\",\n",
    "    \"Combustible Renewables\": \"pp_biomass\",\n",
    "    \"Oil and Petroleum Products\": \"pp_oil\",\n",
    "    \"Natural Gas\": \"pp_gas\",\n",
    "    \"Hydro\": \"pp_hydropower\",\n",
    "    \"Solar\": \"pp_solar\",\n",
    "    \"Geothermal\": \"pp_geothermal\",\n",
    "    \"Nuclear\": \"pp_nuclear\",\n",
    "    \"Other Renewables\": \"pp_ocean\"\n",
    "}\n",
    "\n",
    "dict_wb_region_to_regions = sf.group_df_as_dict(\n",
    "    attr_region.table,\n",
    "    [field_wb_global_region],\n",
    "    fields_out_set = attr_region.key\n",
    ")\n",
    "dict_region_to_wb_region = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_wb_global_region}\")\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "#    FUNCTIONS    #\n",
    "###################\n",
    "\n",
    "def time_str_to_month_year(\n",
    "    date_str: str,\n",
    "    format_str: str = \"%B %Y\"\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Convert date string date_str using format_str to (month, year)\n",
    "        tuple of ints\n",
    "    \"\"\"\n",
    "    dt = datetime.datetime.strptime(date_str, format_str)\n",
    "    \n",
    "    return (dt.month, dt.year)\n",
    "\n",
    "\n",
    "\n",
    "def clean_production_df(\n",
    "    df_in: pd.DataFrame,\n",
    "    cats_drop: Union[List[str], None] = None,\n",
    "    field_country: str = field_country,\n",
    "    field_iso: str = field_iso,\n",
    "    field_technology: str = field_technology,\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean electricity production data frame df_in\n",
    "    \"\"\"\n",
    "    df_in[field_iso] = get_isos_from_iea(\n",
    "        df_in,  \n",
    "        field_country = field_country,\n",
    "        **kwargs\n",
    "    )\n",
    "    df_in.drop([field_country], axis = 1, inplace = True)\n",
    "    \n",
    "    if cats_drop is not None:\n",
    "        df_in = df_in[\n",
    "            ~df_in[field_technology].isin(cats_drop)\n",
    "        ].reset_index(drop = True)\n",
    "        \n",
    "    return df_in\n",
    "\n",
    "\n",
    "\n",
    "def get_and_format_electricity_production(\n",
    "    fp_in: str,\n",
    "    balance_elec: str = \"Net Electricity Production\",\n",
    "    dict_repl_iea_product: Dict[str, str] = dict_repl_iea_product,\n",
    "    field_balance: str = field_iea_balance,\n",
    "    field_month: str = field_month,\n",
    "    field_product: str = field_iea_product,\n",
    "    field_time: str = field_iea_time,\n",
    "    field_year: str = field_year,\n",
    "    year_min: int = 2010,\n",
    ") -> Union[pd.DataFrame, None]:\n",
    "    \"\"\"\n",
    "    Function Arguments\n",
    "    ------------------\n",
    "    - fp_in: path to input data frame\n",
    "    \n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    - balance_elec: value in field_balance associated with electricity production\n",
    "    - dict_repl_iea_product: dictionary mapping IEA Product values to SISEPUEDE\n",
    "        electricity generation technologies (used for allocation)\n",
    "    - field_balance: field storing IEA balances in the MES table\n",
    "    - field_month: field with months\n",
    "    - field_product: field storing IEA input products (fuels) associated with\n",
    "        electricity produciton\n",
    "    - field_time: field storing IEA time\n",
    "    - field_year: field with year\n",
    "    - year_min: minimum year to use for average factor\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(fp_in):\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ##  READ IN PRODUCTION AND ADD/CLEAN SOME FIELDS\n",
    "    \n",
    "    df_production = pd.read_csv(\n",
    "        fp_in, \n",
    "        encoding = \"cp1252\",\n",
    "        skiprows = 8\n",
    "    )\n",
    "    \n",
    "    # select balance that is needed\n",
    "    df_production = df_production[\n",
    "        df_production[field_balance].isin([balance_elec])\n",
    "    ].drop([field_balance], axis = 1)\n",
    "    \n",
    "    # replace fields and drop any products that are unneeded\n",
    "    df_production[field_product].replace(dict_repl_iea_product, inplace = True)\n",
    "    df_production = df_production[\n",
    "        df_production[field_product].isin(list(dict_repl_iea_product.values()))\n",
    "    ].reset_index(drop = True)\n",
    "    \n",
    "    # add month/year\n",
    "    df_production = pd.concat(\n",
    "        [\n",
    "            df_production.drop(field_time, axis = 1),\n",
    "            pd.DataFrame(\n",
    "                list(\n",
    "                    df_production[field_time].apply(time_str_to_month_year)\n",
    "                ),\n",
    "                columns = [field_month, field_year]\n",
    "            )\n",
    "        ],\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "    return df_production\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_electricity_production_dictionary(\n",
    "    df_in: Union[pd.DataFrame, str],    \n",
    "    dict_rename_output: Union[Dict[str, str], None] = None,\n",
    "    field_country: str = field_iea_country,\n",
    "    field_month: str = field_month,\n",
    "    field_product: str = field_iea_product,\n",
    "    field_unit: str = field_iea_unit,\n",
    "    field_value: str = field_iea_value,\n",
    "    field_year: str = field_year,\n",
    "    key_annual_prod_proportions: str = \"annual_production_proportions\",\n",
    "    key_avg_prod_proportions: str = \"average_annual_production_proportions\",\n",
    "    model_attributes: ma.ModelAttributes = sa.model_attributes,\n",
    "    time_periods: Union[sc.TimePeriods, None] = None,\n",
    "    **kwargs\n",
    ") -> Union[Dict[str, pd.DataFrame], None]:\n",
    "    \"\"\"\n",
    "    Return a dictionary of different averages for electricity production\n",
    "\n",
    "    Function Arguments\n",
    "    ------------------\n",
    "    - df_in: data frame containing production data OR file path to \n",
    "        production data to read in (IEA MES file)\n",
    "\n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    - dict_rename_output: dictionary to rename output fields. If None, \n",
    "        returns DataFrame with IEA fields\n",
    "    - field_country: field storing IEA country/regions\n",
    "    - field_month: field with months\n",
    "    - field_product: field storing IEA input products (fuels) associated \n",
    "        with electricity produciton\n",
    "    - field_unit: field storing IEA Units\n",
    "    - field_value: field storing IEA values\n",
    "    - field_year: field with year\n",
    "    - key_annual_prod_proportions: output dictionary key storing annual \n",
    "        production proportions by SISEPUEDE power plant type\n",
    "    - key_avg_prod_proportions: output dictionary key storing average \n",
    "        production proportions by SISEPUEDE power plant type (across years)\n",
    "    - model_attributes: ModelAttributes object used to determine time period \n",
    "        and key fields\n",
    "    - time_periods: optional TimePeriods object used to map years to time \n",
    "        periods\n",
    "    - **kwargs: passed to get_and_format_electricity_production if df_in is \n",
    "        a string\n",
    "    \"\"\"\n",
    "    \n",
    "    ##  INITIALIZATION\n",
    "    \n",
    "    attr_region = model_attributes.dict_attributes.get(f\"{model_attributes.dim_region}\")\n",
    "    attr_time_period = model_attributes.dict_attributes.get(f\"dim_{model_attributes.dim_time_period}\")\n",
    "    time_periods = sc.TimePeriods(model_attributes) if (time_periods is None) else time_periods\n",
    "    \n",
    "    df_in = (\n",
    "        get_and_format_electricity_production(\n",
    "            df_in,\n",
    "            field_month = field_month,\n",
    "            field_product = field_product,\n",
    "            field_year = field_year,\n",
    "            **kwargs\n",
    "        )\n",
    "        if isinstance(df_in, str)\n",
    "        else (df_in if isinstance(df_in, pd.DataFrame) else None)\n",
    "    )\n",
    "    \n",
    "    if df_in is None:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ##  GET AGGREGATIONS\n",
    "    \n",
    "    # initialize output\n",
    "    dict_out = {}\n",
    "    \n",
    "    # check acceptable years\n",
    "    years_keep = []\n",
    "    df_in_grouped = df_in.groupby([field_year])\n",
    "    for yr, df in df_in_grouped:\n",
    "        years_keep.append(yr) if (len(set(df[field_month])) == 12) else None\n",
    "\n",
    "    # total production by fuel (product) for each year\n",
    "    df_production_annual_total = sf.simple_df_agg(\n",
    "        df_in[\n",
    "            df_in[field_year].isin(years_keep)\n",
    "        ].drop([field_unit, field_month], axis = 1),\n",
    "        [\n",
    "            field_country, \n",
    "            field_product,\n",
    "            field_year\n",
    "        ],\n",
    "        {\n",
    "            field_value: \"sum\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # get production fractions by year and update dictionary\n",
    "    df_production_fractions_annual = sf.get_cols_as_grouped_proportions(\n",
    "        df_production_annual_total, \n",
    "        [field_iea_value], \n",
    "        [field_iea_country, field_year],\n",
    "        drop_if_zero_sum = True\n",
    "    )\n",
    "    dict_out.update({key_annual_prod_proportions: df_production_fractions_annual})\n",
    "    \n",
    "    \n",
    "    # get averages across years and add to output dictionary\n",
    "    \n",
    "    df_production_fractions_mean = []\n",
    "    \n",
    "    df_pfm_grouped = (\n",
    "        df_production_fractions_annual\n",
    "        .groupby([field_country])\n",
    "    )\n",
    "    \n",
    "    for country, df in df_pfm_grouped:\n",
    "        df_cur = sf.simple_df_agg(\n",
    "            df,\n",
    "            [\n",
    "                field_country,\n",
    "                field_product\n",
    "            ],\n",
    "            {\n",
    "                field_iea_value: \"sum\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        df_cur[field_iea_value] = np.array(df_cur[field_iea_value])/len(df[field_year].unique())\n",
    "        df_production_fractions_mean.append(df_cur)\n",
    "        \n",
    "        \n",
    "    df_production_fractions_mean = (\n",
    "        pd.concat(df_production_fractions_mean, axis = 0)\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "    dict_out.update({key_avg_prod_proportions: df_production_fractions_mean})\n",
    "\n",
    "    \n",
    "    ##  SOME UPDATES TO EACH DATAFRAME\n",
    "    \n",
    "    for k in dict_out.keys():\n",
    "        df_tmp = dict_out.get(k)\n",
    "        \n",
    "        # add time period\n",
    "        if field_year in df_tmp.columns:\n",
    "            df_tmp[attr_time_period.key] = df_tmp[field_year].apply(time_periods.year_to_tp)\n",
    "    \n",
    "        # rename\n",
    "        if dict_rename_output is not None:\n",
    "            dict_rnm_tmp = {}\n",
    "            for r, v in dict_rename_output.items():\n",
    "                dict_rnm_tmp.update({r: v}) if (r in df_tmp.columns) else None\n",
    "\n",
    "            df_tmp.rename(columns = dict_rnm_tmp, inplace = True)\n",
    "        \n",
    "        \n",
    "    return dict_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#   ADD TO REGIONS CLASS\n",
    "#\n",
    "def get_isos_from_iea(\n",
    "    df_in: pd.DataFrame,\n",
    "    attr_region: AttributeTable = attr_region,\n",
    "    field_country: str = field_country,\n",
    "    field_iso_attr_region: str = field_iso_region_attr,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map IEA countries in field_country to ISO codes\n",
    "    \"\"\"\n",
    "    dict_country_to_iso = attr_region.field_maps.get(f\"{attr_region.key}_to_{field_iso_attr_region}\")\n",
    "    \n",
    "    # some generic replacements\n",
    "    dict_repl_consumption = {\n",
    "        \"czech_republic\": \"czechia\",\n",
    "        \"korea\": \"republic_of_korea\",\n",
    "        \"people's_republic_of_china\": \"china\",\n",
    "        \"republic_of_turkiye\": \"turkey\",\n",
    "        \"slovak_republic\": \"slovakia\",\n",
    "        \"united_states\": \"united_states_of_america\"\n",
    "    }\n",
    "\n",
    "    vec_iso = [x.lower().replace(\" \", \"_\") for x in list(df_in[field_country])]\n",
    "    vec_iso = [dict_repl_consumption.get(x, x) for x in vec_iso]\n",
    "    vec_iso = [dict_country_to_iso.get(x, x) for x in vec_iso]\n",
    "    \n",
    "    return np.array(vec_iso)\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "#    MAIN    #\n",
    "##############\n",
    "\n",
    "# retrieve and clean\n",
    "dict_rnm_elec_prods = {\n",
    "    field_iea_product: field_technology,\n",
    "    field_iea_value: field_fraction_production,\n",
    "}\n",
    "dfs_production_by_country = get_electricity_production_dictionary(\n",
    "    fp_prod_elec,\n",
    "    dict_rename_output = dict_rnm_elec_prods\n",
    ")\n",
    "df_production_by_country = dfs_production_by_country.get(\"annual_production_proportions\")\n",
    "df_avg_production_by_country = dfs_production_by_country.get(\"average_annual_production_proportions\")\n",
    "\n",
    "\n",
    "\n",
    "##  CLEAN FIELDS AND DATA FRAMES\n",
    "\n",
    "#  drop integrated techs for now\n",
    "df_production_by_country = clean_production_df(\n",
    "    df_production_by_country,\n",
    "    cats_drop = cats_entc_drop\n",
    ")\n",
    "\n",
    "df_avg_production_by_country = clean_production_df(\n",
    "    df_avg_production_by_country,\n",
    "    cats_drop = cats_entc_drop\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#set sets of tech & isos available\n",
    "all_technology = sorted(list(df_production_by_country[field_technology].unique()))\n",
    "all_iso_defined_in_production = sorted(list(df_production_by_country[field_iso].unique()))\n",
    "\n",
    "# get all years and techs to merge to\n",
    "years_merge = range(\n",
    "    min(df_production_by_country[field_year]), \n",
    "    max(df_production_by_country[field_year]) + 1\n",
    ")\n",
    "df_left = pd.DataFrame({field_year: years_merge})\n",
    "df_left = sf.explode_merge(\n",
    "    df_left,\n",
    "    pd.DataFrame({field_technology: all_technology})\n",
    ")\n",
    "df_left = sf.explode_merge(\n",
    "    df_left,\n",
    "    pd.DataFrame({field_iso: all_iso_defined_in_production})\n",
    ")\n",
    "\n",
    "# merge to all years/techs available and fill missing fractions with 0\n",
    "df_production_by_country = pd.merge(\n",
    "    df_left, \n",
    "    df_production_by_country,\n",
    "    how = \"left\"\n",
    ")\n",
    "df_production_by_country[sa.model_attributes.dim_time_period] = df_production_by_country[field_year].apply(time_periods.year_to_tp).astype(int)\n",
    "\n",
    "# clean the time period and group by country; group and iterate to     \n",
    "df_production_by_country = sf.pivot_df_clean(\n",
    "    df_production_by_country,\n",
    "    [field_technology],\n",
    "    [field_fraction_production]\n",
    ")\n",
    "\n",
    "# interpolate (backfill) missing years\n",
    "df_production_by_country_list = []\n",
    "df_production_by_country_grouped = df_production_by_country.groupby([field_iso])\n",
    "fields_data = [x for x in df_production_by_country if x not in [field_iso, field_year, attr_time_period.key]]\n",
    "\n",
    "for iso, df in df_production_by_country_grouped:\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if np.abs(df[fields_data].iloc[i].sum() - 1.0) < 0.000001:\n",
    "            df.iloc[i] = df.iloc[i].fillna(0.0)\n",
    "            \n",
    "    df[fields_data] = df[fields_data].interpolate()\n",
    "    df[fields_data] = df[fields_data].interpolate(method = \"bfill\")\n",
    "    \n",
    "    df_production_by_country_list.append(df)\n",
    "    \n",
    "df_production_by_country = pd.concat(df_production_by_country_list, axis = 0).reset_index(drop = True)\n",
    "\n",
    "df_out = [\n",
    "    df_production_by_country\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "##  NEXT, EXPAND TO ALL YEARS\n",
    "\n",
    "years_merge = range(\n",
    "    max(df_production_by_country[field_year]) + 1, \n",
    "    max(attr_time_period.table[field_year]) + 1\n",
    ")\n",
    "df_left = pd.DataFrame({field_year: years_merge})\n",
    "df_left = sf.explode_merge(\n",
    "    df_left,\n",
    "    pd.DataFrame({field_technology: all_technology})\n",
    ")\n",
    "df_left = sf.explode_merge(\n",
    "    df_left,\n",
    "    pd.DataFrame({field_iso: all_iso_defined_in_production})\n",
    ")\n",
    "\n",
    "# use averages for all future dates \n",
    "df_production_by_country_append = pd.merge(\n",
    "    df_left,\n",
    "    df_avg_production_by_country,\n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "\n",
    "df_production_by_country_append = sf.pivot_df_clean(\n",
    "    df_production_by_country_append,\n",
    "    [field_technology],\n",
    "    [field_fraction_production]\n",
    ").fillna(0.0)\n",
    "\n",
    "# clean the time period\n",
    "df_production_by_country_append[sa.model_attributes.dim_time_period] = df_production_by_country_append[\n",
    "    field_year\n",
    "].apply(time_periods.year_to_tp).astype(int)\n",
    "\n",
    "df_out += [\n",
    "    df_production_by_country_append\n",
    "]\n",
    "\n",
    "\n",
    "# concatenate\n",
    "df_out = (\n",
    "    pd.concat(df_out, axis = 0)\n",
    "    .sort_values(by = [field_iso, field_year])\n",
    "    .reset_index(drop = True)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use global average in absence of anything else\n",
    "isos_missing = sorted(list(set(regions.all_isos) - set(all_iso_defined_in_production)))\n",
    "isos_avail = set(df_production_by_country[field_iso])\n",
    "iso_dummy_default = \"iea_total\"\n",
    "\n",
    "# for regions that have no IEA/OECD data, try to relate to closest region\n",
    "dict_try_wb_region_to_related_wb_region = {\n",
    "    \"Middle East & North Africa\": \"Latin America & Caribbean\", \n",
    "    \"Sub-Saharan Africa\": \"Latin America & Caribbean\",\n",
    "    \"South Asia\": \"East Asia & Pacific\"\n",
    "}\n",
    "\n",
    "# some fields to use in the aggregation\n",
    "flds_group = [field_year, attr_time_period.key]\n",
    "flds_data = [x for x in df_out.columns if (x != field_iso) and (x not in flds_group)]\n",
    "\n",
    "\n",
    "if len(isos_missing) > 0:\n",
    "\n",
    "    df_append = [df_out]\n",
    "\n",
    "    for iso_missing in isos_missing:\n",
    "\n",
    "        # initialize some potential components\n",
    "        df_cur = None\n",
    "        iso_replace = None\n",
    "\n",
    "        region_wb = regions.get_world_bank_region(iso_missing)\n",
    "        isos_wb = set([regions.return_region_or_iso(x, return_type = \"iso\") for x in dict_wb_region_to_regions.get(region_wb)])\n",
    "        isos_valid = list(isos_wb & isos_avail)\n",
    "\n",
    "        if len(isos_valid) > 0:\n",
    "            \n",
    "            # get closest region within global WB region\n",
    "            iso_replace = regions.get_closest_region(\n",
    "                iso_missing,\n",
    "                regions_valid = isos_valid,\n",
    "                type_input = \"iso\",\n",
    "                type_return = \"iso\"\n",
    "            )\n",
    "            \n",
    "            print(f\"No MSP found for region '{iso_missing}' -- using value from closest neighbor (in WB Region) '{iso_replace}' \")\n",
    "            \n",
    "        elif region_wb in dict_try_wb_region_to_related_wb_region.keys():\n",
    "\n",
    "            region_wb = dict_try_wb_region_to_related_wb_region.get(region_wb)\n",
    "            df_cur = regions.aggregate_df_by_wb_global_region(\n",
    "                df_out,\n",
    "                region_wb,\n",
    "                flds_group,\n",
    "                dict((x, \"mean\") for x in flds_data),\n",
    "                field_iso = field_iso\n",
    "            )\n",
    "            \n",
    "            print(f\"No MSP found for region '{iso_missing}' -- using regional average from WB Region '{region_wb}'\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # default to global IEA average\n",
    "            iso_replace = iso_dummy_default\n",
    "\n",
    "\n",
    "        df_cur = (\n",
    "            df_out[\n",
    "                df_out[field_iso] == iso_replace\n",
    "            ].copy().reset_index(drop = True)\n",
    "            if (df_cur is None) and (iso_replace is not None)\n",
    "            else df_cur\n",
    "        ) \n",
    "\n",
    "        df_cur[field_iso] = iso_missing\n",
    "        df_append.append(df_cur)\n",
    "\n",
    "    df_out = pd.concat(df_append, axis = 0)\n",
    "    df_out = (\n",
    "        df_out[df_out[field_iso].isin(regions.all_isos)]\n",
    "        .sort_values(by = [field_iso, field_year])\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  FORMAT OUTPUT DATASET\n",
    "\n",
    "fields_group = [field_year, attr_time_period.key, field_iso]\n",
    "fields_data = [x for x in attr_technology.key_values if x in df_out.columns]\n",
    "\n",
    "# name as MSP variable\n",
    "modvar = model_elec.modvar_entc_nemomod_min_share_production\n",
    "subsec = model_elec.model_attributes.get_variable_subsector(modvar)\n",
    "fields_new = sa.model_attributes.build_varlist(\n",
    "    subsec, \n",
    "    modvar,\n",
    "    restrict_to_category_values = fields_data\n",
    ")\n",
    "\n",
    "dict_rnm = dict(zip(fields_data, fields_new))\n",
    "\n",
    "\n",
    "df_out_grouped = df_out.groupby([field_iso])\n",
    "df_out_new = []\n",
    "dfk = None\n",
    "for i, df in df_out_grouped:\n",
    "    \n",
    "    yrs = df[fields_group].copy()\n",
    "    \n",
    "    df[\"TMP\"] = df[fields_data].sum(axis = 1)\n",
    "    \n",
    "    df = pd.merge(\n",
    "        yrs,\n",
    "        df[df[\"TMP\"] > 0],\n",
    "        how = \"left\"\n",
    "    )\n",
    "    dfk = df if (i == \"CRI\") else dfk\n",
    "    \n",
    "    # perform interpolations\n",
    "    df[fields_data] = df[fields_data].interpolate()\n",
    "    df[fields_data] = df[fields_data].interpolate(method = \"bfill\")\n",
    "    \n",
    "    df_out_new.append(df)\n",
    "\n",
    "    \n",
    "df_out = pd.concat(df_out_new, axis = 0).reset_index(drop = True)\n",
    "df_out = df_out[fields_group + fields_data].rename(columns = dict_rnm)\n",
    "\n",
    "# FINALLY--0 OUT SOME VALUES\n",
    "fields_zero = sa.model_attributes.build_varlist(\n",
    "    None,\n",
    "    modvar,\n",
    "    restrict_to_category_values = [\"pp_waste_incineration\", \"pp_biogas\", \"pp_biomass\"]\n",
    ")\n",
    "fields_zero = [x for x in fields_zero if x in df_out.columns]\n",
    "\n",
    "df_out[fields_zero] = 0\n",
    "\n",
    "if True:\n",
    "    df_out.to_csv(\n",
    "        sa.fp_csv_nemomod_minimum_share_of_production_baselines,\n",
    "        index = None,\n",
    "        encoding = \"UTF-8\"\n",
    "    )\n",
    "\n",
    "#if False:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Electric Transmission Loss data\n",
    "- source of CSV (World Bank): https://data.worldbank.org/indicator/EG.ELC.LOSS.ZS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No MSP found for region 'ABW' -- using value from closest neighbor (in WB Region) 'CUW' \n",
      "No MSP found for region 'AFG' -- using value from closest neighbor (in WB Region) 'PAK' \n",
      "No MSP found for region 'AND' -- using value from closest neighbor (in WB Region) 'FRA' \n",
      "No MSP found for region 'ASM' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'ATG' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'BDI' -- using value from closest neighbor (in WB Region) 'TZA' \n",
      "No MSP found for region 'BFA' -- using value from closest neighbor (in WB Region) 'TGO' \n",
      "No MSP found for region 'BHS' -- using value from closest neighbor (in WB Region) 'CUB' \n",
      "No MSP found for region 'BLZ' -- using value from closest neighbor (in WB Region) 'HND' \n",
      "No MSP found for region 'BMU' -- using value from closest neighbor (in WB Region) 'CAN' \n",
      "No MSP found for region 'BRB' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'BTN' -- using value from closest neighbor (in WB Region) 'BGD' \n",
      "No MSP found for region 'CAF' -- using value from closest neighbor (in WB Region) 'CMR' \n",
      "No MSP found for region 'COM' -- using value from closest neighbor (in WB Region) 'MOZ' \n",
      "No MSP found for region 'CPV' -- using value from closest neighbor (in WB Region) 'SEN' \n",
      "No MSP found for region 'CYM' -- using value from closest neighbor (in WB Region) 'CUB' \n",
      "No MSP found for region 'DJI' -- using value from closest neighbor (in WB Region) 'YEM' \n",
      "No MSP found for region 'DMA' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'FJI' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'FRO' -- using value from closest neighbor (in WB Region) 'ISL' \n",
      "No MSP found for region 'FSM' -- using value from closest neighbor (in WB Region) 'PHL' \n",
      "No MSP found for region 'GIN' -- using value from closest neighbor (in WB Region) 'SEN' \n",
      "No MSP found for region 'GMB' -- using value from closest neighbor (in WB Region) 'SEN' \n",
      "No MSP found for region 'GNB' -- using value from closest neighbor (in WB Region) 'SEN' \n",
      "No MSP found for region 'GNQ' -- using value from closest neighbor (in WB Region) 'GAB' \n",
      "No MSP found for region 'GRD' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'GRL' -- using value from closest neighbor (in WB Region) 'ISL' \n",
      "No MSP found for region 'GUM' -- using value from closest neighbor (in WB Region) 'PHL' \n",
      "No MSP found for region 'GUY' -- using value from closest neighbor (in WB Region) 'SUR' \n",
      "No MSP found for region 'IMN' -- using value from closest neighbor (in WB Region) 'IRL' \n",
      "No MSP found for region 'KIR' -- using value from closest neighbor (in WB Region) 'PHL' \n",
      "No MSP found for region 'KNA' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'LAO' -- using value from closest neighbor (in WB Region) 'VNM' \n",
      "No MSP found for region 'LBR' -- using value from closest neighbor (in WB Region) 'CIV' \n",
      "No MSP found for region 'LCA' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'LIE' -- using value from closest neighbor (in WB Region) 'CHE' \n",
      "No MSP found for region 'LSO' -- using value from closest neighbor (in WB Region) 'ZAF' \n",
      "No MSP found for region 'MAC' -- using value from closest neighbor (in WB Region) 'HKG' \n",
      "No MSP found for region 'MAF' -- using value from closest neighbor (in WB Region) 'DOM' \n",
      "No MSP found for region 'MCO' -- using value from closest neighbor (in WB Region) 'CHE' \n",
      "No MSP found for region 'MDG' -- using value from closest neighbor (in WB Region) 'MUS' \n",
      "No MSP found for region 'MDV' -- using value from closest neighbor (in WB Region) 'LKA' \n",
      "No MSP found for region 'MHL' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'MLI' -- using value from closest neighbor (in WB Region) 'CIV' \n",
      "No MSP found for region 'MNP' -- using value from closest neighbor (in WB Region) 'JPN' \n",
      "No MSP found for region 'MRT' -- using value from closest neighbor (in WB Region) 'SEN' \n",
      "No MSP found for region 'MWI' -- using value from closest neighbor (in WB Region) 'MOZ' \n",
      "No MSP found for region 'NCL' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'NRU' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'PLW' -- using value from closest neighbor (in WB Region) 'PHL' \n",
      "No MSP found for region 'PNG' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'PRI' -- using value from closest neighbor (in WB Region) 'DOM' \n",
      "No MSP found for region 'PYF' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'RWA' -- using value from closest neighbor (in WB Region) 'COD' \n",
      "No MSP found for region 'SLB' -- using value from closest neighbor (in WB Region) 'AUS' \n",
      "No MSP found for region 'SLE' -- using value from closest neighbor (in WB Region) 'CIV' \n",
      "No MSP found for region 'SMR' -- using value from closest neighbor (in WB Region) 'ITA' \n",
      "No MSP found for region 'SOM' -- using value from closest neighbor (in WB Region) 'ETH' \n",
      "No MSP found for region 'STP' -- using value from closest neighbor (in WB Region) 'GAB' \n",
      "No MSP found for region 'SWZ' -- using value from closest neighbor (in WB Region) 'ZAF' \n",
      "No MSP found for region 'SXM' -- using value from closest neighbor (in WB Region) 'DOM' \n",
      "No MSP found for region 'SYC' -- using value from closest neighbor (in WB Region) 'MUS' \n",
      "No MSP found for region 'TCA' -- using value from closest neighbor (in WB Region) 'HTI' \n",
      "No MSP found for region 'TCD' -- using value from closest neighbor (in WB Region) 'CMR' \n",
      "No MSP found for region 'TLS' -- using value from closest neighbor (in WB Region) 'IDN' \n",
      "No MSP found for region 'TON' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'TUV' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'UGA' -- using value from closest neighbor (in WB Region) 'KEN' \n",
      "No MSP found for region 'VCT' -- using value from closest neighbor (in WB Region) 'TTO' \n",
      "No MSP found for region 'VGB' -- using value from closest neighbor (in WB Region) 'DOM' \n",
      "No MSP found for region 'VIR' -- using value from closest neighbor (in WB Region) 'DOM' \n",
      "No MSP found for region 'VUT' -- using value from closest neighbor (in WB Region) 'NZL' \n",
      "No MSP found for region 'WSM' -- using value from closest neighbor (in WB Region) 'NZL' \n"
     ]
    }
   ],
   "source": [
    "df_losses = pd.read_csv(\n",
    "    \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/API_EG.ELC.LOSS.ZS_DS2_en_csv_v2_4898900/API_EG.ELC.LOSS.ZS_DS2_en_csv_v2_4898900.csv\",\n",
    "    skiprows = 3\n",
    ")\n",
    "\n",
    "# some filtering\n",
    "field_cc = \"Country Code\"\n",
    "indicator = \"Electric power transmission and distribution losses (% of output)\"\n",
    "df_losses = df_losses[\n",
    "    df_losses[\"Indicator Name\"] == indicator\n",
    "].reset_index(drop = True).rename(columns = {field_cc: field_iso}).dropna(how = \"all\", axis = 1)\n",
    "\n",
    "# get variable name\n",
    "subsec = sa.model_attributes.get_variable_subsector(\n",
    "    model_elec.modvar_enfu_transmission_loss_frac_electricity\n",
    ")\n",
    "field_var = sa.model_attributes.build_varlist(\n",
    "    subsec,\n",
    "    model_elec.modvar_enfu_transmission_loss_frac_electricity,\n",
    "    restrict_to_category_values = [model_elec.cat_enfu_elec]\n",
    ")[0]\n",
    "\n",
    "\n",
    "# get data and melt\n",
    "fields_data = [x for x in df_losses.columns if str(x).isnumeric()]\n",
    "df_losses = pd.melt(\n",
    "    df_losses[[field_iso] + fields_data],\n",
    "    [field_iso],\n",
    "    fields_data,\n",
    "    value_name = field_var,\n",
    "    var_name = field_year\n",
    ").dropna().reset_index(drop = True)\n",
    "# convert strings to int\n",
    "df_losses[field_year] = [int(x) for x in list(df_losses[field_year])]\n",
    "\n",
    "# get full set of years to merge into \n",
    "year_min = 2010\n",
    "years_merge = range(\n",
    "    year_min, \n",
    "    time_periods.year_max + 1\n",
    ")\n",
    "df_left = pd.DataFrame({field_year: years_merge})\n",
    "df_left = sf.explode_merge(\n",
    "    df_left,\n",
    "    pd.DataFrame({field_iso: all_iso})\n",
    ")\n",
    "\n",
    "# group and iterate\n",
    "dfs_losses = df_losses.groupby([field_iso])\n",
    "df_out = []\n",
    "for i, df in dfs_losses:\n",
    "    \n",
    "    if i in all_iso:\n",
    "        df_cur = df.sort_values(by = [\"year\"], ascending = False)\n",
    "        mv = np.mean(np.array(df_cur[field_var])[0:min(5, len(df))])\n",
    "\n",
    "        df_cur = pd.merge(df_left[df_left[field_iso] == i], df_cur, how = \"left\")\n",
    "        df_cur = df_cur[df_cur[field_year] >= year_min].fillna(mv)\n",
    "        \n",
    "        # add time period and reduce to fraction\n",
    "        df_cur[attr_time_period.key] = df_cur[field_year].apply(time_periods.year_to_tp)\n",
    "        df_cur[field_var] = sf.vec_bounds(np.array(df_cur[field_var])/100, (0.0, 1.0))\n",
    "        \n",
    "        df_out.append(df_cur)\n",
    "\n",
    "df_out = pd.concat(df_out, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "# use global average in absence of anything else\n",
    "isos_avail = set(df_out[field_iso])\n",
    "isos_missing = sorted(list(set(regions.all_isos) - isos_avail))\n",
    "\n",
    "# for regions that have no IEA/OECD data, try to relate to closest region\n",
    "dict_try_wb_region_to_related_wb_region = {\n",
    "    \"Middle East & North Africa\": \"Latin America & Caribbean\", \n",
    "    \"Sub-Saharan Africa\": \"Latin America & Caribbean\",\n",
    "    \"South Asia\": \"East Asia & Pacific\"\n",
    "}\n",
    "\n",
    "# some fields to use in the aggregation\n",
    "flds_group = [field_year, attr_time_period.key]\n",
    "flds_data = [x for x in df_out.columns if (x != field_iso) and (x not in flds_group)]\n",
    "\n",
    "\n",
    "if len(isos_missing) > 0:\n",
    "\n",
    "    df_append = [df_out]\n",
    "\n",
    "    for iso_missing in isos_missing:\n",
    "\n",
    "        # initialize some potential components\n",
    "        df_cur = None\n",
    "        iso_replace = None\n",
    "\n",
    "        region_wb = regions.get_world_bank_region(iso_missing)\n",
    "        isos_wb = set([regions.return_region_or_iso(x, return_type = \"iso\") for x in dict_wb_region_to_regions.get(region_wb)])\n",
    "        isos_valid = list(isos_wb & isos_avail)\n",
    "\n",
    "        if len(isos_valid) > 0:\n",
    "            \n",
    "            # get closest region within global WB region\n",
    "            iso_replace = regions.get_closest_region(\n",
    "                iso_missing,\n",
    "                regions_valid = isos_valid,\n",
    "                type_input = \"iso\",\n",
    "                type_return = \"iso\"\n",
    "            )\n",
    "            \n",
    "            print(f\"No MSP found for region '{iso_missing}' -- using value from closest neighbor (in WB Region) '{iso_replace}' \")\n",
    "            \n",
    "        elif region_wb in dict_try_wb_region_to_related_wb_region.keys():\n",
    "\n",
    "            region_wb = dict_try_wb_region_to_related_wb_region.get(region_wb)\n",
    "            df_cur = regions.aggregate_df_by_wb_global_region(\n",
    "                df_out,\n",
    "                region_wb,\n",
    "                flds_group,\n",
    "                dict((x, \"mean\") for x in flds_data),\n",
    "                field_iso = field_iso\n",
    "            )\n",
    "            \n",
    "            print(f\"No MSP found for region '{iso_missing}' -- using regional average from WB Region '{region_wb}'\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # default to global IEA average\n",
    "            iso_replace = iso_dummy_default\n",
    "\n",
    "\n",
    "        df_cur = (\n",
    "            df_out[\n",
    "                df_out[field_iso] == iso_replace\n",
    "            ].copy().reset_index(drop = True)\n",
    "            if (df_cur is None) and (iso_replace is not None)\n",
    "            else df_cur\n",
    "        ) \n",
    "\n",
    "        df_cur[field_iso] = iso_missing\n",
    "        df_append.append(df_cur)\n",
    "\n",
    "    df_out = pd.concat(df_append, axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "fields_ord = [field_iso, field_year, attr_time_period.key, field_var]\n",
    "df_out = df_out[fields_ord].sort_values(by = [field_iso, field_year]).reset_index(drop = True)\n",
    "\n",
    "if True:\n",
    "    df_out.to_csv(\n",
    "        sa.fp_csv_nemomod_transmission_losses,\n",
    "        index = None,\n",
    "        encoding = \"UTF-8\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  FUEL COSTS\n",
    "- fuel costs come from Edmundo\n",
    "- tonne/barrel of oil comes from https://sciencing.com/convert-metric-tons-barrels-8220711.html\n",
    "    - 0.14459225\n",
    "- m3/barrel comes from https://www.metric-conversions.org\n",
    "    - 0.158987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fuel = pd.read_csv(\"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/Energy/fuel_prices_from_edmundo_20230306_with_thermal_hydrogen.csv\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set some field names\n",
    "field_fuel = \"fuel\"\n",
    "field_price = \"price\"\n",
    "field_unit = \"UNIT\"\n",
    "field_unit_denominator = \"unit_denominator\"\n",
    "field_tmp_scalar = \"scalar\"\n",
    "\n",
    "# some other fuel conversion costs\n",
    "oil_tonne_per_barrel = 0.14459225\n",
    "oil_m3_per_barrel = 0.158987\n",
    "oil_tonne_per_m3 = oil_tonne_per_barrel/oil_m3_per_barrel\n",
    "\n",
    "# drop some fields\n",
    "fields_drop = [x for x in df_fuel.columns if x in [\"Unnamed: 0\", \"Country.Name\", \"unit_type\"]]\n",
    "df_fuel.drop(fields_drop, axis = 1, inplace = True) if (len(fields_drop) > 0) else None\n",
    "\n",
    "# expand fuel before filling NAs\n",
    "df_fuel_all = sf.explode_merge(\n",
    "    df_fuel[[field_fuel, field_unit_denominator]].drop_duplicates(),\n",
    "    df_fuel[[field_iso]].drop_duplicates()\n",
    ")\n",
    "df_fuel = pd.merge(\n",
    "    df_fuel_all,\n",
    "    df_fuel, \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# loop over fuels and replace oil units if necessary\n",
    "df_fuel_grouped = df_fuel.groupby([field_fuel])\n",
    "fuels_mass_to_volume = [\"fuel_oil\", \"fuel_crude\"]\n",
    "\n",
    "df_fuel_new = []\n",
    "\n",
    "for i, df in df_fuel_grouped:\n",
    "    if i in fuels_mass_to_volume:\n",
    "        if set(df[field_unit_denominator]) == set({\"tonne\"}):\n",
    "            df[field_unit_denominator].replace({\"tonne\": \"m3\"}, inplace = True)\n",
    "            df[field_price] = np.array(df[field_price])*oil_tonne_per_m3\n",
    "        else:\n",
    "            print(f\"Check fuel {fuel}: not entered in tonnes\")\n",
    "\n",
    "    # get regional mean\n",
    "    price_mean = np.array(list(set(\n",
    "        df[\n",
    "            df[field_iso].isin(dict_iso_to_country.keys()) & \n",
    "            ~df[field_price].isna()\n",
    "        ][field_price]\n",
    "    ))).mean()\n",
    "\n",
    "    df[field_price].fillna(price_mean, inplace = True)\n",
    "\n",
    "    df_fuel_new.append(df)\n",
    "\n",
    "df_fuel = pd.concat(df_fuel_new, axis = 0).reset_index(drop = True)\n",
    "df_fuelc = df_fuel.copy()\n",
    "\n",
    "\n",
    "# replace input units\n",
    "dict_repl_units = {\n",
    "    'Mwh': \"mmbtu\", \n",
    "    \"mwh\": \"mmbtu\",\n",
    "    'liter': \"m3\", \n",
    "    'tonne': \"tonne\", \n",
    "    'MWH': \"mmbtu\", \n",
    "    '1000 liters': \"m3\", \n",
    "    '1000 liter': \"m3\", \n",
    "    'MBtu': \"mmbtu\",\n",
    "    \"mmbtu\": \"mmbtu\"\n",
    "}\n",
    "\n",
    "dict_repl_num_units = {\n",
    "    \"Total price (USD/unit using PPP)\": 1,\n",
    "    \"Total price (USD/unit)\": 1\n",
    "}\n",
    "\n",
    "# add scalars in terms of old per new\n",
    "\n",
    "# get variable units\n",
    "units_gravimetric = sa.model_attributes.get_variable_characteristic(\n",
    "    model_energy.modvar_enfu_price_gravimetric,\n",
    "    sa.model_attributes.varchar_str_unit_mass\n",
    ")\n",
    "units_thermal = sa.model_attributes.get_variable_characteristic(\n",
    "    model_energy.modvar_enfu_price_thermal,\n",
    "    sa.model_attributes.varchar_str_unit_energy\n",
    ")\n",
    "units_volumetric = sa.model_attributes.get_variable_characteristic(\n",
    "    model_energy.modvar_enfu_price_volumetric,\n",
    "    sa.model_attributes.varchar_str_unit_volume\n",
    ")\n",
    "\n",
    "dict_repl_units_scalars = {\n",
    "    'Mwh': sa.model_attributes.get_energy_equivalent(\"mwh\", units_thermal), \n",
    "    'liter': sa.model_attributes.get_volume_equivalent(\"litre\", units_volumetric), \n",
    "    'tonne': sa.model_attributes.get_mass_equivalent(\"tonne\", units_gravimetric), \n",
    "    'MWH': sa.model_attributes.get_energy_equivalent(\"mwh\", units_thermal),\n",
    "    '1000 liters': sa.model_attributes.get_volume_equivalent(\"m3\", units_volumetric),\n",
    "    '1000 liter': sa.model_attributes.get_volume_equivalent(\"m3\", units_volumetric), \n",
    "    \"m3\": sa.model_attributes.get_volume_equivalent(\"m3\", units_volumetric),\n",
    "    'MBtu': sa.model_attributes.get_energy_equivalent(\"mbtu\", units_thermal),\n",
    "    'mmbtu': sa.model_attributes.get_energy_equivalent(\"mmbtu\", units_thermal),\n",
    "}\n",
    "\n",
    "#\n",
    "df_fuel[field_tmp_scalar] = df_fuel[field_unit_denominator].replace(dict_repl_units_scalars)\n",
    "df_fuel[field_price] = np.array(df_fuel[field_price])/np.array(df_fuel[field_tmp_scalar])\n",
    "df_fuel[field_unit_denominator].replace(dict_repl_units, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# loop over fuels again, group to build variable \n",
    "df_fuel_grouped = df_fuel.groupby([field_fuel])\n",
    "\n",
    "cats_mass = sa.model_attributes.get_variable_categories(model_energy.modvar_enfu_price_gravimetric)\n",
    "cats_thermal = sa.model_attributes.get_variable_categories(model_energy.modvar_enfu_price_thermal)\n",
    "cats_volume = sa.model_attributes.get_variable_categories(model_energy.modvar_enfu_price_volumetric)\n",
    "\n",
    "# should all be the same, but just for consistency's sake\n",
    "subsec_mass = sa.model_attributes.get_variable_subsector(model_energy.modvar_enfu_price_gravimetric)\n",
    "subsec_thermal = sa.model_attributes.get_variable_subsector(model_energy.modvar_enfu_price_thermal)\n",
    "subsec_volume = sa.model_attributes.get_variable_subsector(model_energy.modvar_enfu_price_volumetric)\n",
    "\n",
    "dict_repl = {}\n",
    "fuels_unresolved = []\n",
    "\n",
    "\n",
    "for i, df in df_fuel_grouped:\n",
    "    \n",
    "    new_val = None\n",
    "    \n",
    "    if (str(df[field_unit_denominator].iloc[0]) == units_gravimetric) & (i in cats_mass):\n",
    "        \n",
    "        # check mass\n",
    "        new_val = sa.model_attributes.build_varlist(\n",
    "            subsec_mass,\n",
    "            model_energy.modvar_enfu_price_gravimetric,\n",
    "            restrict_to_category_values = [i]\n",
    "        )[0]\n",
    "    \n",
    "    if (str(df[field_unit_denominator].iloc[0]) == units_thermal) & (i in cats_thermal):\n",
    "        \n",
    "        # check thermal\n",
    "        new_val = sa.model_attributes.build_varlist(\n",
    "            subsec_thermal,\n",
    "            model_energy.modvar_enfu_price_thermal,\n",
    "            restrict_to_category_values = [i]\n",
    "        )[0]\n",
    "    \n",
    "    if (str(df[field_unit_denominator].iloc[0]) == units_volumetric) & (i in cats_volume):\n",
    "        \n",
    "        # check volume\n",
    "        new_val = sa.model_attributes.build_varlist(\n",
    "            subsec_volume,\n",
    "            model_energy.modvar_enfu_price_volumetric,\n",
    "            restrict_to_category_values = [i]\n",
    "        )[0]\n",
    "        \n",
    "    \n",
    "    fuels_unresolved += [i] if (new_val is None) else []\n",
    "    dict_repl.update({i: new_val}) if (new_val is not None) else None\n",
    "    \n",
    "        \n",
    "df_fuel[field_fuel].replace(dict_repl, inplace = True)\n",
    "    \n",
    "# pivot and reorder\n",
    "df_fuel = sf.pivot_df_clean(\n",
    "    df_fuel[[field_iso, field_fuel, field_price]],\n",
    "    [field_fuel],\n",
    "    [field_price]\n",
    ")\n",
    "\n",
    "df_fuel = sf.explode_merge(\n",
    "    attr_time_period.table[[attr_time_period.key]],\n",
    "    df_fuel[\n",
    "        df_fuel[field_iso].isin(regions.all_isos)\n",
    "    ]\n",
    ").sort_values(by = [field_iso, attr_time_period.key]).reset_index(drop = True)\n",
    "    \n",
    "\n",
    "fields_index = [field_iso, attr_time_period.key]\n",
    "df_fuel = df_fuel[fields_index + sorted([x for x in df_fuel.columns if x not in fields_index])]\n",
    "\n",
    "if True:\n",
    "    df_fuel.to_csv(\n",
    "        sa.fp_csv_nemomod_fuel_costs,\n",
    "        index = None, \n",
    "        encoding = \"UTF-8\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
